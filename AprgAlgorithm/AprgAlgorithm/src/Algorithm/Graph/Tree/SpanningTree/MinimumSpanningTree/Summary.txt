
Minimum spanning tree (MST) -> a spanning tree with the least weight (summation of the weight of the edges)

Applications:
-> MST is fundamental problem with diverse applications
---> Dithering
---> Cluster analysis
---> Max bottleneck paths
---> Real time face verification
---> Low-density parity-check (LDPC) codes for error correction
---> Image registration with Renyi entropy
---> Find road networks in satellite and aerial imagery
---> Reducing data storage in satellite and aerial imagery
---> Reducing data storage in sequencing amino acids in a protein
---> Model locality of particle interactions in turbulent fluid flows
---> Auto config protocol for Ethernet bridging to avoid cycles in a network
---> Approximation algorithms for NP-hard problems (TSP Steiner tree)
---> Network design (communication, electrical, hydraulic, computer, road)

MST exists and unique when:
-> Edge weights are distinct
-> Graph is connected
The algorithms here with still work even without those assumptions.

What would happen if the edge weights are not distinct?
-> Multiple MSTs

What if graph is not connected?
-> We will have minimum spanning forest. The MST of each component.

Cut property
-> A cut in a graph is a partition of its vertices into two (nonempty) sets.
-> Crossing edges connect a vertex in one set with a vertex in the other.
-> Given any cut, the crossing edge with minimum weight is in the MST.
-> Proof:
-> Suppose minimum weight crossing edge (e) is not in the MST
--> One of the other crossing edges are in the MST so adding e to the MST creates a cycle
--> Some other edge f in cycle must be a crossing edge
--> Removing f and adding e is also a spanning tree
--> Since weight of e is less than the weight of f -> that spanning tree is lower weight. -> This is a contradiction.

Greedy MST algorithm
-> Start with all edges colored gray.
-> Find any cut with no black crossing edges, color its minimum eight edge black.
-> Repeat until V-1 edges are colored black.

Proposition: The greedy algorithm computes the MST.
Proof: 
-> Any edge colored black is in the MST (via cut property)
-> Fewer than V-1 black edges => cut with no black crossing edges (consider cut whose vertices are one connected component). 


Unsolved problem: Does a linear time MST algorithm exist?
-> In 1975, Yao found MST algorithm with worst case E log log V
-> In 1976, Cheriton-Tarjan found MST algorithm with worst case E log log V
-> In 1984, Fredman-Tarjan found MST algorithm with worst case E log* V, E + V log V
-> In 1986, Gabow-Galil-Spencer-Tarjan found MST algorithm with worst case E log(log* V)
-> In 1997, Chazelle found MST algorithm with worst case E alpha(V) log(alpha(V)). Alpha is Inverse Ackermann function
-> In 2000, Chazelle found MST algorithm with worst case E alpha(V). Alpha is Inverse Ackermann function
-> In 2002, Pettie-Ramachandran found MST algorithm which is optimal.  
---> From the paper: 
---> Because of the nature of our algorithm, its exact running time is not known. 
---> This might seem paradoxical at first. The source of our algorithm’s optimality, and its mysterious running time, is the use of precomputed "MST decision trees" whose exact depth is unknown but nonetheless provably optimal.
-> In 20xx, any paper of proof or linear running time in the future?


Euclidean MST
-> Given N points in the plane, find MST connected them where the distance between point pairs are their Euclidean distances.
--> Brute force: Compute ~ (N^2)/2 distances and run Prim's algorithm.
--> Ingenuity. Exploit geometry and do it in ~ c N log N time. -> Voronoi Diagram or Delaunay triangulation -> (TBH I was thinking about Kd-trees and Prim's Algorithm)

Clustering
-> K-Clustering. Divide a set of objects classify into k-coherent groups.
-> Distance function: Numeric value specifying the closeness of two objects
-> Goal: Divide into clusters so that objects in different cluster are far apart
---> Practical example: outbreak of cholera deaths in London in the 1850's. -> They identified well pumps infected with cholera.

Single link clustering
-> Single link: Distance between two clusters equal the distance between the two closest objects (one in each cluster)
-> Single link clustering: Given an integer k, find a k-clustering that maximizes the distance between two closes clusters.

Well known algorithm for single link clustering
-> Form V clusters for one object each.
-> Find the closest pair of objects such that each object is in a different cluster, and merge the two clusters.
-> Repeat until there are exactly k clusters.
-> This is Kruskal algorithm (stop when there are k connected components).


Other discussions:

-> In a similar way, a "maximum spanning tree" is a spanning tree whose weight is as large as possible.
-> Minimum spanning tree algorithms can be used to find maximum spanning trees by processing the edges in reverse order.

What is Minimum Spanning Tree? 
Given a connected and undirected graph, a spanning tree of that graph is a subgraph that is a tree and connects all the vertices together. 
A single graph can have many different spanning trees. 
A minimum spanning tree (MST) or minimum weight spanning tree for a weighted, connected, undirected graph is a spanning tree with a weight less than or equal to the weight of every other spanning tree. 
The weight of a spanning tree is the sum of weights given to each edge of the spanning tree.

How many edges does a minimum spanning tree has? 
A minimum spanning tree has (V – 1) edges where V is the number of vertices in the given graph.

What are the applications of the Minimum Spanning Tree? 
MST is fundamental problem with diverse applications.
-> Network design.
–--> telephone, electrical, hydraulic, TV cable, computer, road
–--> The standard application is to a problem like phone network design. 
–--> You have a business with several offices; you want to lease phone lines to connect them up with each other; and the phone company charges different amounts of money to connect different pairs of cities. 
–--> You want a set of lines that connects all your offices with a minimum total cost. 
–--> It should be a spanning tree, since if a network isn’t a tree you can always remove some edges and save money.
-> Approximation algorithms for NP-hard problems.
–--> traveling salesperson problem, Steiner tree
–--> A less obvious application is that the minimum spanning tree can be used to approximately solve the traveling salesman problem. 
–----> A convenient formal way of defining this problem is to find the shortest path that visits each point at least once.
Note that if you have a path visiting all points exactly once, it’s a special kind of tree. 
For instance in the example above, twelve of sixteen spanning trees are actually paths. 
If you have a path visiting some vertices more than once, you can always drop some edges to get a tree. 
So in general the MST weight is less than the TSP weight, because it’s a minimization over a strictly larger set.
On the other hand, if you draw a path tracing around the minimum spanning tree, you trace each edge twice and visit all points, so the TSP weight is less than twice the MST weight. 
Therefore this tour is within a factor of two of optimal.
-> Indirect applications.
–--> max bottleneck paths
–--> LDPC codes for error correction
–--> image registration with Renyi entropy
–--> learning salient features for real-time face verification
–--> reducing data storage in sequencing amino acids in a protein
–--> model locality of particle interactions in turbulent fluid flows
–--> autoconfig protocol for Ethernet bridging to avoid cycles in a network
-> Cluster analysis
–--> k clustering problem can be viewed as finding an MST and deleting the k-1 most expensive edges.




