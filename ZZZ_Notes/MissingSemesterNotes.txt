Virtual Machines

-> What are VMs?
---> Simulated computers
---> Lets you run an entire OS and bunch of software thats isolates your host environment
---> Its configurable. So you can set your how much resources can be used in the VM.

-> Usage of VMs
---> You can use it to experiment with the OS and new software without any risks.
---> You can use it for applications that run in a specific operating system.
---> You can use it for buggy and malicious software without any risks.
-----> VMs can give pretty good isolation to the host environment

-> One example of a VM is the "Virtual Box"

-> Snapshots
---> One cool thing you can do with VMs is the "snapshot".
---> "Snapshot" are captured data of the entire machine state (everything from the disk, the memory and what is in CPU registers)
---> Since the entire VM is simulated you can freeze it and collect data of its state.
---> Useful if you want to do something that is really dangerous and you dont want to break anything.
-----> For example: Manually delete you boot disk. You can undo by loading again a previous snapshot.

-> Guest addons
---> Makes it easier to communicate with the host machine.
-----> Examples:
-------> Clipboard usage
-------> Drag files in and out of the VMs with the host machine

-> How are they implemented?
---> It simulation of the various HW (memory/disk).
---> It has big interpreter that simulates CPU instructions.
---> Modern hardware have actual support for this kind of stuffs.
-----> VMs can be pretty efficient.
-------> There are exceptions like in games using the video card.



Containers

-> This is the solution if you have to isolate environments, and they look the same, and you want to share as much as possible (operating system is shared).
---> Instead of using multiple VMs, use multiple containers to reduce redundant work (boot time, operating system resources)
-----> In multiple VMs, we have different instances of the OS and simulated HW.
-----> This has faster/better performance, but has weaker isolation to each containers.

-> Heavily used by:
---> Github
-----> Sending GIT commands to the website typically uses a container.
---> Amazon
-----> Saves time because less setup time (no more OS boot time), instead of having minutes to load, you have seconds to load.
---> Automated testing

-> Containers can only be executed in a machine that has a similar configuration.
---> If you want to run a windows container on a linux machine, you need to run these containers in a VM.

-> Examples:
---> Docker
---> RKT/Rocket
---> LXC/Linux container stack
---> Amazon fire crackers
---> Used on hosting website (having a base container with its dependencies setup hastens the deployment of a website)

-> Underneath
---> Its just like running the application but there are jail/fences to make it think that its running alone.  
-----> APIs called to the operating system are hacked so that we can make the application isolated to the rest of the system.



Shell and scripting

-> Shell is really efficient textual interface to your computer.
---> You can do almost anything in the shell.

-> Common shortcuts:
---> CTRL+L - lets you clear your screen
---> CTRL+R - autocomplete based on bash history
---> CTRL+A - jumps to the start of the current line
---> CTRL+E - jumps to the end of the current line

-> Common commands
---> mkdir
---> cd
---> ls
---> mv
---> cp
---> touch - create an empty file
---> which - lets you know the location of application
---> chmod - change permissions. chmod +x hello.sh

-> Shell provides you more than commands
---> You can invoke any program in your computer
---> Command line tools exist for pretty much anything you may want.
---> More efficient than their GUI counterparts.

-> Shell provides an interactive programming language (often referred to as scripting)
---> A lot of different shells that have different languages.
-----> Examples: sh, bash (born again shell), csh (c shell, looks like c language), fish, zsh, ksh

-> Shell programming is useful tool
---> You can write commands in the command line.
---> You can also stick this commands into a file.
-----> Create a .sh file
-----> At the top of the file, add this: "#!/bin/sh" or "#!/bin/bash"
-------> This is known as a hash bang line.
-------> This feeds the entire contents of the file to the program mentioned in the hash bang line.
-------> Also works in python: "#!/usr/bin/python"

-> Loops
---> for i in $(seq 1 5); do echo hello; done
-----> This reads: For i in list (1 to 5); 
-----> Note: New lines are semicolon and semicolons are new lines (they are interchangable)
-----> Note: Bash has no curly brackets, it usually instead have unique keyword for starting and ending a block ("do" and "done" in this case)
-----> Note: The list is actually just space separated.
-------> All the command "seq 1 5" does is to just print 1 to 5
-------> So this for command is just gonna assign i for every space separated value on the list.

-> Program substitution
---> Note: This part "$( )" is also known as program substitution.
-----> Basically what it does is just run whatever command is inside the parenthesis, and the output of the command is replaced where "$( )" is.
-----> So this means that this loop "for i in $(seq 1 5);" is the same as "for i in 1 2 3 4 5;"
-------> So what bash does is:
---------> Put 1 2 3 4 5 (with white space) in the loop command
---------> Assign i for each of the value
---------> Run the body of the loop (after do keyword)

-> Path variable
---> In the previous example, echo is just a program
-----> In fact run: "which echo" -> and it will print the location of echo command ("/usr/bin/echo")
---> All the commands that dont need the absolute directory (like echo), are found using the variable called $PATH 
---> $PATH is colon separated list of directories where your shell looks for programs.

-> Another loop example
---> for f in $(ls); do echo $f; done
-----> This prints all files/directories listed in the directory.

-> Variable
---> For loop assignment works: "for f in $(ls)"
---> Setting a value also works: foo=bar
-----> echo $foo -> this prints -> bar
-----> Note that bash is really picky about the syntax so this will not work: "foo = bar"
-------> This means run the program "foo", with the first argument "=", and the second argument "bar"

-> Special variables:
---> $0 is the name of the current program
---> $1 to $9 are the arguments given to the program
---> $# is the number of arguments
---> $$ is the Process ID of the current shell 
---> $? is the current exit code
---> $! is the Process ID of the last run process

-> Loop example with if statement
---> for f in $(ls); do if test -d $f; then echo dir $f; fi; done
-----> This prints only the directories listed in the directory.
-----> This follows the form: if CONDITION; then BODY; fi
-----> Every program you run in the command line will exit with an exit code
-------> $? has the current exit code
-------> In general, every non zero exit code is a failure and zero means success.
-----> The if statement just runs the command in the CONDITION, and if the exit code is zero it will run the BODY.
-----> The "test" command has applications (strings, integers, file) and in general it just test the condition and exit with an exit code depending on its usage.
-------> Check the manual for "test" for more information
---> "elif" and "else" are also some keywords you can use

-> Open and close square brackets ([])
---> Open square bracket program is just the same with the test command (check manual of test)
---> Close square bracket is just an argument to opern square bracket program on your machine.
---> Open square bracket program requires that the last argument of the program is a close square bracket
---> You can do this(equivalent to the previous example): for f in $(ls); do if [ -d $f ]; then echo dir $f; fi; done
---> Open square bracket is just a program on your machine.
-----> In fact run: "which [" -> and it will print the location of echo command ("/usr/bin/[")

-> Problem with white spaces
---> This loop is problematic: "for f in $(ls)", because if something is named with a whitespace it will in different entries.
-----> Having a folder with a name "My Documents" will have two separate entries: "My" and "Documents"
---> This is really big source of bugs in bash.
---> You can fix this problem by wrapping it in quotations and using globbing
-----> Original: for f in $(ls); do if [ -d $f ]; then echo dir $f; fi; done
-----> Fixed: for f in *; do if [ -d "$f" ]; then echo dir $f; fi; done
-------> Notice you need to wrap it in quotations on the parameter given in the "[" program ("[" only expects one filename)
-------> Notice globbing is used in the loop assingment

-> Problem with new lines 
---> Newlines are generally stored as carriage return, which forces the cursor at the back of the line.

-> Globbing
---> "*" lets you match any string of characters that are files/directories in the current directory
-----> "ls *" will list all files/directories 
-----> "echo b/c/*.txt" will display all txt files in "b/c" path
---> "?" lets you match any single character
-----> "ls ???" will list any files/directories with 3 characters
---> "{}" lets you match two conditions
-----> "ls {b,r}*" will list any files/directories that starts with a "b" or "r"
-----> this expands to "ls b* r*"
-------> note that "mv aaa(.txt)" -> expands to "mv aaa aaa.txt" -> which renames aaa to aaa.txt
-----> "touch {a,b}{a,b}.txt" lets create 4 empty files
-------> aa.txt, ab.txt, ba.txt, bb.txt
---> "**" lets you match any path
-----> "echo **/*.txt" will display all txt files in all paths in the current directory

-> Globbing examples with loop statement
---> for f in a*; do if [ -d "$f" ]; then echo dir $f; fi; done
-----> This loops for any files/directories that starts with "a"
---> for f in foo/*.txt; do if [ -d "$f" ]; then echo dir $f; fi; done
-----> This loops for any ".txt" file that starts with inside the directory "foo"
---> for f in foo/*.txt; do if [ -d "$f" ]; then echo dir $f; fi; done
-----> This loops for any ".txt" file that starts with inside the directory "foo"

-> Problem with white spaces
---> When no argument is given $1 to $9 expands to nothing (not a null string)
-----> This causes a lot of bash script errors.
-----> Example: if [ $1 = "bar" ]
-------> If there is no argument, this expands to: if [  = "bar" ]
---------> This flags an error if run.
-------> Common hack is: if [ x$1 = "xbar" ]
-------> Or use this bash fix ("[[", "]]") : if [[ $1 = "xbar" ]]
---------> Cannot be used in "sh"

-> Composability
---> The shell is powerful because it lets compose multiple programs.
---> You can chain multiple programs together.
---> The character for doing this is pipe "|"
-----> For example: "a | b" this means:
-------> Run "a"
-------> Run "b"
-------> Send all the output of "a" as input to "b"
-------> Print the output of "b"
---> All processes you launch has basically 3 streams
-----> input stream or stdin
-----> output stream or stdout
-----> error stream or stderr
-----> For example: "a | b" also means:
-------> Change stdout of "a" to be equal to stdin of "b" 
-------> So its not depedent on your input anymore, but rather the output of preceeding program

-> cat command
---> This command just prints its input.
---> This command just reads from stdin and writes to stdout

-> ">" means to write the output stream into a file
---> cat > file.txt
-----> This writes to file with the output of cat. 

-> "<" means to read a file and put to stdin
---> cat < file.txt
-----> This reads from file as the input of cat. 

-> Example: cat < in.txt > out.txt
---> This reads from in.txt and writes to out.txt
---> This is basically copy.

-> "2>"
---> Redirects stderr

-> "&>" 
---> Redirects everything

-> grep examples:
---> ls | grep o
-----> This display every file/directory with an "o" in it.
---> ls | grep [REGEX EXPRESSION]
-----> This display every file/directory that satisfies the regex expression
---> journalctrl -b | grep -i kernel | tail -n5
-----> This displays the last file lines of boot log with the word "kernel" on it.

-> sendmail examples:
---> who | sendmail -t me@example.com
-----> This sends an email containing the current users of the machine.

-> (;) lets you combine outputs
---> (who; ps aux) | grep jon | head -n 5
-----> This shows the current users of the machine and the process report containing the word "jon" and just shows the first 5 lines.

-> Process substitution
---> Lets you want to find the difference between the boot logs.
-----> You can do this:
-------> journalctl -b -1 > LastBoot.txt
-------> journalctl -b -2 > SecondToTheLastBoot.txt
-------> diff -u LastBoot.txt SecondToTheLastBoot.txt
-----> Better way is:
-------> diff -u <(journalctl -b -1) <(journalctl -b -2)
---------> diff needs 2 file names
---------> bash starts both journalctl commands and creates sort of temporary files for the result of each
---------> The output of both "<(journalctl -b -1)" and "<(journalctl -b -2)" are the file names of the temporary files
-----------> In fact this command prints the filenames: echo <(journalctl -b -1) <(journalctl -b -2)
---> NOTE: journalctl shows OS activity

-> Running things on the background
---> The ampersand "&" suffix tells bash to run it in the background
-----> For example: "./server &"
-------> Runs the server in the background
-----> The output of this contains the job number and the process id.
-------> For example: "[1] 19436"
---------> It has a job number of 1 and process id of 19436
---> The command "jobs" list all the jobs started with &
---> The command "fg" can run it in the foreground.
-----> For example: "fg"
-------> Puts the most recent process to the foreground
-----> For example: "fg %1"
-------> Puts the process with job number 1 to the foreground
---> The command "bg" can run it in the background.
-----> For example: "bg %1"
-------> Puts the process with job number 1 to the background
---> CTRL+Z stops the current process and put in the background
-----> You need to run bg to start it again.
---> Note: If you close the shell, you are also closing all the background jobs.
---> The command "disown" will let the background processes continue on even if shell is closed
-----> For example: "disown %1"
-------> The process with job number 1 will continue to run even if shell is closed.

-> Tail follow example:
---> Create file count.sh that has this line (this will count to 1000 per second):
-----> "for i in $(seq 1 1000); do echo hello; sleep 1; done"
---> Run count.sh in the background and put its output to a file
-----> "./count.sh > count.log &"
---> Use tail to display the latest values
-----> "tail -f count.log"
-----> -f means follow and this continuously prints the lines in the file

-> Processes commands
---> ps 
-----> lists the running process from the current user of the machine
---> ps -A
-----> lists the running process from all users on the machine
---> pgrep -af server
-----> list all the running process with word "server" on it 
---> pstree
-----> lists the running process in a tree
---> kill
-----> sends a signal to a process
---> pkill 
-----> sends a signal to process the matches the pgrep
-----> These are similar: 
-------> pkill server
-------> kill &(pgrep server)
---> kill -l
-----> lists all the signals that kill can send
-------> default is SIGKILL(9), which tells the process to exit right now
---> kill -s TERM 20156
-----> tells process with pid 20156 to exit politely
-----> SIGTERM tells the process to exit, equivalent to CTRL+C
-----> SIGKILL tells the kernel to forcefully exit the process, equivalent to CTRL+\

-> Common meanings of flags
---> Note: You can combine flags:
-----> "-v -v" is equivalent to "-vv"
---> "-h" or "--help" shows help contents of the command (short version of the man page)
---> "-v" or "--verbose" shows verbose output
---> "-vv" shows more verbose output (pass multiple -v for more verbose output)
---> "-V" or "--version" shows the version
---> "-a" or "--all" means all
---> "-f" or "--forced" means forced
---> "--" means after this you should not interpret arguments as a flag
-----> If you want to create "-a" file, instead of "touch -a", do "touch -- -a"



Command line environment

-> Aliases
---> Create an alias for a command.
---> You can do this:
-----> alias l2="ls -l"
-----> l2
---> You can shorten git status:
-----> alias gs="git status"
-----> gs
---> You can know what is being aliased using "which" command:
-----> which l2
---> Aliases can be compounded:
-----> alias l3="l2 -a"
---> Aliases can be overwritten, for example its completely legal to do this:
-----> alias ls=l3
-------> ls expands to l3, l3 expands to "l2 -a", l2 expands to the command "ls -l"
---> You can call the non-aliased command using back slash:
-----> \ls
---> You can call the non-aliased function using "command":
-----> command ls
---> You can remove the alias by using "unalias"
-----> unalias ls
---> Note: Aliases needs to be done everytime a new command line session is started
-----> You can add it to .bashrc or .bash_profile.
-----> It might be a good idea to use source:
-------> source ~/.aliases

-> Autocomplete works

-> You customize the font, the color, of the terminals.

-> tmux command
---> terminal multiplexer
---> Check the configuration file .tmux.conf at home directory
---> This is very handy for checking server and client. Both are running in parallel and you can check the status for each one.

-> autojump command
---> helps you jump to a path based from history

-> ranger command
---> ranger is a console file manager with VI key bindings. 

-> bat
---> similar to cat but more beautiful (has syntax highlighting, git integration and line numbers) 

-> find command
---> find . -name
---> find is very verbose
-----> fd command is much more helpful

-> rg command
---> regrep
---> search for a string in a file

-> fzf command
---> grep on the go
---> ps aux | fzf
-----> this lets you grep in real time

-> trash command
---> lets delete a file and move to trash

-> aunpack command
---> instead of knowing the commands on tar, use this command and it will figure it out

-> rsync command
---> lets you copy files
---> Rsync is a fast and extraordinarily versatile file copying tool.
---> Rsync is widely used for backups and mirroring and as an improved copy command for everyday use. 



Data wrangling

-> Data wrangling means you want to transform a bunch of text (usually you want less text).
---> grep and | are examples of data wrangling

-> ssh tsp journalctl > tsp.log
---> just for demo (in case network cuts out)
---> you can also just pipe it directly
-----> ssh tsp journalctl | [insert command]

-> cat tsp.log | grep sshd | "Disconnected from"
---> shows disconnected users
---> but needs to remove other "crap" from the line
-----> you can use "sed"

-> sed
---> streaming editor that lets give commands to edit a line of text

-> tail
---> lets you output the last few lines

-> head
---> lets you output the first few lines

-> cat tsp.log | grep sshd | "Disconnected from" | sed 's/.*Disconnected from //' | tail -n5
---> "s" in the sed command means substitute
-----> substitute the pattern on the between the first and second slash with the contents between the second and third slash
-------> /[pattern to match]/[text to replace]/
-------> The pattern can be a regular expression.
---> This means substitute any string characters before and including "Disconnected from" with nothing.

-> Regular expression quick reference:
---> "." means any single character
---> "*" means zero or more preceeding pattern
---> "+" means one or more preceeding pattern
---> "?" means zero or one
---> "[]" means any of the specified characters 
-----> "[abc]" means "a" or "b" or "c"
-----> "[0-9]" means 0 to 9 (ranges can be used as well)
-----> "[^ ]" means any character that is not a space
---> "|" means or condition
-----> "(P1|P2)" means any string of characters that match pattern 1 or pattern 2
---> "^" means start of line
---> "$" means end of line
---> ".*" means zero or more of any character


-> NOTE: Regular expressions are greedy by default. This match as much possible with the pattern used.

-> NOTE: You need to put a black slash when you are using special character when substitute in sed.
---> sed 's/a*+|(c|d)//'
-----> Needs to be transformed to: 
-------> sed 's/a\*\+\|\(c\|d\)//'
-----> Or you can use -E: 
-------> sed -E 's/a*+|(c|d)//'

-> NOTE: Regular expressions are greedy by default. This match as much possible with the pattern used.
---> You can use perl with sed as alternative.

-> cat tsp.log | grep sshd | "Disconnected from" | sed -E 's/.*Disconnected from (invalid |authenticating )?user//' 
---> This matches more with the given pattern.
---> The username is now first in the output.

-> cat tsp.log | grep sshd | "Disconnected from" | sed -E 's/.*Disconnected from (invalid |authenticating )?user .+ [^ ]+ port [0-9]+( \[preauth\])?$//' 
---> This matches more with the given pattern.
---> This will result in blank lines, you need to get the user part(see next example)
---> "[^ ]" means any character that is not a space (check regular expression quick reference)

-> cat tsp.log | grep sshd | "Disconnected from" | sed 's/.*Disconnected from (invalid |authenticating )?user .+ [^ ]+ port [0-9]+( \[preauth\])?$//' 
---> This will result in blank lines, you need to get the user name part(see next example)
---> "[^ ]" means any character that is not a space (check regular expression quick reference)

-> cat tsp.log | grep sshd | "Disconnected from" | sed -E's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' 
---> "\2" means the second capture group
------> any pattern that is enclosed with parenthesis is a capture group (saved by the engine)
------> parentheses were wrapped in "(.+)" to capture it
------> by putting "\2" between the second slash and third slash in sed, we can replace the whole line with the username part
---> If we have a username "Disconnected from", since we have an exact regex of the line, it needs to match the whole line, so "Disconnected from" username will still be in the output.

-> NOTE: Email regex
---> https://emailregex.com/
---> This is aligned with the RFC (its noted on the site which version).

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
---> removed the redundant grep commands
---> "-e" lets you add multiple expressions on the sed, each expression just needs to be prefixed with "-e"
---> "'/Disconnected from/!d'" means dont delete the line with "Disconnected from"

-> wc
---> lets you output the word count

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log  | wc -l
---> gives the number of usernames
---> "wc -l" prints only new line counts

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log | sort | uniq | wc -l
---> gives the number of unique usernames
---> "sort" will sort lines
---> "uniq" will only give unique lines in sorted list

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log | sort | uniq -c | sort -n -k1,1 -r
---> gives number of occurrences and unique usernames, with the most frequent usernames at the beginning
---> "sort -n -k1,1 -r"
-----> "-n" means sort by numerical order
-----> "-k" means sort only on given fields 
-------> "-k1,1" means sort only starting from the first column field until the first column field (so sort only on the first column field)
-------> example: "-k1,3" means sort on the first three columns
-------> example: "-k3,3" means sort on the third column
-----> "-r" means reverse sort (put the highest number of occurrences first)
-------> you can also pipe it to "tac", which prints in reverse order
---> "uniq -c" outputs both the number of occurrences and the name

-> awk
---> another stream editor per line (similar to sed)
---> you want sometimes to use awk instead of sed because awk knows about fields
---> line oriented
---> every command of awk has a optional [PATTERN] followed by a {BLOCK}
-----> If this pattern matches then execute the code on this block.
---> special variables:
-----> $0 is the entire line
-----> $1 is the first field
-----> $2 is the second field
---> by default, awk will split by whitespace  
-----> you can also use the -F flag
-------> "awk -F," means split by comma (useful for csv files)
-------> "awk -F$'\t'" means split by tab
---> awk is a programming language

-> paste
---> takes inputs as lines and paste them together

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | awk '{print $2}' | paste -sd,
---> this generates a comma separated list of usernames, as sorted with the most frequent usernames at the beginning
---> "awk '{print $2}'" get only the second field (the username)
---> "paste -sd," means list them as comma separated
-----> "-d" "--delimiters=LIST"
-------> reuse characters from LIST instead of TABs
-----> "-s" "--serial"
-------> paste one file at a time instead of in parallel

-> ps aux |  awk '$1 ~ /root/ && $2 > 2000 {print $9}' 
---> this prints the time of processes that has user "root" with process id greater than 2000

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | awk 'BEGIN {rows = 0} $1 != 1 && $2 ~ /^c/ {rows += $1} END {print rows}' | paste -sd+ | bc -l
---> this gives the number usernames that are used more than once that starts with the letter c
------> "$1 != 1" means that the username is used more than once (occurrence is not one)
------> $2 ~ /^c/ means start with the letter c

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | awk '{print $1}' | paste -sd+ | bc -l
---> instead of using "wc -l", this adds the number of occurrences (by listing the occurrences with plus as delimeter and adding them in a calculator)

-> echo "2*($(sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | awk '{print $1}' | paste -sd+))" | bc -l
---> this multiplies the total number of occurences to two
---> NOTE: This uses process substitution.

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | awk '{print $1}' | R --slave -e 'x <- scan(file="stdin", quiet=TRUE); summary(x)'
---> this pipes the number of occurrences to R, and then prints a summary of the data

-> sed -E -e '/Disconnected from/!d' -e 's/.*Disconnected from (invalid |authenticating )?user (.+) [^ ]+ port [0-9]+( \[preauth\])?$/\2/' tsp.log 
| sort | uniq -c | sort -n -k1,1 -r | gnuplot -p -e 'set boxwidth 0.5; plot "-" using 1:xtic(2) with boxes'
---> this pipes the number of occurrences and usernames to gnuplot, and then shows a box plot of it

-> rustup
---> manages your rust installations

-> rustup toolchain
---> shows rust installations

-> xargs
---> lets convert the input as arguments to a command
---> echo "hello" | xargs echo 
-----> this lets you pass "hello" as an argument to echo

-> rustup toolchain list | grep nightly | grep -vE 'nightly-x86' | sed 's/-x86.*//' | xargs rustup toolchain uninstall
---> lets you delete all rust toolchain that match the regex pattern (so you dont have to call it one by one)
 
-> cat /usr/share/dict/words
---> contains a list of words 

-> rustup has this installation guideline:
---> Run the following in your terminal: curl https://sh.rustup.rs -sSf |sh
-----> Dont do this! This is downloading a script on the internet and running it to your shell.

-> pup
---> input an html to it and it can give certain details

-> curl -s https:// news.ycombinator.com/ | pup 'table table tr:nth-last-of-type(n+2) td.title a'
---> get a link from a table using curl and pup

-> jq
---> jq is tool for operating json files 




Editors

-> vim
---> vim vs emacs (very heated topic)
---> More info on: https://en.wikipedia.org/wiki/Editor_war
---> Powerful text editor

-> Learning materials
---> vimtutor
-----> probably already installed in your pc if it has vim
-----> http://www2.geog.ucl.ac.uk/~plewis/teaching/unix/vimtutor
-----> The approximate time required to complete the tutor is 25-30 minutes, depending upon how much time is spent with experimentation.
---> vimadventures
-----> https://vim-adventures.com

-> nano
---> simple to use
---> its great to use when you dont to use anything else
---> its great when you dont have anything else to use and just have to create a small change
---> its not great to use when you want to create complicated programs (no great support to change anything densy)

-> vim is a modal editor
---> We typically dont write essays when we code. We just peruse the code and change some line and peruse again and change line again. 
---> So in Vim, there is a concept of modes. The entire tool can be in different modes designed to create this kind of things.
---> There is a mode of inserting text, but there is a mode of viewing the file, and manipulating the file in different ways.
---> "Normal mode" is just viewing the file and manipulating the file in different ways.

-> vim is programmable
---> vim can be programmed using vimscript
-----> you can customize a lot of aspects of this tool by writing in vimscript
-----> you change the configuration and write programs and plugins
---> the interface is also like a programming language
-----> the way you move the cursor around and make changes to a file also is through a sequence of commands (usually thru key strokes)
-----> the commands are composable
-------> you can combine "movement commands" and "editing commands" to create a "compound command"
-------> Example: you can combine the command "to go forward by a word" with the command "to change something" means you can "replace the word"

-> we dont want to use the mouse to navigate
---> its imprecise and very slow
---> we just use the keyboard
---> the editor should work on the speed you think

-> Modes:
---> shown the at the bottom-left of vim
---> if nothing is shown then you are in normal mode
---> Keystrokes:
-----> 'esc' takes you back to "normal mode"
-----> 'i' takes you to "insert mode"
-------> you can type in text
-----> 'v' takes you to "visual mode"
-------> you can select a bunch of text
-----> 'V' takes you to "visual line mode"
-------> you can select a block of text by lines
-----> 'ctrl+v' takes you to "visual block mode"
-------> you can select a block of text

-> X-commands (in normal mode)
---> if youre in normal mode, you press colon (you can see that cursor jump down to the bottom-left)
---> Basic X-commands:
-----> ':q' means quit
-----> ':w' means write (means save the file)
-----> ':wq' means write then quit
-------> ':x' means write then quit as well (save so much time by avoid one character lol)
-----> ':e' means edit
-------> if you give it a name, you can edit that file (vim can have many buffers open)
-----> ':ls' means list the buffers open
-------> it will show you the files you have open
-----> ':bn' means go to the next buffer
-----> ':h' means help 
-------> ":help write" shows the help contents of the write command
-------> ":help w" shows the help contents of the "w" keystoke (move words forward)

-> Moving around the file (in normal mode)
---> You can disable the arrow keys when using vim to avoid bad habits.
-----> vim ~/.vimrc
-------> ".vimrc" is the configuration file
-------> put these lines on the file:
----------> nnoremap <Left> :echoe "Use h" <CR>
----------> nnoremap <Right> :echoe "Use l" <CR>
----------> nnoremap <Up> :echoe "Use k" <CR>
----------> nnoremap <Down> :echoe "Use j" <CR>
---> Keystrokes:
-----> 'w' move forward by words (beginning of word)
-----> 'b' move backward by words (beginning of word)
-----> 'e' move forward by words (end of the word)
-----> '0' moves at the start of the line
-----> '$' moves at the end of the line
-----> '^' moves at the start of the nonwhitespace character of the line
-----> 'H' goes to the top of the screen 
-----> 'M' goes to the middle of the screen 
-----> 'L' goes to the bottom of the screen  
-----> 'ctrl+d' goes down by a page 
-----> 'ctrl+u' goes up by a page 
-----> 'gg' moves at the beginning of the file
-----> 'G' moves at the end of the file
-----> ':[linenumber]' can get you to the exact line number of the file
-----> '%' move to the corresponding item (for example in a parenthesis block, it will go the start of the parenthesis)
-----> 'f' and then 'character' means find (search forward) the first occurrence of that character
-----> 'F' and then 'character' means find (search backward) the first occurrence of that character
-----> 't' and then 'character' means jump to (search forward) the first occurrence of that character (one character before the searched character)
-----> 'T' and then 'character' means jump to (search backward) the first occurrence of that character (one character before the searched character)
---> Composability of keystrokes:
-----> '5' then 'j' means go down 5 times
-----> '3' then 'w' means move forward by 3 words

-> Searching (in normal mode):
---> Type in '/' and the cursor moves at the bottom-left of the screen and you can regex search to the next occurence of the regex hit
-----> 'n' mean next occurence (this is after performing the regex search)

-> Modifying the file (goes into insert mode)
---> 'i' for insert
---> 'a' for append

-> Selecting a block of text (visual mode)
---> You can still use the movement keystrokes you can use in normal mode.

-> Deleting text
---> Can be composed with movement keystrokes:
-----> 'd' then 'e' means delete to the end of the word
-----> 'd' then '$' means delete to the end of the line
-----> 'd' then '0' means delete to the start of the line
-----> 'd' then '^' means delete until the non white space character at the start of the line
-----> 'd' then '3' then 'j' means delete three lines down
-----> 'd' then '3' then 'w' means delete the next three words
-----> 'd' then 'l' means delete one thing to the right
-----> 'x' means delete the character on the cursor
---> note: this also can be done in the visual modes

-> Changing text (goes into insert mode)
---> Can be composed with movement keystrokes:
-----> 'c' then '3' then 'w' means delete the next three words and then go to insert mode
---> Substitute:
-----> 's' means delete the character on the cursor and go to insert mode
--------> equivalent to 'd' then 'l' then 'i'
---> Flip the case:
-----> '~' means flip the case the character on the cursor and move to the right
--------> '3' then '~' changes 3 characters
---> note: this also can be done in the visual modes

-> undo and redo
---> 'u' to undo
---> 'r' to redo

-> ".vimrc"
---> can configure tons of things (syntax highlighting, backspace usage etc)
---> look for inspiration from other people in github

-> Search and replace
---> ':%s/foo/bar/g' this means regex search for "foo" replace with "bar" globally in the file
-----> http://vim.wikia.com/wiki/Search_and_replace
-----> "\1" means the replace with the captured text in the parenthesis (similar to sed)

-> Split windows
---> ':sp' means split to multiple windows of the same file
-----> what if you want to see the top line of text and bottom line of text at the same time

-> Macros
---> 'q' then 'any letter' and it will record a macro under that letter
---> '@' then 'any letter' replays the macro
---> Example: You can change an xml file into a json file.




Dotfiles

-> Intro
---> A lot of command-line programs are configurable using Dotfiles
---> The reason they are called Dotfiles because they have a dot in the name (make sense lol).
---> Dotfiles are hidden by default
-----> This was actually a bug on "ls" implementation (dotfiles have a conflict on folders("." and "..")).
---> Different tools are configured in different ways, you need to read that tools documentation to edit dotfiles.

-> Examples of Dotfiles:
---> .vimrc (vim is configurable using vimscript)
---> .gitconfig (not a program but just a file format where you can set different values)
---> .bashrc
---> .emacs
---> .vim

-> Advice: Avoid directly copying other peoples Dotfiles/configuration
---> You should set your configuration that suits your needs not other people.

-> Goals on handling Dotfiles
---> Easy to install
-----> Example: You should be able to just checkout a git repo, run a single script and you're good to go.
---> Portability
-----> Configuration should be one and be same everywhere so you can synchronize back and forth. 
---> Track changes your on configuration
-----> Keep it under version control (git for example).

-> How do achieve this different things?
---> (1) Have a single folder that have your configuration.
---> (2) Have this folder on version control (git public repo is recommended)
---> (3) Have a single script setup so when you run that script
---> Note: Dont make your home folder (where all the configuration files are located) a git repository
-----> Bad idea because other files are in there, not just configuration files.

-> Some commands to get you started:
---> mkdir dotfiles
---> cd dotfiles
---> git init
---> touch bashrc // Just an example
---> // Edit configuration file
---> // You can use copy: cp bashrc ~/.bashrc, but use symbolic links instead.
---> ln -s /tmp/dotfiles/bashrc ~/.bashrc   // create symbolic link
---> ll ~/.bashrc // list and show the links on the current directory
---> // You can also create an install script (filename: install):
---> // touch install
---> // chmod +x install
Bash install script (filename: install):
-> #!/usr/bin/env bash
-> BASEDIR=$(dirname $0)
-> cd $BASEDIR
-> 
-> ln -s ${PWD}/bashrc ~/.bashrc || true
-> ln -s ${PWD}/vimrc ~/.vimrc || true
-> ...
---> NOTE: There are better script than this.

-> Portability
---> There are slight diferrences in different machines.
-----> (1) Add conditionals on the Dotfiles itself if its programmable
-------> You have to make sure on how to get the details about the environment as well
-----> (2) Keep common parameters on a dotfile and create a new files for specific parameters and use them depending on the machine.
-------> Example: ".gitconfig" to keep common files, ".gitconfig_local" for local customizations



Backups

-> There are two kinds of people in the world. People who do backups and people who will do backups.
---> It just a matter of time to do backups.
-----> Your drive can fail.
-----> Your laptop can be stolen.
-----> rm -rf *

-> 3-2-1 rule on backups
---> 3 copies, on 2 mediums, and at least 1 is offsite.
-----> You dont want to put all your eggs in the same basket.
-----> Examples: Weekly backups, needs to be separate hard drive or stored in servers

-> 3-2-1:
---> 3 Copies of Data – Maintain three copies of data — the original, and at least two copies.
---> 2 Different Media – Use two different media types for storage. 
-----> This can help reduce any impact that may be attributable to one specific storage media type. 
-----> It’s your decision as to which storage medium will contain the original data and which will contain any of the additional copies.
-----> Consider the cost of media as well
---> 1 Copy Offsite – Keep one copy offsite to prevent the possibility of data loss due to a site-specific failure (house burns down, zombie apocalypse etc).

-> Test your backups are working
---> Its not enough that the script finished. Possible problems:
-----> You dont have correct permissions on the server youre copying to.
---> Infamous story is about the film "Toy story 2", someone deleted the film and its almost lost because the backups werent working.
-----> Backups werent working and it was just lucky that someone copied the data, so it was still saved.

-> Mirroring is not a backup
---> If youre just synching your data somewhere else then its not a back up. 
---> Two disks that mirror each other is not a backup.
---> If you accidentally delete stuff on one, since its synching its deleted on the other one as well.

-> Deduplication
---> Deduplication refers to a method of eliminating a dataset's redundant data. 
---> Use symlinks or hard links to reduce cost

-> Encryption
---> Sometimes sensitive info are stored so you need to secure your data.

---> Example of good backups:
-----> Waybackmachine: https://archive.org/web/
-----> Tarsnap: https://www.tarsnap.com/
-----> Borgbackup: https://www.borgbackup.org/
-----> Restic: https://restic.net/



Automation

-> Suppose you want to run a program at specific time or date or periodically (every min or every hour)
---> Use cron
-----> The cron command-line utility is a job scheduler on Unix-like operating systems. 
-----> Users who set up and maintain software environments use cron to schedule jobs, also known as cron jobs, to run periodically at fixed times, dates, or intervals.
---> Use watch
-----> The watch command is a built-in Linux utility used for running user-defined commands at regular intervals. 
-----> It temporarily clears all the terminal content and displays the output of the attached command, along with the current system date and time.
-----> By default, the watch command updates the output every two seconds. Press Ctrl+C to exit out of the command output.
-----> Simple usage: watch -n [interval in seconds] [command]
---> Use anacron
-----> cron will be not work any more if the machine is turned off
-----> anacron is a computer program that performs periodic command scheduling, which is traditionally done by cron, but without assuming that the system is running continuously. 

-> To know where crontab is:
---> ps aux | grep cron




Machine Introspection

-> Sometimes youre computer misbehaves and sometimes something goes wrong and more often than not you wanna know why.
-> Here is bunch of tools to let know what when wrong, what currently is going wrong and prevent it as being as wrong in the future.

-> First you need privileges.

---> Kernel will not you look the OS state.
---> Need to be root or be part of a group (with access) in the system.

---> "sudo" command lets you run as the root user
-----> Example:
-------> whoami (output is your account name)
-------> sudo whoami (output is root)

---> "visudo" command lets you update the sudoers file
-----> NOTE: It will check if its syntactically correct before you save it

---> "su" command lets you run a new prompt as a new user (if no parameters, then by default its root)
-----> sudo su (lets you run a new prompt as root)


-> Logs and commands to check

---> Folder: /var/log 
-----> This has tons of logs
-----> exa /var/log (exa is improved file lister better than ls)
-----> "Xorg" -> logs when X fails
-----> "private" -> logs for user application failures (example: web servers failures)

---> dmesg
-----> This command shows kernel logs
-----> It shows you all the kernel logs since boot

---> journalctl 
-----> This command shows system logs
-----> -u flag gives you all the messages given by this user
-------> journalctl -u systemd-logind
---------> shows you the log of systemd-logind since the beginning of time
-----> -b flag gives you all the message since the last boot (give it a negative number and it will show logs of based on how many previous boots)
-----> -n[NUMBER] flag gives the last NUMBER lines
-----> NOTE: Be careful of piping journalctl sometimes its crops long text to "..."

---> top
-----> This command shows you the processes running on the machine
-----> It show how much memory and cpu the processes are using.

---> htop 
-----> This is better than top because it has a nicer output
-----> It has more graphical representation of things
-----> It shows you the tree of processes (it helps determining which one is subprocess or what)
-------> pstree shows a better output/graph
---------> -p flag shows you the process id 
-----> -t shows process in a tree

---> dstat
-----> This monitors different subsystems on the machine.
-----> This includes network traffic, disk traffic, number interrupts on CPU, context switches, the number of processes, CPU utilization etc.
-----> NOTE: Useful when running a program and it looks that its not making progress, open dstat to check whats happening on your machine

---> df
-----> This useful when looking at disk space
-----> This shows you for all the filesystems you have on your machine: how much space is used? how much space is available? where is it mounted? etc
-----> -h flag shows you in readable numbers (uses M for megabyte and G for giga byte) because by default its in bytes

---> du
-----> This shows you disk usage for particular files.
-----> du *
--------> This shows you usage of files in the current directory
-----> du -h *
--------> This shows you usage of files in the current directory in readable number format (uses M for megabyte and G for giga byte)
-----> du -hs *
--------> This shows you a summary

---> dust
-----> Similar to du, this shows you disk usage for particular files in a tree.

---> ss
-----> This great for networking
-----> This shows you different connections on your machine.
-----> This shows you all open sockets.
-----> ss -t
-------> This shows you TCP connections.
-----> ss -tl
-------> This shows you listening ports in TCP as well.
-----> ss -tlp
-------> This shows you what programs are listening in TCP in my machine.
-----> ss -tlpn
-------> This shows you the actual port number where there are listening.


-> Print the last few messages and dont close (useful for debugging)
---> journalctl -f 
-----> f stands for follow
---> dmesg -w 
-----> w stands for wait
---> for other logs use tail
-----> tail -f [LOG_COMMAND]
-------> f stands for follow
-------> Example: tail -f Xorg.0.log
---> you can also use less
-----> less +F [LOG_COMMAND]
-------> Example: less +F Xorg.0.log


-> Configuration

---> ip
-----> This command is really handy on networking.
-----> ip help
-------> This shows help contents.
-------> This includes grammar on sub commands instead.
-------> Example: ip help addr
-------> However, man pages may provide better explanations.
-----> ip addr
-------> This shows you all the interfaces you have.
-------> "lo" prefix are for loopback, "e" prefix are for ethernet, "w" prefix are for wifi.
-------> This also shows you the IPv4 (under inet) and IPv6 (under inet 6) addresses
-----> ip route
-------> This shows you how your machine is going to communicate.
-------> This also shows you the ipaddress of your router

---> ping
-----> This sends small packets and waits for responses
-----> Example: "ping google.com" "ping 1.1.1.1"
-----> You can try to ping the ipaddress of your router as well (can be found out using ip route).

---> If you have ip issues, you can check /etc/resolv.conf
-----> cat /etc/resolv.conf
-------> This shows you the name server you are using.

---> iptables
-----> This is firewall that uses kernel rules to filter internet traffic.  
-----> It lets you set rules that if packets look a certain way, or from this IP, etc.

---> wireguard
-----> vpn
-----> needs to install

---> systemd
-----> This is useful for configuring/running services
-----> systemd is the system deamon and it manages your system
-----> For every service on your machine, there is a service file.
-------> This maybe under /usr/lib/systemd/system
-------> You can check the file. Example: vim /usr/lib/systemd/system/vboxweb.service
----------> You can see configuration on how that service is run and shutdown.
-----> systemctl
-------> systemctl status
---------> This shows you all the services that are currently running.
-------> To manage services:
---------> systemctl start [UNIT_FILE]
---------> systemctl stop [UNIT_FILE]
---------> systemctl restart [UNIT_FILE]
---------> systemctl enable [UNIT_FILE]
-----------> It will no longer be started on boot.
---------> systemctl disable [UNIT_FILE]
-----------> It will be started on boot.
---------> NOTE: You can use journalctl to investigate if theres a problem in the service (why its not starting?)
-----> systemd-analyze
-------> This shows you how long your boot took.
-------> systemd-analyze blame
---------> This shows you how long does each thing in your boot took.


-> Searching
---> find
-----> find -iname [STRING]
---> mlocate is a package that is installed on most systems
-----> sudo updatedb
-------> This will create an index on your entire filesystem for searching
-----> locate [STRING]
-------> This will show you all the files in your machine that contains the string [STRING] in the path
-----> locate [STRING] | fzf
-------> This can help interactively search.
-----> locate is better than find becaused its indexed


-> Hardware information

---> dmidecode
-----> This parses all the firmware on your machine and tells you what different things are.
-----> This tells you what hardware you are running and all the capabilities that they support.
-----> This probably not that useful unless you are checking firmware upgrades and youre  curious about what CPU you are running. 
---> lstopo
-----> This shows you the entire physical layout of your CPU (including all caches).
-----> This pretty useful when doing performance debugging.
---> hwloc-bind
-----> This lets you run a program on only specific cores.


-> OS/Kernel folders
---> /sys/ and /proc/ are special parts of the filesystem that are managed by the kernel
---> This contain not real files but just meta information that kernel exposes.
---> /sys/
-----> Example:
-------> cd /sys/cla/bac/intel_backlight
-------> echo 500 | sudo tee  brightness
---------> This change the brightness of your laptop.
-----> There tons of things you can do here like change queuing behavior in the kernel, disable safety features like vslr, you can break your system here as well.
---> /proc/
-----> This contains information about the processes.
-----> Example:
-------> cd /proc/6905/
-------> ls -la
-------> cat cwd (shows current working directory) 
-------> cat cmdline (shows command used when its was run) 
---> /boot/
-----> Two important files vmlinuz-linux and initramfs-linux.img.
-------> These are like the boot images for linux.


-> links [URL]
---> This command is like a text web browser that lets you surf the web.




Program introspectation

-> Debugging a program
---> printf style debugging
-----> excellent debugging technique but sometimes its not good enough
---> debugger is a more powerful tool
-----> lets you halt when it reaches a certain line in the code
-----> lets you poke whats in memory
-----> lets you execute the program one line of code at a time


-> Debuggers

---> GDB (GNU debugger)
-----> NOTE: GDB works for c-style languages (like C++, objective C, GO, Rust)
-----> NOTE: GDB will work actually on any executable binary but it needs debug symbols to be able to map it into source code 
-----> Compile with -g flag to include debug symbols:
-------> gcc -g -o example example.c 
-----> Invoke gdb with the program:
-------> gdb example
-----> Run the program (within gdb):
-------> run
-----> Insert breakpoint (within gdb):
-------> b [NAME_OF_FUNCTION]
-------> b [FILE_NAME]:[LINE_NUMBER]
-------> After running when breakpoint is reached, the program halts and gdb console is again available.
-------> NOTE: You call a function when the program halts because of breakpoint (you call printf like functions to print variables).
-------> NOTE: You print the value of the variable when the program halts because of breakpoint 
---------> print [NAME_OF_VARIABLE]
-----> Show current breakpoints:
-------> info breakpoints
-----> Continue execution (usually done when program halts due to breakpoint)
-------> continue
-----> Execute one line and step into function calls
-------> step
-----> Execute one line and skips function calls
-------> next
-----> Step out of the function
-------> finish
-----> Display values at every line executed
-------> display [COMMAND]
-----> Stop execution whenever the program reads from this value
-------> rwatch [EXPRESSION]
-------> Example: rwatch numbers[3]
-------> NOTE: The names used in [EXPRESSION] just needs to be in the current scope where the GDB is running.
-------> NOTE: Underneath, this is implemented thru hardware support that watches memory addresses.
-----> Show stack trace
-------> bt
-----> Setup GDB to be more informative and interactive
-------> layout
-------> layout regs (to show registers as well)
-----> Step to one line of assembly code
-------> si

---> RR (Debugger that lets you go back)
-----> Has rstep and previous
-----> Very useful when the issue is hard to reproduce and you need to know what happened before

---> pdb (python debugger)
-----> Insert this line in the code:
-------> import pdb; pdb.set_trace()
-----> This opens a hybrid GDB like prompt and similar to a python shell
-------> You can write python code in the prompt and it will execute as if its the next line to where its stopped.
-----> ipdb also exists for interactive python

---> Graphical user interfaces for debuggers also exists in web browsers


-> System calls

---> strace
-----> Very useful when doing systems programming
-----> Basically, this runs a program, then for every system call that program makes, it will print the what system call it is and what arguments were given to it
-----> Example: strace echo hi


-> Profiling

---> Another problem for programs is its performance.
---> You are able to investigate why and where its slow.

---> time
-----> Gives you basic information about how long its executed
-----> Gives you information on how much time its spent running on user space vs how much time its running on system calls.

---> perf
-----> See PerformanceNotes.txt(on notes) or Chandler Carruths lecture as well
-----> Record first:
-------> Example: perf record ag -c 'x' . 
-----> Show the results:
-------> perf report
-------> perf stat [COMMAND]
-----> What about small, tight loops?
-------> perf record
-------> perf report
-----> Performance counters
-------> perf stat
---------> check for "stalled cycles"
-------> perf list
---------> list all commands on perf
---------> check for command for cache

---> flamegraphs
-----> Its a really nice profiling graphs.



-> Package and Dependency Management

---> When people write libraries and packages they generally put them on common repository so that people can access them.
---> In python, where people put them is the python package index.
---> In rust, where people put them is crates.io
---> So its pretty language specific, but in general the communities agree on some place to put all the libraries that are written for a certain language.

---> Versioning
-----> Normally its just an consecutive numbers, but we can do better than that.
-----> Git hash commit id can also work, but it does NOT convey any more information.
-----> There is also semantic versioning.
-------> Normally the format is: [MAJOR_VERSION].[MINOR_VERSION].[PATCH_VERSION]
---------> Example: 10.2.4
-------> PATCH_VERSION is incremented on:
---------> If you fix a bug and you're not changing the behavior of anything else, then PATCH_VERSION is incremented.
-----------> So you can use the a new release even if the PATCH_VERSION is increased because there is no new behavior introduced.
-----------> So for example, Version 10.2.5 still works with 10.2.4.
-------> MINOR_VERSION is incremented on:
---------> If you introduce a new feature and youre still making it backwards compatible, then MINOR_VERSION is incremented.
-----------> For example, you introduce a new function/API but you do not change any of the old function/API.
-----------> So for example, Version 10.3.0 still works with 10.2.4.
-------> MAJOR_VERSION is incremented on:
---------> If you introduce a change that is not backwards compatible, then MAJOR_VERSION is incremented.
-----------> So for example, Version 11.0.0 will NOT work with 10.2.4.

---> Cryptographic hashes also work on requiring the exact same version with the exact same binaries
-----> This is prevent attacks from other people.
-----> This is also called "Lock files"
-----> This is also enables several repositories to host the binaries (and not trust just one), because you can check if the hash is the same.

---> Constraints
-----> Minimum minor version
-------> Example: >= 1.2 and < 2.0
-----> Minimum patch version
-------> >= 3.5.4 and < 4.0 
-------> Example: This useful if you need a critical bug fixed.
-----> Exact version
-------> Example: == 1.4.3
-------> This useful if your software relies on some specific behavior on that version.
-------> Or maybe you just dont trust the dependencies to adhere to semantic versioning.

---> Dependency resolution algorithms
-----> This is complicated because the dependencies might rely on other dependencies that already has dependency.
-----> You can also make this problem computationally hard (this is similar to SAT/satifiability problem).
-----> So take note of this when specifying your constraints on versioning of your software.
-------> You dont want to be unecessarily strict on your versioning because it might cause problems somewhere else.

---> Virtual environments
-----> This useful when the conflict on the dependencies cannot be resolved (you need two set of versions for one dependency)
-----> This useful for maintaining several sets of dependencies for maintaining different projects.
-----> NOTE: Rust typically doesnt have this problem because it uses static libaries on its application (so when its run, its not relying on dynamic libaries on the system)

---> Vendoring
-----> Very different approach to dependency management 
-----> Basically, you take all the codes from other dependencies and build everything with your project.
-----> There are some benefits on doing this:
-------> Youre not depending on package repositories anymore.
-------> Youre not relying on dependency resolution anymore.
-------> Its always the same code/behavior everytime.
-----> But there is not sustainable on every project because it will yield to a lot of binary duplications on several applications.
-----> NOTE: This is Google's approach on building its application because the dont want to rely on package repositories and dont want to deal with problems in versioning.



-> OS customizations

---> Keyboard remapping
-----> Youre keyboard has useless keys that are not used all the time.
-------> You should remap them to make them do useful things.

---> Cusomizing hidden OS settings (not shown in the UI of the settings in the OS)
-----> MacOS has the "defaults" command
 
---> Window management
-----> Tiling window management
-------> This sets your windows so that it shows whats needed on you application.
-------> You can bind keys to this as well (so that it will be faster).
-------> MacOS has hammerspoon

---> Check the reddit thread "unixp*rn"
-----> It has screenshots of really cool setups that other people uses.



-> Remote machines

---> To connect:
-----> ssh [NAME]@[IP_ADDRESS OR HOST_NAME]
---> SSH Information are saved in the hidden folder ".ssh".
---> Generating keys
-----> ssh-keygen -t rsa -b 4096
---> Copying keys to the server
-----> ssh-copy-id foobar@172.16.174.149
---> Copying folders to server
-----> scp -r folder1 foobar@172.16.174.149:folder2
-----> rsync -avP folder1 foobar@172.16.174.149:folder2
-----> rsync is better than scp 
-------> scp just copies all the files, while rsync copies only what changed (minimizing the traffic)
-------> rsync has also the capability to resume if the connection drops
-------> https://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync
---> Running processes that wont close if the users logs out
-----> nohup sleep &
-----> nohup is a POSIX command which means "no hang up". 
-----> Its purpose is to execute a command such that it ignores the HUP (hangup) signal and therefore does not stop when the user logs out. 
---> Managing windows inside the terminal
-----> screen
-----> tmux
---> Port forwarding
-----> Can be local port forwarding or remote port forwarding
-----> ssh -L 9999:locahost:8888 foobar@172.16.174.149
-------> Forwarding port 9999 to port 8888
---> Graphics forwarding (similar to remote desktop connection)
-----> ssh -X foobar@172.16.174.149
-----> you can run firefox on this and the graphics of the firefox window in the server will be forwarded to you
---> Handle disconnections better than ssh
-----> mosh foobar@172.16.174.149
-----> NOTE: mosh does not work on port forwarding and graphics forwarding
---> Save configuration of the connection to host (so you dont have to specify all the time)
-----> vim .ssh/config
-----> ssh vm (vm is the host name)
---> Mounting a remote folder to a local folder
-----> sshfs vm:Downloads Downloads
---> Proxy jump
-----> edit ssh config file
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 
---> 














add objdump 
add top
demangle