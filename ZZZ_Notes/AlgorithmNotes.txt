-> Algorithmic analysis

---> It is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. 
-----> Methods have been developed for the analysis of algorithms to obtain such quantitative answers (estimates); 
-----> for example, an algorithm which adds up the elements of a list of n numbers would have a time requirement of O(n), using big O notation. 
-----> At all times the algorithm only needs to remember two values: the sum of all the elements so far, and its current position in the input list. 
-----> Therefore, it is said to have a space requirement of O(1), if the space required to store the input numbers is not counted, or O(n) if it is counted.

---> Different algorithms may complete the same task with a different set of instructions in less or more time, space, or 'effort' than others. 
-----> For example, a binary search algorithm (with cost O(log n)) outperforms a sequential search (cost O(n)) when used for table lookups on sorted lists or arrays.

---> Formal versus empirical

-----> Empirical algorithmics, Profiling (computer programming), and Program optimization

-----> The analysis, and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. 
-------> In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. 
-------> Usually pseudocode is used for analysis as it is the simplest and most general representation. 

-----> However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their algorithmic efficiency is eventually put to the test using real code. 
-------> For the solution of a "one off" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) 
-------> but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. 
-------> Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.

-----> Empirical testing is useful because it may uncover unexpected interactions that affect performance. 
-------> Benchmarks may be used to compare before/after potential improvements to an algorithm after program optimization. 
-------> Empirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.

---> Execution efficiency

-----> To illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, 
-------> relating to FFT algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. 
-------> In general, speed improvements depend on special properties of the problem, which are very common in practical applications.
-------> Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.



-> Classification

---> There are various ways to classify algorithms, each with its own merits.



---> By implementation

-----> (1) Recursion
-------> A recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition (also known as termination condition) matches, which is a method common to functional programming. 
-------> Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. 
-------> Some problems are naturally suited for one implementation or the other. For example, towers of Hanoi is well understood using recursive implementation. 
-------> Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.

-----> (2) Logical
-------> An algorithm may be viewed as controlled logical deduction. 
-------> This notion may be expressed as: Algorithm = logic + control.[74] 
-------> The logic component expresses the axioms that may be used in the computation and the control component determines the way in which deduction is applied to the axioms. 
-------> This is the basis for the logic programming paradigm. 
-------> In pure logic programming languages, the control component is fixed and algorithms are specified by supplying only the logic component. 
-------> The appeal of this approach is the elegant semantics: a change in the axioms produces a well-defined change in the algorithm.
 
-----> (3) Serial, parallel or distributed
-------> Algorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. 
-------> Those computers are sometimes called serial computers. 
-------> An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. 
-------> Parallel algorithms take advantage of computer architectures where several processors canwork on a problem at the same time, 
-------> whereas distributed algorithms utilize multiple machines connected with a computer network. 
-------> Parallel or distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. 
-------> The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. 
-------> Some sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable. 
-------> Some problems have no parallel algorithms and are called inherently serial problems.

-----> (4) Deterministic or non-deterministic
-------> Deterministic algorithms solve the problem with exact decision at every step of the algorithm 
-------> whereas non-deterministic algorithms solve problems via guessing although typical guesses are made more accurate through the use of heuristics.

-----> (5) Exact or approximate
-------> While many algorithms reach an exact solution, approximation algorithms seek an approximation that is closer to the true solution. 
-------> The approximation can be reached by either using a deterministic or a random strategy. 
-------> Such algorithms have practical value for many hard problems. 
-------> One of the examples of an approximate algorithm is the Knapsack problem, where there is a set of given items. 
---------> Its goal is to pack the knapsack to get the maximum total value. 
---------> Each item has some weight and some value. 
---------> Total weight that can be carried is no more than some fixed number X. 
---------> So, the solution must consider weights of items as well as their value.

-----> (6) Quantum algorithm
-------> They run on a realistic model of quantum computation. 
-------> The term is usually used for those algorithms which seem inherently quantum, or use some essential feature of Quantum computing such as quantum superposition or quantum entanglement.



---> By design paradigm

-----> Another way of classifying algorithms is by their design methodology or paradigm. 
-------> There is a certain number of paradigms, each different from the other. 
-------> Furthermore, each of these categories includes many different types of algorithms. 
-------> Some common paradigms are:

-----> (1) Brute-force or exhaustive search
-------> This is the naive method of trying every possible solution to see which is best.

-----> (2) Divide and conquer
-------> A divide-and-conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem 
-------> (usually recursively) until the instances are small enough to solve easily. 
-------> One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data 
-------> after dividing data into segments and sorting of entire data can be obtained in the conquer phase by merging the segments. 
-------> A simpler variant of divide and conquer is called a decrease-and-conquer algorithm, 
-------> which solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. 
-------> Divide and conquer divides the problem into multiple subproblems and so the conquer stage is more complex than decrease and conquer algorithms. 
-------> An example of a decrease and conquer algorithm is the binary search algorithm.

-----> (3) Search and enumeration
-------> Many problems (such as playing chess) can be modeled as problems on graphs. 
-------> A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. 
-------> This category also includes search algorithms, branch and bound enumeration and backtracking.

-----> (4) Randomized algorithm
-------> Such algorithms make some choices randomly (or pseudo-randomly). 
-------> They can be very useful in finding approximate solutions for problems where finding exact solutions can be impractical (see heuristic method below). 
-------> For some of these problems, it is known that the fastest approximations must involve some randomness. 
-------> Whether randomized algorithms with polynomial time complexity can be the fastest algorithms for some problems is an open question known as the P versus NP problem. 
-------> There are two large classes of such algorithms:
---------> Monte Carlo algorithms return a correct answer with high-probability. E.g. RP is the subclass of these that run in polynomial time.
---------> Las Vegas algorithms always return the correct answer, but their running time is only probabilistically bound, e.g. ZPP.

-----> (5) Reduction of complexity
-------> This technique involves solving a difficult problem by transforming it into a better-known problem for which we have (hopefully) asymptotically optimal algorithms. 
-------> The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm's. 
-------> For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion)
-------> and then pulling out the middle element in the sorted list (the cheap portion). 
-------> This technique is also known as transform and conquer.

-----> (6) Back tracking
-------> In this approach, multiple solutions are built incrementally and abandoned when it is determined that they cannot lead to a valid full solution.



---> Optimization problems

-----> For optimization problems there is a more specific classification of algorithms; 
-----> an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:

-----> (1) Linear programming
-------> When searching for optimal solutions to a linear function bound to linear equality and inequality constraints, 
-------> the constraints of the problem can be used directly in producing the optimal solutions. 
-------> There are algorithms that can solve any problem in this category, such as the popular simplex algorithm. 
-------> Problems that can be solved with linear programming include the maximum flow problem for directed graphs. 
-------> If a problem additionally requires that one or more of the unknowns must be an integer then it is classified in integer programming. 
-------> A linear programming algorithm can solve such a problem if it can be proved that all restrictions for integer values are superficial, i.e., the solutions satisfy these restrictions anyway. 
-------> In the general case, a specialized algorithm or an algorithm that finds approximate solutions is used, depending on the difficulty of the problem.
 
-----> (2) Dynamic programming
-------> When a problem shows optimal substructures—meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems—and overlapping subproblems, 
-------> meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. 
-------> For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. 
-------> Dynamic programming and memoization go together. 
-------> The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. 
-------> The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. 
-------> When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. 
-------> By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.

-----> (3) The greedy method
-------> A greedy algorithm is similar to a dynamic programming algorithm in that it works by examining substructures, in this case not of the problem but of a given solution. 
-------> Such algorithms start with some solution, which may be given or have been constructed in some way, and improve it by making small modifications. 
-------> For some problems they can find the optimal solution while for others they stop at local optima, that is, at solutions that cannot be improved by the algorithm but are not optimum. 
-------> The most popular use of greedy algorithms is for finding the minimal spanning tree where finding the optimal solution is possible with this method. 
-------> Huffman Tree, Kruskal, Prim, Sollin are greedy algorithms that can solve this optimization problem.
 
-----> (4) The heuristic method
-------> In optimization problems, heuristic algorithms can be used to find a solution close to the optimal solution in cases where finding the optimal solution is impractical. 
-------> These algorithms work by getting closer and closer to the optimal solution as they progress. 
-------> In principle, if run for an infinite amount of time, they will find the optimal solution. 
-------> Their merit is that they can find a solution very close to the optimal solution in a relatively short time. 
-------> Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms. 
-------> Some of them, like simulated annealing, are non-deterministic algorithms while others, like tabu search, are deterministic. 
-------> When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.



---> By field of study

-----> Every field of science has its own problems and needs efficient algorithms. 
-------> Related problems in one field are often studied together. 
-------> Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, 
-------> computational geometric algorithms, combinatorial algorithms, medical algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.

-----> Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. 
-------> For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.



---> By complexity

-----> Algorithms can be classified by the amount of time they need to complete compared to their input size:
-------> Constant time: if the time needed by the algorithm is the same, regardless of the input size. E.g. an access to an array element.
-------> Logarithmic time: if the time is a logarithmic function of the input size. E.g. binary search algorithm.
-------> Linear time: if the time is proportional to the input size. E.g. the traverse of a list.
-------> Polynomial time: if the time is a power of the input size. E.g. the bubble sort algorithm has quadratic time complexity.
-------> Exponential time: if the time is an exponential function of the input size. E.g. Brute-force search.

-----> Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. 
-------> There are also mappings from some problems to other problems. 
-------> Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.



---> Continuous algorithms

-----> The adjective "continuous" when applied to the word "algorithm" can mean:
-------> An algorithm operating on data that represents continuous quantities, even though this data is represented by discrete approximations—such algorithms are studied in numerical analysis; or
-------> An algorithm in the form of a differential equation that operates continuously on the data, running on an analog computer.[79]



-> List of Algorithms (including my notes)



-> Combinatorial algorithms

---> General combinatorial algorithms

-----> Brent's algorithm: 
-------> This finds a cycle in function value iterations using only two iterators.
-------> This is an alternative cycle detection algorithm that, like the tortoise and hare algorithm, requires only two pointers into the sequence.
-------> It has two advantages compared to the tortoise and hare algorithm: 
---------> It finds the correct length λ of the cycle directly, rather than needing to search for it in a subsequent stage, 
---------> and its steps involve only one evaluation of f rather than three (faster).
------->  Its much faster because it relies on power of two for changing the position of turtoise. 

-----> Floyd's cycle-finding algorithm: 
-------> This finds a cycle in function value iterations
-------> This is tortoise and hare algorithm
-------> This is a pointer algorithm that uses only two pointers, which move through the sequence at different speeds (typically the turtoise moves one and the hare moves two). 

-----> Gale–Shapley algorithm: 
-------> This solves the stable marriage problem
---------> The stable marriage problem is the problem of finding a stable matching between two equally sized sets of elements given an ordering of preferences for each element. 
---------> A matching is a bijection from the elements of one set to the elements of the other set. 
---------> A matching is not stable if:
-----------> There is an element A of the first matched set which prefers some given element B of the second matched set over the element to which A is already matched, and
-----------> B also prefers A over the element to which B is already matched.
-------> In other words, a matching is stable when there does not exist any pair (A, B) which both prefer each other to their current partner under the matching.
-------> The stable marriage problem has been stated as follows:
---------> Given n men and n women, where each person has ranked all members of the opposite sex in order of preference, 
---------> marry the men and women together such that there are no two people of opposite sex who would both rather have each other than their current partners.
---------> When there are no such pairs of people, the set of marriages is deemed stable.
-------> Applications: Algorithms for finding solutions to the stable marriage problem have applications in a variety of real-world situations, 
---------> perhaps the best known of these being in the assignment of graduating medical students to their first hospital appointments
-------> The Gale–Shapley algorithm (also known as the deferred acceptance algorithm or propose-and-reject algorithm) is an algorithm for finding a solution to the stable matching problem.
---------> It takes polynomial time, and the time is linear in the size of the input to the algorithm.
-------> The Gale–Shapley algorithm involves a number of "rounds" (or "iterations"):
---------> (1) In the first round, first 
-----------> a) each unengaged man proposes to the woman he prefers most, and then 
-----------> b) each woman replies "maybe" to her suitor she most prefers and "no" to all other suitors. 
-----------> She is then provisionally "engaged" to the suitor she most prefers so far, and that suitor is likewise provisionally engaged to her.
---------> (2) In each subsequent round, first 
-----------> a) each unengaged man proposes to the most-preferred woman to whom he has not yet proposed (regardless of whether the woman is already engaged), 
-----------> and then b) each woman replies "maybe" if she is currently not engaged or if she prefers this man over her current provisional partner 
-------------> (in this case, she rejects her current provisional partner who becomes unengaged). 
-----------> The provisional nature of engagements preserves the right of an already-engaged woman to "trade up" (and, in the process, to "jilt" her until-then partner).
---------> (3) This process is repeated until everyone is engaged.
-------> The runtime complexity of this algorithm is O(n^2) where n is the number of men or women. 
---------> Since the input preference lists also have size proportional to n^2, the runtime is linear in the input size.
-------> This algorithm guarantees that:
---------> Everyone gets married
-----------> At the end, there cannot be a man and a woman both unengaged, as he must have proposed to her at some point (since a man will eventually propose to everyone, if necessary) 
-------------> and, being proposed to, she would necessarily be engaged (to someone) thereafter.
---------> The marriages are stable
-----------> Let Alice and Bob both be engaged, but not to each other. 
-----------> Upon completion of the algorithm, it is not possible for both Alice and Bob to prefer each other over their current partners. 
-------------> If Bob prefers Alice to his current partner, he must have proposed to Alice before he proposed to his current partner. 
-------------> If Alice accepted his proposal, yet is not married to him at the end, she must have dumped him for someone she likes more, and therefore doesn't like Bob more than her current partner. 
-------------> If Alice rejected his proposal, she was already with someone she liked more than Bob.
-------> Note: The stable marriage problem is also called the stable matching problem or SMP.
 
-----> Pseudorandom number generators:

-------> ACORN generator
---------> The ACORN or ″Additive Congruential Random Number″ generators are a robust family of PRNGs (pseudorandom number generators) for sequences of uniformly distributed pseudo-random numbers, 
---------> The main advantages of ACORN are simplicity of concept and coding, speed of execution, long period length, and mathematically proven convergence.
---------> In testing, ACORN performs extremely well, for appropriate parameters. However in its present form, ACORN has not been shown to be suitable for cryptography.
---------> The ACORN was introduced in 1989 and still valid in 2019, thirty years later. 

-------> Blum Blum Shub
---------> Blum Blum Shub (B.B.S.) is a pseudorandom number generator takes the form:
-----------> x[n+1] = x[n]^2 mod M 
-----------> where M = pq is the product of two large primes p and q. 
-----------> At each step of the algorithm, some output is derived from xn+1; the output is commonly either the bit parity of xn+1 or one or more of the least significant bits of xn+1.
---------> The seed x0 should be an integer that is co-prime to M (i.e. p and q are not factors of x0) and not 1 or 0.
---------> The two primes, p and q, should both be congruent to 3 (mod 4) (this guarantees that each quadratic residue has one square root which is also a quadratic residue),
---------> and should be safe primes with a small gcd((p-3)/2, (q-3)/2) (this makes the cycle length large).
---------> An interesting characteristic of the Blum Blum Shub generator is the possibility to calculate any xi value directly (via Euler's theorem)
---------> Security: There is a proof reducing its security to the computational difficulty of factoring.
---------> Note: The Blum Blum Shub generator wasproposed in 1986 by Lenore Blum, Manuel Blum and Michael Shub that is derived from Michael O. Rabin's one-way function. 

-------> Lagged Fibonacci generator
---------> A Lagged Fibonacci generator (LFG or sometimes LFib) is an example of a pseudorandom number generator. 
---------> This class of random number generator is aimed at being an improvement on the 'standard' linear congruential generator.
---------> These are based on a generalisation of the Fibonacci sequence. 
---------> The Fibonacci sequence may be described by the recurrence relation:
-----------> S[n] = S[n−1] + S[n−2]
---------> Hence, the new term is the sum of the last two terms in the sequence. 
---------> This can be generalised to the sequence:
-----------> S[n] ≡ S[n−j] BinaryOperator S[n−k] ( mod m ), 0<j<k
---------> In which case, the new term is some combination of any two previous terms. 
---------> m is usually a power of 2 (m = 2M), often 2^32 or 2^64. 
---------> The operator denotes a general binary operation. 
---------> This may be either addition, subtraction, multiplication, or the bitwise exclusive-or operator (XOR). 
---------> The theory of this type of generator is rather complex, and it may not be sufficient simply to choose random values for j and k.
---------> These generators also tend to be very sensitive to initialization. 

-------> Linear congruential generator
---------> A linear congruential generator (LCG) is an algorithm that yields a sequence of pseudo-randomized numbers calculated with a discontinuous piecewise linear equation. 
---------> The method represents one of the oldest and best-known pseudorandom number generator algorithms. 
---------> The theory behind them is relatively easy to understand, and they are easily implemented and fast, especially on computer hardware which can provide modular arithmetic by storage-bit truncation.
---------> The generator is defined by the recurrence relation:
-----------> X[n+1] = ( a X[n] + c ) mod m
-----------> where X is the sequence of pseudo-random values, and
-------------> m , 0 < m — the "modulus"
-------------> a , 0 < a < m — the "multiplier"
-------------> c , 0 ≤ c < m  — the "increment"
-------------> X 0 , 0 ≤ X 0 < m  — the "seed" or "start value"
-------------> are integer constants that specify the generator. 
-------------> If c = 0, the generator is often called a multiplicative congruential generator (MCG), or Lehmer RNG. 
-------------> If c ≠ 0, the method is called a mixed congruential generator.[1]: 4- 
-------------> When c ≠ 0, a mathematician would call the recurrence an affine transformation, not a linear one, but the misnomer is well-established in computer science.

-------> Mersenne Twister
---------> The Mersenne Twister is a general-purpose pseudorandom number generator (PRNG)
---------> Its name derives from the fact that its period length is chosen to be a Mersenne prime.
---------> The Mersenne Twister was designed specifically to rectify most of the flaws found in older PRNGs.
---------> The most commonly used version of the Mersenne Twister algorithm is based on the Mersenne prime. 
---------> The standard implementation of that, MT19937, uses a 32-bit word length.
---------> There is another implementation that uses a 64-bit word length, MT19937-64; it generates a different sequence. 
---------> Note: C++ has this random generator.
---------> Note: This was developed in 1997 by Makoto Matsumoto [ja] (松本 眞) and Takuji Nishimura (西村 拓士). 

 

---> Graph algorithms

-----> Coloring algorithm: 
-------> In graph theory, graph coloring is a special case of graph labeling; it is an assignment of labels traditionally called "colors" to elements of a graph subject to certain constraints. 
-------> In its simplest form, it is a way of coloring the vertices of a graph such that no two adjacent vertices are of the same color; this is called a vertex coloring. 
-------> Similarly, an edge coloring assigns a color to each edge so that no two adjacent edges are of the same color, 
-------> and a face coloring of a planar graph assigns a color to each face or region so that no two faces that share a boundary have the same color. 

-----> Hopcroft–Karp algorithm: 
-------> This convert a bipartite graph to a maximum cardinality matching.
-------> The "Maximum cardinality matching" is a set of as many edges as possible with the property that no two edges share an endpoint. 
-------> This is an algorithm that takes a bipartite graph as input and produces a maximum cardinality matching as its output 
---------> It runs in O(|E|sqrt(|V|))) time in the worst case, 
-----------> where E  E is set of edges in the graph, V is set of vertices of the graph, and it is assumed that |E| = Ω (|V|)  .
-----------> In the case of dense graphs the time bound becomes O (|V|^2.5)), and for sparse random graphs it runs in time O (|E| log⁡ (|V|)).
-------> The algorithm may be expressed in the following pseudocode:
---------> Input: Bipartite graph G ( U ∪ V , E )
---------> Output: Matching M is subset of E 
---------> M ← ∅ 
---------> repeat
-----------> P ← { P 1 , P 2 , … , P k }  maximal set of vertex-disjoint shortest augmenting paths
-----------> M ← M ⊕ ( P 1 ∪ P 2 ∪ ⋯ ∪ P k )
---------> until P = nullset
-------> In more detail, let U and V be the two sets in the bipartition of G, and let the matching from U to V at any time be represented as the set M. 
-------> The algorithm is run in phases. 
-------> Each phase consists of the following steps:
-------> (1) A breadth-first search partitions the vertices of the graph into layers. 
---------> The free vertices in U are used as the starting vertices of this search and form the first layer of the partitioning. 
---------> At the first level of the search, there are only unmatched edges, since the free vertices in U are by definition not adjacent to any matched edges. 
---------> At subsequent levels of the search, the traversed edges are required to alternate between matched and unmatched. 
---------> That is, when searching for successors from a vertex in U, only unmatched edges may be traversed, while from a vertex in V only matched edges may be traversed. 
---------> The search terminates at the first layer k where one or more free vertices in V are reached.
-------> (2) All free vertices in V at layer k are collected into a set F. 
---------> That is, a vertex V is put into F if and only if it ends a shortest augmenting path.
-------> (3) The algorithm finds a maximal set of vertex disjoint augmenting paths of length k. 
---------> Note: Maximal means that no more such paths can be added. 
-----------> This is different from finding the maximum number of such paths, which would be harder to do. 
-----------> Fortunately, it is sufficient here to find a maximal set of paths.)
---------> This set may be computed by depth first search (DFS) from F to the free vertices in U, using the breadth first layering to guide the search: 
---------> the DFS is only allowed to follow edges that lead to an unused vertex in the previous layer, and paths in the DFS tree must alternate between matched and unmatched edges. 
---------> Once an augmenting path is found that involves one of the vertices in F, the DFS is continued from the next starting vertex. 
---------> Any vertex encountered during the DFS can immediately be marked as used, since if there is no path from it to U at the current point in the DFS, 
---------> then that vertex can't be used to reach U at any other point in the DFS.
---------> This ensures O (|E|)) running time for the DFS. 
---------> It is also possible to work in the other direction, from free vertices in U to those in V, which is the variant used in the pseudocode.
-------> (4) Every one of the paths found in this way is used to enlarge M.
-------> Note: This sometimes more accurately called the Hopcroft–Karp–Karzanov algorithm.
 
-----> Hungarian algorithm:
-------> This is an algorithm for finding a perfect matching.
-------> The Hungarian method is a combinatorial optimization algorithm that solves the assignment problem in polynomial time and which anticipated later primal–dual methods. 
-------> The assignment problem in its most general form, the problem is as follows:
---------> The problem instance has a number of agents and a number of tasks. 
---------> Any agent can be assigned to perform any task,  incurring some cost that may vary depending on the agent-task assignment. 
---------> It is required to perform as many tasks as possible by assigning at most one agent to each task and at most one task to each agent, in such a way that the total cost of the assignment is minimized.
---------> Alternatively, describing the problem using graph theory:
-----------> The assignment problem consists of finding, in a weighted bipartite graph, a matching of a given size, in which the sum of weights of the edges is minimum.
-------> The cost of each perfect matching is at least the value of each potential: 
---------> the total cost of the matching is the sum of costs of all edges; 
---------> the cost of each edge is at least the sum of potentials of its endpoints; since the matching is perfect, 
---------> each vertex is an endpoint of exactly one edge; hence the total cost is at least the total potential. 
-------> Example: 
---------> In this simple example there are three workers: Paul, Dave, and Chris. 
---------> One of them has to clean the bathroom, another sweep the floors and the third washes the windows, but they each demand different pay for the various tasks. 
---------> The problem is to find the lowest-cost way to assign the jobs. The problem can be represented in a matrix of the costs of the workers doing the jobs. 
---------> For example:
--------->          |  Clean bathroom | Sweep floors | Wash windows
---------> | Paul   |$2               | $3           | $3
---------> | Dave   |$3               | $2           | $3
---------> | Chris  |$3               | $3           | $2 
-------> Note: This was developed and published in 1955 by Harold Kuhn, who gave the name "Hungarian method" because of the two Hungarian mathematicians: Dénes Kőnig and Jenő Egerváry

----> Prüfer coding: conversion between a labeled tree and its Prüfer sequence
-----> In combinatorial mathematics, the Prüfer sequence (also Prüfer code or Prüfer numbers) of a labeled tree is a unique sequence associated with the tree. 
-----> The sequence for a tree on n vertices has length n − 2, and can be generated by a simple iterative algorithm. 
-----> This can be use to convert a graph into a Prüfer sequence and vice versa
-----> Algorithms:
-------> (1) Algorithm to convert a tree into a Prüfer sequence
---------> One can generate a labeled tree's Prüfer sequence by iteratively removing vertices from the tree until only two vertices remain. 
---------> Specifically, consider a labeled tree T with vertices {1, 2, ..., n}. At step i, remove the leaf with the smallest label and set the ith element of the Prüfer sequence to be the label of this leaf's neighbour.
---------> The Prüfer sequence of a labeled tree is unique and has length n − 2.
---------> Both coding and decoding can be reduced to integer radix sorting and parallelized.[2] 
-------> (2) Algorithm to convert a Prüfer sequence into a tree
---------> Let {a[1], a[2], ..., a[n]} be a Prüfer sequence:
---------> The tree will have n+2 nodes, numbered from 1 to n+2. For each node set its degree to the number of times it appears in the sequence plus 1. For instance, in pseudo-code:
-----------> Convert-Prüfer-to-Tree(a)
----------->  1 n ← length[a]
----------->  2 T ← a graph with n + 2 isolated nodes, numbered 1 to n + 2
----------->  3 degree ← an array of integers
----------->  4 for each node i in T do
----------->  5     degree[i] ← 1
----------->  6 for each value i in a do
----------->  7     degree[i] ← degree[i] + 1
----------->  8 for each value i in a do
----------->  9     for each node j in T do
-----------> 10         if degree[j] = 1 then
-----------> 11             Insert edge[i, j] into T
-----------> 12             degree[i] ← degree[i] - 1
-----------> 13             degree[j] ← degree[j] - 1
-----------> 14             break
-----------> 15 u ← v ← 0
-----------> 16 for each node i in T
-----------> 17     if degree[i] = 1 then
-----------> 18         if u = 0 then
-----------> 19             u ← i
-----------> 20         else
-----------> 21             v ← i
-----------> 22             break
-----------> 23 Insert edge[u, v] into T
-----------> 24 degree[u] ← degree[u] - 1
-----------> 25 degree[v] ← degree[v] - 1
-----------> 26 return T
-----> Note: Prüfer sequences were first used by Heinz Prüfer to prove Cayley's formula in 1918

-----> Tarjan's off-line lowest common ancestors algorithm: 
-------> This computes lowest common ancestors for pairs of nodes in a tree
-------> This is an algorithm for computing lowest common ancestors for pairs of nodes in a tree, based on the union-find data structure. 
-------> The lowest common ancestor of two nodes d and e in a rooted tree T is the node g that is an ancestor of both d and e and that has the greatest depth in T. 
-------> Tarjan's algorithm is an offline algorithm; that is, unlike other lowest common ancestor algorithms, 
-------> it requires that all pairs of nodes for which the lowest common ancestor is desired must be specified in advance. 
-------> The simplest version of the algorithm uses the union-find data structure, 
-------> which unlike other lowest common ancestor data structures can take more than constant time per operation when the number of pairs of nodes is similar in magnitude to the number of nodes. 
-------> A later refinement by Gabow & Tarjan (1983) speeds the algorithm up to linear time. 
-------> The pseudocode below determines the lowest common ancestor of each pair in P, given the root r of a tree in which the children of node n are in the set n.children. 
---------> For this offline algorithm, the set P must be specified in advance. It uses the MakeSet, Find, and Union functions of a disjoint-set forest. 
---------> MakeSet(u) removes u to a singleton set, Find(u) returns the standard representative of the set containing u, and Union(u,v) merges the set containing u with the set containing v. 
---------> TarjanOLCA(r) is first called on the root r.
---------> function TarjanOLCA(u) is
--------->     MakeSet(u)
--------->     u.ancestor := u
--------->     for each v in u.children do
--------->         TarjanOLCA(v)
--------->         Union(u, v)
--------->         Find(u).ancestor := u
--------->     u.color := black
--------->     for each v such that {u, v} in P do
--------->         if v.color == black then
--------->             print "Tarjan's Lowest Common Ancestor of " + u +
--------->                   " and " + v + " is " + Find(v).ancestor + "."
-------> Note: This was named after Robert Tarjan, who discovered the technique in 1979. 

-----> Topological sort: 
-------> This finds linear order of nodes (e.g. jobs) based on their dependencies.
-------> A topological sort or topological ordering of a directed graph is a linear ordering of its vertices such that for every directed edge uv from vertex u to vertex v, u comes before v in the ordering. 
-------> For instance, the vertices of the graph may represent tasks to be performed, and the edges may represent constraints that one task must be performed before another; 
-------> in this application, a topological ordering is just a valid sequence for the tasks. 
-------> Precisely, a topological sort is a graph traversal in which each node v is visited only after all its dependencies are visited. 
-------> A topological ordering is possible if and only if the graph has no directed cycles, that is, if it is a directed acyclic graph (DAG). 
-------> Any DAG has at least one topological ordering, and algorithms are known for constructing a topological ordering of any DAG in linear time.



---> Graph drawing

-----> Force-based algorithms
-------> This also known as force-directed algorithms or spring-based algorithm.
---------> Force-directed graph drawing algorithms are a class of algorithms for drawing graphs in an aesthetically-pleasing way. 
---------> Their purpose is to position the nodes of a graph in two-dimensional or three-dimensional space 
---------> so that all the edges are of more or less equal length and there are as few crossing edges as possible, 
---------> by assigning forces among the set of edges and the set of nodes, based on their relative positions, 
---------> and then using these forces either to simulate the motion of the edges and nodes or to minimize their energy.

-----> Spectral layout
-------> Spectral layout is a class of algorithm for drawing graphs. 
---------> The layout uses the eigenvectors of a matrix, such as the Laplace matrix of the graph, as Cartesian coordinates of the graph's vertices.
-------> The idea of the layout is to compute the two largest (or smallest) eigenvalues and corresponding eigenvectors of the Laplacian matrix of the graph and then use those for actually placing the nodes. 
---------> Usually nodes are placed in the 2 dimensional plane. 
---------> An embedding into more dimensions can be found by using more eigenvectors. 
---------> In the 2-dimensional case, for a given node which corresponds to the row/column i in the (symmetric) Laplacian matrix x of the graph, 
---------> the x and y-coordinates are the i-th entries of the first and second eigenvectors of x, respectively. 




---> Network theory

-----> Network analysis

-------> Link analysis

---------> Girvan–Newman algorithm: 
-----------> This detect communities in complex systems.
-----------> The Girvan–Newman algorithm detects communities by progressively removing edges from the original network. 
-----------> The connected components of the remaining network are the communities. 
-----------> Instead of trying to construct a measure that tells us which edges are the most central to communities, 
-----------> the Girvan–Newman algorithm focuses on edges that are most likely "between" communities.
-----------> The algorithm's steps for community detection are summarized below:
-------------> (1) The betweenness of all existing edges in the network is calculated first.
-------------> (2) The edge(s) with the highest betweenness are removed.
-------------> (3) The betweenness of all edges affected by the removal is recalculated.
-------------> (4) Steps 2 and 3 are repeated until no edges remain.
-----------> The end result of the Girvan–Newman algorithm is a dendrogram. 
-----------> As the Girvan–Newman algorithm runs, the dendrogram is produced from the top down (i.e. the network splits up into different communities with the successive removal of links). 
-----------> The leaves of the dendrogram are individual nodes. 
 
 
 
 
---------> Web link analysis

-----------> Hyperlink-Induced Topic Search (HITS)
-------------> Hyperlink-Induced Topic Search (HITS; also known as hubs and authorities) is a link analysis algorithm that rates Web pages, developed by Jon Kleinberg. 
-------------> The idea behind Hubs and Authorities stemmed from a particular insight into the creation of web pages when the Internet was originally forming; 
-------------> that is, certain web pages, known as hubs, served as large directories that were not actually authoritative in the information that they held,
-------------> but were used as compilations of a broad catalog of information that led users direct to other authoritative pages. 
-------------> In other words, a good hub represents a page that pointed to many other pages, while a good authority represents a page that is linked by many different hubs.
-------------> The scheme therefore assigns two scores for each page: its authority, which estimates the value of the content of the page, and its hub value, which estimates the value of its links to other pages. 
-------------> Algorithm
---------------> In the HITS algorithm, the first step is to retrieve the most relevant pages to the search query. 
-----------------> This set is called the root set and can be obtained by taking the top pages returned by a text-based search algorithm. 
-----------------> A base set is generated by augmenting the root set with all the web pages that are linked from it and some of the pages that link to it. 
-----------------> The web pages in the base set and all hyperlinks among those pages form a focused subgraph. 
-----------------> The HITS computation is performed only on this focused subgraph. 
-----------------> According to Kleinberg the reason for constructing a base set is to ensure that most (or many) of the strongest authorities are included.
---------------> Authority and hub values are defined in terms of one another in a mutual recursion. 
-----------------> An authority value is computed as the sum of the scaled hub values that point to that page. 
-----------------> A hub value is the sum of the scaled authority values of the pages it points to. 
-----------------> Some implementations also consider the relevance of the linked pages.
---------------> The algorithm performs a series of iterations, each consisting of two basic steps:
-----------------> (1) Authority update: 
-------------------> Update each node's authority score to be equal to the sum of the hub scores of each node that points to it. 
-------------------> That is, a node is given a high authority score by being linked from pages that are recognized as Hubs for information.
-----------------> (2) Hub update: 
-------------------> Update each node's hub score to be equal to the sum of the authority scores of each node that it points to. 
-------------------> That is, a node is given a high hub score by linking to nodes that are considered to be authorities on the subject.
---------------> The Hub score and Authority score for a node is calculated with the following algorithm:
-----------------> Start with each node having a hub score and authority score of 1.
-----------------> Run the authority update rule
-----------------> Run the hub update rule
-----------------> Normalize the values by dividing each Hub score by square root of the sum of the squares of all Hub scores, 
-----------------> and dividing each Authority score by square root of the sum of the squares of all Authority scores.
-----------------> Repeat from the second step as necessary.
---------------> HITS, like Page and Brin's PageRank, is an iterative algorithm based on the linkage of the documents on the web.
-----------------> However it does have some major differences:
-------------------> It is query dependent, that is, the (Hubs and Authority) scores resulting from the link analysis are influenced by the search terms;
-------------------> As a corollary, it is executed at query time, not at indexing time, with the associated hit on performance that accompanies query-time processing.
-------------------> It is not commonly used by search engines. (Though a similar algorithm was said to be used by Teoma, which was acquired by Ask Jeeves/Ask.com.)
-------------------> It computes two scores per document, hub and authority, as opposed to a single score;
-------------------> It is processed on a small subset of ‘relevant’ documents (a 'focused subgraph' or base set), not all documents as was the case with PageRank.

-----------> PageRank
-------------> PageRank (PR) is an algorithm used by Google Search to rank web pages in their search engine results. 
---------------> It is named after both the term "web page" and co-founder Larry Page. 
---------------> PageRank is a way of measuring the importance of website pages.
-------------> According to Google:
---------------> PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. 
---------------> The underlying assumption is that more important websites are likely to receive more links from other websites.
-------------> Currently, PageRank is not the only algorithm used by Google to order search results, 
---------------> but it is the first algorithm that was used by the company, and it is the best known.
---------------> As of September 24, 2019, PageRank and all associated patents are expired.
-------------> Description:
---------------> The size of each face is proportional to the total size of the other faces which are pointing to it.
---------------> PageRank is a link analysis algorithm and it assigns a numerical weighting to each element of a hyperlinked set of documents, 
-----------------> such as the World Wide Web, with the purpose of "measuring" its relative importance within the set.
-----------------> The algorithm may be applied to any collection of entities with reciprocal quotations and references. 
-----------------> The numerical weight that it assigns to any given element E is referred to as the PageRank of E and denoted by PR(E).
---------------> A PageRank results from a mathematical algorithm based on the webgraph, created by all World Wide Web pages as nodes and hyperlinks as edges, 
-----------------> taking into consideration authority hubs such as cnn.com or mayoclinic.org. 
-----------------> The rank value indicates an importance of a particular page. A hyperlink to a page counts as a vote of support. 
-----------------> The PageRank of a page is defined recursively and depends on the number and PageRank metric of all pages that link to it ("incoming links"). 
-----------------> A page that is linked to by many pages with high PageRank receives a high rank itself.
---------------> Numerous academic papers concerning PageRank have been published since Page and Brin's original paper. 
-----------------> In practice, the PageRank concept may be vulnerable to manipulation. 
-----------------> Research has been conducted into identifying falsely influenced PageRank rankings. 
-----------------> The goal is to find an effective means of ignoring links from documents with falsely influenced PageRank.
-------------> Algorithm:
---------------> The PageRank algorithm outputs a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page. 
-----------------> PageRank can be calculated for collections of documents of any size. 
-----------------> It is assumed in several research papers that the distribution is evenly divided among all documents in the collection at the beginning of the computational process. 
-----------------> The PageRank computations require several passes, called "iterations", through the collection to adjust approximate PageRank values to more closely reflect the theoretical true value.
---------------> A probability is expressed as a numeric value between 0 and 1. 
-----------------> A 0.5 probability is commonly expressed as a "50% chance" of something happening. 
-----------------> Hence, a document with a PageRank of 0.5 means there is a 50% chance that a person clicking on a random link will be directed to said document. 
-------------> Simplified algorithm
---------------> Assume a small universe of four web pages: A, B, C, and D. Links from a page to itself are ignored. 
-----------------> Multiple outbound links from one page to another page are treated as a single link. PageRank is initialized to the same value for all pages. 
-----------------> In the original form of PageRank, the sum of PageRank over all pages was the total number of pages on the web at that time, so each page in this example would have an initial value of 1.
-----------------> However, later versions of PageRank, and the remainder of this section, assume a probability distribution between 0 and 1. 
-----------------> Hence the initial value for each page in this example is 0.25.
---------------> The PageRank transferred from a given page to the targets of its outbound links upon the next iteration is divided equally among all outbound links.
---------------> If the only links in the system were from pages B, C, and D to A, each link would transfer 0.25 PageRank to A upon the next iteration, for a total of 0.75.
-----------------> PR(A) = PR(B) + PR(C) + PR(D).
---------------> Suppose instead that page B had a link to pages C and A, page C had a link to page A, and page D had links to all three pages. 
---------------> Thus, upon the first iteration, page B would transfer half of its existing value, or 0.125, to page A and the other half, or 0.125, to page C. 
---------------> Page C would transfer all of its existing value, 0.25, to the only page it links to, A. 
---------------> Since D had three outbound links, it would transfer one third of its existing value, or approximately 0.083, to A.
---------------> At the completion of this iteration, page A will have a PageRank of approximately 0.458.
-----------------> PR(A) = PR(B)/2 + PR(C)/1 + PR(D)/3.
---------------> In other words, the PageRank conferred by an outbound link is equal to the document's own PageRank score divided by the number of outbound links L( ).
-----------------> PR(A) = PR(B)/L(B) + PR(C)/L(C) + PR(D)/L(D). 
---------------> In the general case, the PageRank value for any page u can be expressed as:
-----------------> PR(u) = ∑ v PR(v)/L(v) 
---------------> i.e. the PageRank value for a page u is dependent on the PageRank values for each page v 
-----------------> contained in the set Bu (the set containing all pages linking to page u), divided by the number L(v) of links from page v. 

-----------> TrustRank
-------------> TrustRank is an algorithm that conducts link analysis to separate useful webpages from spam and helps search engine rank pages in SERPs (Search Engine Results Pages).
---------------> It is semi-automated process which means that it needs some human assistance in order to function properly. 
---------------> Search engines have many different algorithms and ranking factors that they use when measuring the quality of webpages. 
---------------> TrustRank is one of them.
-------------> Because manual review of the Internet is impractical and very expensive, TrustRank was introduced in order to help achieve this task much faster and cheaper. 
---------------> It was first introduced by researchers Zoltan Gyongyi and Hector Garcia-Molina of Stanford University and Jan Pedersen of Yahoo! in their paper "Combating Web Spam with TrustRank" in 2004.
---------------> Today, this algorithm is a part of major web search engines like Yahoo! and Google.
-------------> One of the most important factors that help web search engine determine the quality of a web page when returning results are backlinks. 
---------------> Search engines take a number and quality of backlinks into consideration when assigning a place to a certain web page in SERPs. 
---------------> Many web spam pages are created only with the intention of misleading search engines. 
---------------> These pages, chiefly created for commercial reasons, use various techniques to achieve higher-than-deserved rankings in the search engines' result pages. 
---------------> While human experts can easily identify spam, search engines are still being improved daily in order to do it without help of humans.
-------------> One popular method for improving rankings is to increase the perceived importance of a document through complex linking schemes. 
---------------> Google's PageRank and other search ranking algorithms have been subjected to such manipulation.
-------------> TrustRank seeks to combat spam by filtering the web based upon reliability. 
---------------> The method calls for selecting a small set of seed pages to be evaluated by an expert.
---------------> Once the reputable seed pages are manually identified, a crawl extending outward from the seed set seeks out similarly reliable and trustworthy pages. 
---------------> TrustRank's reliability diminishes with increased distance between documents and the seed set.
-------------> The logic works in the opposite way as well, which is called Anti-Trust Rank. 
---------------> The closer a site is to spam resources, the more likely it is to be spam as well.
-------------> The researchers who proposed the TrustRank methodology have continued to refine their work by evaluating related topics, such as measuring spam mass. 




-----> Flow networks

-------> Dinic's algorithm:
---------> This is a strongly polynomial algorithm for computing the maximum flow in a flow network.
---------> Dinic's algorithm or Dinitz's algorithm is a strongly polynomial algorithm for computing the maximum flow in a flow network.
---------> The algorithm runs in O(V^2*E) time and is similar to the Edmonds–Karp algorithm, which runs in O (V*E^2) time, in that it uses shortest augmenting paths. 
---------> The introduction of the concepts of the level graph and blocking flow enable Dinic's algorithm to achieve its performance.
---------> Dinic's Algorithm
-----------> Terms: G is graph, Gf is residual graph, GL is the level graph, e is an edge, E is the set of all edges, f is the flow function, s is start, t is target, dist() is the shortest path 
-----------> Input: A network G = ((V, E), c, s, t).
-----------> Output: An s–t flow f of maximum value.
-------------> (1) Set f(e) = 0 for each e is an element of E.
-------------> (2) Construct GL from Gf of G. If dist ⁡ (t) = ∞, stop and output f.
-------------> (3) Find a blocking flow f' in GL.
-------------> (4) Add augment flow f by f' and go back to step 2.
---------> Analysis
-----------> It can be shown that the number of layers in each blocking flow increases by at least 1 each time and thus there are at most |V|-1 blocking flows in the algorithm. 
-------------> For each of them:
---------------> the level graph GL can be constructed by breadth-first search in O(E) time
---------------> a blocking flow in the level graph GL can be found in O(VE) time
-------------> with total running time O ( E + V E ) = O ( V E ) for each layer. 
-------------> As a consequence, the running time of Dinic's algorithm is O(V^2*E).
-----------> Using a data structure called dynamic trees, the running time of finding a blocking flow in each phase can be reduced to O(E log ⁡ V) 
-------------> and therefore the running time of Dinic's algorithm can be improved to O(V*E*log⁡ V). 
---------> Note: This was conceived in 1970 by Israeli (formerly Soviet) computer scientist Yefim (Chaim) A. Dinitz.

-------> Edmonds–Karp algorithm: 
---------> This is an implementation of Ford–Fulkerson
-----------> This is an implementation of the Ford–Fulkerson method for computing the maximum flow in a flow network in O (|V||E|^2) time.
-----------> Dinic's algorithm includes additional techniques that reduce the running time to O(|V|^2*|E|) 
---------> Algorithm
-----------> The algorithm is identical to the Ford–Fulkerson algorithm, except that the search order when finding the augmenting path is defined. 
-----------> The path found must be a shortest path that has available capacity. 
-----------> This can be found by a breadth-first search, where we apply a weight of 1 to each edge. 
-----------> The running time of O(|V||E|^2) is found by showing that each augmenting path can be found in O(|E|) time, 
-----------> that every time at least one of the E edges becomes saturated (an edge which has the maximum possible flow), 
-----------> that the distance from the saturated edge to the source along the augmenting path must be longer than last time it was saturated, and that the length is at most |V|.
-----------> Another property of this algorithm is that the length of the shortest augmenting path increases monotonically.
---------> Note: The algorithm was first published by Yefim Dinitz (whose name is also transliterated "E. A. Dinic", notably as author of his early papers) in 1970 
-----------> and independently published by Jack Edmonds and Richard Karp in 1972. 

-------> Ford–Fulkerson algorithm: 
---------> This computes the maximum flow in a graph
-----------> The Ford–Fulkerson method or Ford–Fulkerson algorithm (FFA) is a greedy algorithm that computes the maximum flow in a flow network. 
-----------> It is sometimes called a "method" instead of an "algorithm" as the approach to finding augmenting paths in a residual graph is not fully specified 
-----------> or it is specified in several implementations with different running times.
---------> Algorithm Ford–Fulkerson
-----------> Inputs Given a Network G=(V,E) with flow capacity c, a source node s, and a sink node t
-----------> Output Compute a flow f from s to t of maximum value
-------------> f(u,v) ← 0  for all edges (u,v)
-------------> While there is a path p from s to t in Gf, such that cf(u,v) > 0 for all edges (u,v) is an element of p:
------------->     Find cf(p) = min { cf(u, v) : (u, v) is an element of p }  (find the augmenting path)
------------->     For each edge (u , v) is an element of p
------------->         f(u, v) ← f(u, v) + cf(p) (Send flow along the path)
------------->         f(v, u) ← f(v, u) − cf(p) (The flow might be "returned" later)
-------------> 

-------> Karger's algorithm: 
---------> This is a Monte Carlo method to compute the minimum cut of a connected graph.
-----------> The idea of the algorithm is based on the concept of contraction of an edge(u,v) in an undirected graph G=(V, E). 
-------------> Informally speaking, the contraction of an edge merges the nodes u and v into one, reducing the total number of nodes of the graph by one. 
-------------> All other edges connecting either u or v are "reattached" to the merged node, effectively producing a multigraph. 
-------------> Karger's basic algorithm iteratively contracts randomly chosen edges until only two nodes remain; those nodes represent a cut in the original graph. 
-------------> By iterating this basic algorithm a sufficient number of times, a minimum cut can be found with high probability. 
---------> Note: This was invented by David Karger and first published in 1993.

-------> Push–relabel algorithm: 
---------> This computes a maximum flow in a graph.
-----------> In mathematical optimization, the push–relabel algorithm is an algorithm for computing maximum flows in a flow network. 
-----------> The name "push–relabel" comes from the two basic operations used in the algorithm. 
-----------> Throughout its execution, the algorithm maintains a "preflow" and gradually converts it into a maximum flow by moving flow locally between neighboring nodes
-----------> using push operations under the guidance of an admissible network maintained by relabel operations. 
-----------> In comparison, the Ford–Fulkerson algorithm performs global augmentations that send flow following paths from the source all the way to the sink.[1]
---------> The push–relabel algorithm is considered one of the most efficient maximum flow algorithms. 
-----------> The generic algorithm has a strongly polynomial O(V^2E) time complexity, which is asymptotically more efficient than the O(VE^2) Edmonds–Karp algorithm.
-----------> Specific variants of the algorithms achieve even lower time complexities. 
-----------> The variant based on the highest label node selection rule has O(V*2√E) time complexity and is generally regarded as the benchmark for maximum flow algorithms.
-----------> Subcubic O(V*E*log(V^2/E)) time complexity can be achieved using dynamic trees, although in practice it is less efficient
---------> The push–relabel algorithm has been extended to compute minimum cost flows.
-----------> The idea of distance labels has led to a more efficient augmenting path algorithm, 
-----------> which in turn can be incorporated back into the push–relabel algorithm to create a variant with even higher empirical performance.
---------> This is alternatively called the preflow–push algorithm.



---> Routing for graphs

-----> Edmonds' algorithm: 
-------> This finds the maximum or minimum branchings.
-------> This is an algorithm for finding a spanning arborescence of minimum weight (sometimes called an optimum branching). 
---------> An arborescence is an directed-graph form of a rooted tree of an undirected graph.
---------> It is the directed analog of the minimum spanning tree problem. 
-------> Algorithm Description
---------> The algorithm takes as input a directed graph D = <V, E>, where V is the set of nodes and E is the set of directed edges,
-----------> a distinguished vertex r is an element of V called the root, 
-----------> and a real-valued weight w(e) for each edge e is an element of E. 
-----------> It returns a spanning arborescence A rooted at r of minimum weight, 
-----------> where the weight of an arborescence is defined to be the sum of its edge weights, w(A) = ∑ w(e) where e is an element of A.
---------> The algorithm has a recursive description. 
-----------> Let f(D, r, w) denote the function which returns a spanning arborescence rooted at r of minimum weight. 
-----------> We first remove any edge from E whose destination is r. 
-----------> We may also replace any set of parallel edges (edges between the same pair of vertices in the same direction) 
-------------> by a single edge with weight equal to the minimum of the weights of these parallel edges.
---------> Now, for each node V other than the root, find the edge incoming to V of lowest weight (with ties broken arbitrarily). 
-----------> Denote the source of this edge by π(v)
-----------> If the set of edges P = {(π(v), v) | v is an element of V \ {r} } does not contain any cycles, then f(D, r, w) = P.
---------> Otherwise, P contains at least one cycle. 
-----------> Arbitrarily choose one of these cycles and call it C. 
-----------> We now define a new weighted directed graph D' = <V', E'>, in which the cycle C is "contracted" into one node as follows:
---------> The nodes of V' are the nodes of V not in C plus a new node denoted vC.
-----------> If (u, v) is an edge in E with u is not an element of C and v is an element of C (an edge coming into the cycle), 
-------------> then include in E' a new edge e = (u, vC), and define w′(e) = w(u, v) − w(π(v), v) .
-----------> If (u, v) is an edge in E with u is an element of C and v is not an element of C (an edge going away from the cycle), 
-------------> then include in E' a new edge e = (vC, v), and define w′(e) = w(u, v)
-----------> If (u, v) is an edge in E with u is not an element of C and v is not an element of C (an edge unrelated to the cycle), t
-------------> then include in E' a new edge e=(u, v), and define w′(e) = w(u, v)
---------> For each edge in E', we remember which edge in E it corresponds to.
---------> Now find a minimum spanning arborescence A' of D' using a call to f(D′, r, w′). 
-----------> Since A' is a spanning arborescence, each vertex has exactly one incoming edge. 
-----------> Let (u, vC) be the unique incoming edge to vC in A'. 
-----------> This edge corresponds to an edge (u, v) is an element of E with v is an element of C. 
-----------> Remove the edge (π(v), v) from C, breaking the cycle. 
-----------> Mark each remaining edge in C. 
-----------> For each edge in A', mark its corresponding edge in E. 
-----------> Now we define f(D, r, w) to be the set of marked edges, which form a minimum spanning arborescence.
---------> Observe that f(D, r, w) is defined in terms of f(D′, r, w′), with D' having strictly fewer vertices than D. 
-----------> Finding f(D, r, w) for a single-vertex graph is trivial (it is just D itself), so the recursive algorithm is guaranteed to terminate.
-----------> Running time
-----------> The running time of this algorithm is O(E*V).
-----------> A faster implementation of the algorithm due to Robert Tarjan runs in time O(E*logV)  for sparse graphs and O(V^2) for dense graphs. 
-----------> This is as fast as Prim's algorithm for an undirected minimum spanning tree. 
-----------> In 1986, Gabow, Galil, Spencer, and Tarjan produced a faster implementation, with running time O(E + V \log V). 
-------> Note: This is also known as Chu–Liu/Edmonds' algorithm.
---------> The algorithm was proposed independently first by Yoeng-Jin Chu and Tseng-Hong Liu (1965) and then by Jack Edmonds (1967). 

-----> Euclidean minimum spanning tree: 
-------> These algorithms for computing the minimum spanning tree of a set of points in the plane
-------> A Euclidean minimum spanning tree of a finite set of points in the Euclidean plane 
---------> or higher-dimensional Euclidean space connects the points by a system of line segments with the points as endpoints, 
---------> minimizing the total length of the selected segments. 
---------> In it, any two points can reach each other along a path through the line segments. 
---------> It can be found as the minimum spanning tree of a complete graph with the points as vertices and the Euclidean distances between points as edge weights.
-------> The edges of the minimum spanning tree meet at angles of at least 60°, at most six to a vertex. 
---------> In higher dimensions, the number of edges per vertex is controlled by the kissing number of tangent unit spheres. 
---------> The total length of the edges, for points in a unit square, is at most proportional to the square root of the number of points. 
---------> Each edge lies in an empty region of the plane, 
---------> and these regions can be used to prove that the Euclidean minimum spanning tree a subgraph of other geometric graphs including the relative neighborhood graph and Delaunay triangulation. 
---------> By constructing the Delaunay triangulation and then applying a graph minimum spanning tree algorithm, 
---------> a Euclidean minimum spanning tree for n given planar points may be found in time O(n log ⁡ n), as expressed in Big O notation. 
---------> Faster randomized algorithms are known for points with integer coordinates. 
---------> For points in higher dimensions, finding an optimal algorithm remains an open problem. 

-----> Longest path problem: 
-------> This finds a simple path of maximum length in a given graph.
-------> The longest path problem is the problem of finding a simple path of maximum length in a given graph. 
---------> A path is called simple if it does not have any repeated vertices.
---------> The length of a path may either be measured by its number of edges, or (in weighted graphs) by the sum of the weights of its edges. 
---------> In contrast to the shortest path problem, which can be solved in polynomial time in graphs without negative-weight cycles, 
---------> the longest path problem is NP-hard and the decision version of the problem, which asks whether a path exists of at least some given length, is NP-complete. 
---------> This means that the decision problem cannot be solved in polynomial time for arbitrary graphs unless P = NP. 
---------> Stronger hardness results are also known showing that it is difficult to approximate. 
-------> However, it has a linear time solution for directed acyclic graphs, which has important applications in finding the critical path in scheduling problems. 




-----> Minimum spanning tree
-------> A minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, 
---------> edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. 
---------> That is, it is a spanning tree whose sum of edge weights is as small as possible.
---------> More generally, any edge-weighted undirected graph (not necessarily connected) has a "Minimum Spanning Forest", which is a union of the minimum spanning trees for its connected components.
-------> There are many use cases for minimum spanning trees. 
---------> One example is a telecommunications company trying to lay cable in a new neighborhood. 
---------> If it is constrained to bury the cable only along certain paths (e.g. roads), then there would be a graph containing the points (e.g. houses) connected by those paths. 
---------> Some of the paths might be more expensive, because they are longer, or require the cable to be buried deeper; these paths would be represented by edges with larger weights. 
---------> Currency is an acceptable unit for edge weight – there is no requirement for edge lengths to obey normal rules of geometry such as the triangle inequality. 
---------> A spanning tree for that graph would be a subset of those paths that has no cycles but still connects every house; there might be several spanning trees possible. 
---------> A minimum spanning tree would be one with the lowest total cost, representing the least expensive path for laying the cable. 

-------> Borůvka's algorithm
---------> Borůvka's algorithm is a greedy algorithm for finding a minimum spanning tree in a graph, or a minimum spanning forest in the case of a graph that is not connected.
---------> The algorithm begins by finding the minimum-weight edge incident to each vertex of the graph, and adding all of those edges to the forest. 
-----------> Then, it repeats a similar process of finding the minimum-weight edge from each tree constructed so far to a different tree, and adding all of those edges to the forest. 
-----------> Each repetition of this process reduces the number of trees, within each connected component of the graph, 
-----------> to at most half of this former value, so after logarithmically many repetitions the process finishes. 
-----------> When it does, the set of edges it has added forms the minimum spanning forest. 
---------> Algorithm
-----------> The following pseudocode illustrates a basic implementation of Borůvka's algorithm. 
-------------> In the conditional clauses, every edge uv is considered cheaper than "None". 
-------------> The purpose of the completed variable is to determine whether the forest F is yet a spanning forest.
-----------> If edges do not have distinct weights, then a consistent tie-breaking rule must be used, e.g. based on some total order on vertices or edges. 
-------------> This can be achieved by representing vertices as integers and comparing them directly; comparing their memory addresses; etc. 
-------------> A tie-breaking rule is necessary to ensure that the created graph is indeed a forest, that is, it does not contain cycles. 
-------------> For example, consider a triangle graph with nodes {a,b,c} and all edges of weight 1. 
-------------> Then a cycle could be created if we select ab as the minimal weight edge for {a}, bc for {b}, and ca for {c}. 
-------------> A tie-breaking rule which orders edges first by source, then by destination, will prevent creation of a cycle, resulting in the minimal spanning tree {ab, bc}.
-----------> algorithm Borůvka is
----------->     input: A weighted undirected graph G = (V, E).
----------->     output: F, a minimum spanning forest of G.
----------->     Initialize a forest F to (V, E') where E' = {}.
----------->     completed := false
----------->     while not completed do
----------->         Find the connected components of F and assign to each vertex its component
----------->         Initialize the cheapest edge for each component to "None"
----------->         for each edge u, v in E, where u and v are in different components of F:
----------->             let wx be the cheapest edge for the component of u
----------->             if is-preferred-over(uv, wx) then
----------->                 Set uv as the cheapest edge for the component of u
----------->             let yz be the cheapest edge for the component of v
----------->             if is-preferred-over(uv, yz) then
----------->                 Set uv as the cheapest edge for the component of v
----------->         if all components have cheapest edge set to "None" then
----------->             // no more trees can be merged -- we are finished
----------->             completed := true
----------->         else
----------->             completed := false
----------->             for each component whose cheapest edge is not "None" do
----------->                 Add its cheapest edge to E'
-----------> function is-preferred-over(edge1, edge2) is
----------->     return (edge2 is "None") or
----------->            (weight(edge1) < weight(edge2)) or
----------->            (weight(edge1) = weight(edge2) and tie-breaking-rule(edge1, edge2))
-----------> function tie-breaking-rule(edge1, edge2) is
----------->     The tie-breaking rule; returns true if and only if edge1
----------->     is preferred over edge2 in the case of a tie.
-----------> As an optimization, one could remove from G each edge that is found to connect two vertices in the same component, 
-------------> so that it does not contribute to the time for searching for cheapest edges in later components. 
---------> Note: This was first published in 1926 by Otakar Borůvka as a method of constructing an efficient electricity network for Moravia. 
-----------> The algorithm was rediscovered by Choquet in 1938;[4] again by Florek, Łukasiewicz, Perkal, Steinhaus, and Zubrzycki in 1951; and again by Georges Sollin in 1965.
-----------> This algorithm is frequently called Sollin's algorithm, especially in the parallel computing literature.

-------> Kruskal's algorithm
---------> Kruskal's algorithm finds a minimum spanning forest of an undirected edge-weighted graph. 
-----------> If the graph is connected, it finds a minimum spanning tree. 
-----------> For a disconnected graph, a minimum spanning forest is composed of a minimum spanning tree for each connected component. 
-----------> It is a greedy algorithm in graph theory as in each step it adds the next lowest-weight edge that will not form a cycle to the minimum spanning forest.
---------> Algorithm
-----------> create a forest F (a set of trees), where each vertex in the graph is a separate tree
-----------> create a set S containing all the edges in the graph
-----------> while S is nonempty and F is not yet spanning
----------->     remove an edge with minimum weight from S
----------->     if the removed edge connects two different trees then add it to the forest F, combining two trees into a single tree
---------> At the termination of the algorithm, the forest forms a minimum spanning forest of the graph. 
-----------> If the graph is connected, the forest has a single component and forms a minimum spanning tree.
---------> Algorithm Pseudocode
-----------> A demo for Kruskal's algorithm on a complete graph with weights based on Euclidean distance.
-----------> The following code is implemented with a disjoint-set data structure. 
-----------> Here, we represent our forest F as a set of edges, and use the disjoint-set data structure to efficiently determine whether two vertices are part of the same tree.
-----------> algorithm Kruskal(G) is
----------->     F:= nullset
----------->     for each v is an element of G.V do
----------->         MAKE-SET(v)
----------->     for each (u, v) in G.E ordered by weight(u, v), increasing do
----------->         if FIND-SET(u) ≠ FIND-SET(v) then
----------->             F:= F ∪ {(u, v)} ∪ {(v, u)}
----------->             UNION(FIND-SET(u), FIND-SET(v))
----------->     return F
---------> Note: This algorithm first appeared in Proceedings of the American Mathematical Society, pp. 48–50 in 1956, and was written by Joseph Kruskal. 
-----------> It was rediscovered by Loberman & Weinberger (1957).

-------> Prim's algorithm
---------> Prim's algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. 
-----------> This means it finds a subset of the edges that forms a tree that includes every vertex, where the total weight of all the edges in the tree is minimized. 
-----------> The algorithm operates by building this tree one vertex at a time, from an arbitrary starting vertex, at each step adding the cheapest possible connection from the tree to another vertex.
---------> The algorithm may informally be described as performing the following steps:
-----------> (1) Initialize a tree with a single vertex, chosen arbitrarily from the graph.
-----------> (2) Grow the tree by one edge: of the edges that connect the tree to vertices not yet in the tree, find the minimum-weight edge, and transfer it to the tree.
-----------> (3) Repeat step 2 (until all vertices are in the tree).
---------> In more detail, it may be implemented following the pseudocode below.
-----------> (1) Associate with each vertex v of the graph a number C[v] (the cheapest cost of a connection to v) and an edge E[v] (the edge providing that cheapest connection). 
-------------> To initialize these values, set all values of C[v] to +∞ (or to any number larger than the maximum edge weight) 
-------------> and set each E[v] to a special flag value indicating that there is no edge connecting v to earlier vertices.
-----------> (2) Initialize an empty forest F and a set Q of vertices that have not yet been included in F (initially, all vertices).
-----------> (3) Repeat the following steps until Q is empty:
-------------> (3.1) Find and remove a vertex v from Q having the minimum possible value of C[v]
-------------> (3.2) Add v to F
-------------> (3.3) Loop over the edges vw connecting v to other vertices w. 
-------------> For each such edge, if w still belongs to Q and vw has smaller weight than C[w], perform the following steps:
---------------> (3.3.1) Set C[w] to the cost of edge vw
---------------> (3.3.2) Set E[w] to point to edge vw.
-----------> (4) Return F
---------> As described above, the starting vertex for the algorithm will be chosen arbitrarily, 
-----------> because the first iteration of the main loop of the algorithm will have a set of vertices in Q that all have equal weights, 
-----------> and the algorithm will automatically start a new tree in F when it completes a spanning tree of each connected component of the input graph. 
-----------> The algorithm may be modified to start with any particular vertex s by setting C[s] to be a number smaller than the other values of C (for instance, zero), 
-----------> and it may be modified to only find a single spanning tree rather than an entire spanning forest (matching more closely the informal description) 
-----------> by stopping whenever it encounters another vertex flagged as having no associated edge.
---------> Different variations of the algorithm differ from each other in how the set Q is implemented: 
-----------> as a simple linked list or array of vertices, or as a more complicated priority queue data structure. 
-----------> This choice leads to differences in the time complexity of the algorithm. 
-----------> In general, a priority queue will be quicker at finding the vertex v with minimum cost, but will entail more expensive updates when the value of C[w] changes. 
---------> Note: This is also known as Jarník's algorithm
 
-------> Reverse-delete algorithm
---------> The reverse-delete algorithm is an algorithm in graph theory used to obtain a minimum spanning tree from a given connected, edge-weighted graph. 
-----------> If the graph is disconnected, this algorithm will find a minimum spanning tree for each disconnected part of the graph. 
-----------> The set of these minimum spanning trees is called a minimum spanning forest, which contains every vertex in the graph.
---------> This algorithm is a greedy algorithm, choosing the best choice given any situation. 
-----------> It is the reverse of Kruskal's algorithm, which is another greedy algorithm to find a minimum spanning tree.
-----------> Kruskal’s algorithm starts with an empty graph and adds edges while the Reverse-Delete algorithm starts with the original graph and deletes edges from it. 
---------> The algorithm works as follows:
----------->     Start with graph G, which contains a list of edges E.
----------->     Go through E in decreasing order of edge weights.
----------->     For each edge, check if deleting the edge will further disconnect the graph.
----------->     Perform any deletion that does not lead to additional disconnection.
-----------> function ReverseDelete(edges[] E) is
----------->     sort E in decreasing order
----------->     Define an index i ← 0
----------->     while i < size(E) do
----------->         Define edge ← E[i]
----------->     delete E[i]
----------->     if graph is not connected then
----------->                 E[i] ← edge
----------->                 i ← i + 1
----------->     return edges[] E
---------> In the above the graph is the set of edges E with each edge containing a weight and connected vertices v1 and v2. 
---------> Note: This first appeared in Kruskal (1956), but it should not be confused with Kruskal's algorithm which appears in the same paper. 

-----> Nonblocking minimal spanning switch
-------> A nonblocking minimal spanning switch is a device that can connect N inputs to N outputs in any combination. 
---------> The most familiar use of switches of this type is in a telephone exchange. 
---------> The term "non-blocking" means that if it is not defective, it can always make the connection. 
---------> The term "minimal" means that it has the fewest possible components, and therefore the minimal expense.
-------> Historically, in telephone switches, connections between callers were arranged with large, expensive banks of electromechanical relays, Strowger switches. 
---------> The basic mathematical property of Strowger switches is that for each input to the switch, there is exactly one output. 
---------> Much of the mathematical switching circuit theory attempts to use this property to reduce the total number of switches needed to connect a combination of inputs to a combination of outputs.
-------> Note: In the 1940s and 1950s, engineers in Bell Lab began an extended series of mathematical investigations into methods 
---------> for reducing the size and expense of the "switched fabric" needed to implement a telephone exchange. 
---------> One early, successful mathematical analysis was performed by Charles Clos, and a switched fabric constructed of smaller switches is called a Clos network.



-----> Shortest path problem
-------> In graph theory, the shortest path problem is the problem of finding a path between two vertices (or nodes) in a graph such that the sum of the weights of its constituent edges is minimized.
-------> The problem of finding the shortest path between two intersections on a road map may be modeled as a special case of the shortest path problem in graphs, 
-------> where the vertices correspond to intersections and the edges correspond to road segments, each weighted by the length of the segment. 

-------> Bellman–Ford algorithm: 
---------> This computes shortest paths in a weighted graph (where some of the edge weights may be negative)
-----------> The Bellman–Ford algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph. 
-----------> It is slower than Dijkstra's algorithm for the same problem, but more versatile, as it is capable of handling graphs in which some of the edge weights are negative numbers. 
---------> Like Dijkstra's algorithm, Bellman–Ford proceeds by relaxation, in which approximations to the correct distance are replaced by better ones until they eventually reach the solution. 
-----------> In both algorithms, the approximate distance to each vertex is always an overestimate of the true distance, and is replaced by the minimum of its old value and the length of a newly found path. 
-----------> However, Dijkstra's algorithm uses a priority queue to greedily select the closest vertex that has not yet been processed, and performs this relaxation process on all of its outgoing edges; 
-----------> by contrast, the Bellman–Ford algorithm simply relaxes all the edges, and does this |V|-1 times, where |V| is the number of vertices in the graph. 
-----------> In each of these repetitions, the number of vertices with correctly calculated distances grows, from which it follows that eventually all vertices will have their correct distances. 
-----------> This method allows the Bellman–Ford algorithm to be applied to a wider class of inputs than Dijkstra. 
-----------> The intermediate answers depend on the order of edges relaxed, but the final answer remains the same.
---------> Bellman–Ford runs in O(|V|*|E|) time, where |V| and |E| are the number of vertices and edges respectively.
---------> Pseudocode:
-----------> function BellmanFord(list vertices, list edges, vertex source) is
----------->     // This implementation takes in a graph, represented as
----------->     // lists of vertices (represented as integers [0..n-1]) and edges,
----------->     // and fills two arrays (distance and predecessor) holding
----------->     // the shortest path from the source to each vertex
----------->     distance := list of size n
----------->     predecessor := list of size n
----------->     // Step 1: initialize graph
----------->     for each vertex v in vertices do
----------->         distance[v] := inf             // Initialize the distance to all vertices to infinity
----------->         predecessor[v] := null         // And having a null predecessor
----------->     distance[source] := 0              // The distance from the source to itself is, of course, zero
----------->     // Step 2: relax edges repeatedly
----------->     repeat |V|−1 times:
----------->          for each edge (u, v) with weight w in edges do
----------->              if distance[u] + w < distance[v] then
----------->                  distance[v] := distance[u] + w
----------->                  predecessor[v] := u
----------->     // Step 3: check for negative-weight cycles
----------->     for each edge (u, v) with weight w in edges do
----------->         if distance[u] + w < distance[v] then
----------->             // Step 4: find a negative-weight cycle
----------->             negativeloop := [v, u]
----------->             repeat |V|−1 times:
----------->                 u := negativeloop[0]
----------->                 for each edge (u, v) with weight w in edges do
----------->                     if distance[u] + w < distance[v] then
----------->                         negativeloop := concatenate([v], negativeloop)
----------->             find a cycle in negativeloop, let it be ncycle
----------->             // use any cycle detection algorithm here
----------->             error "Graph contains a negative-weight cycle", ncycle
----------->     return distance, predecessor
---------> Simply put, the algorithm initializes the distance to the source to 0 and all other nodes to infinity. 
-----------> Then for all edges, if the distance to the destination can be shortened by taking the edge, the distance is updated to the new lower value.
---------> The core of the algorithm is a loop that scans across all edges at every loop. 
-----------> For every i ≤ |V|-1, at the end of the i-th iteration, from any vertex v,
-----------> following the predecessor trail recorded in predecessor yields a path that has a total weight that is at most distance[v],
-----------> and further, distance[v] is a lower bound to the length of any path from source to v that uses at most i edges.
---------> Since the longest possible path without a cycle can be |V|-1 edges, the edges must be scanned |V|-1 times to ensure the shortest path has been found for all nodes. 
-----------> A final scan of all the edges is performed and if any distance is updated, then a path of length |V| edges has been found which can only occur if at least one negative cycle exists in the graph. 
---------> Negative edge weights are found in various applications of graphs, hence the usefulness of this algorithm.
-----------> If a graph contains a "negative cycle" (i.e. a cycle whose edges sum to a negative value) that is reachable from the source, 
-----------> then there is no cheapest path: any path that has a point on the negative cycle can be made cheaper by one more walk around the negative cycle. 
-----------> In such a case, the Bellman–Ford algorithm can detect and report the negative cycle.
---------> Note: The algorithm was first proposed by Alfonso Shimbel (1955), but is instead named after Richard Bellman and Lester Ford Jr., who published it in 1958 and 1956, respectively. 
-----------> Edward F. Moore also published a variation of the algorithm in 1959, and for this reason it is also sometimes called the Bellman–Ford–Moore algorithm.

-------> Dijkstra's algorithm: 
---------> This computes shortest paths in a graph with non-negative edge weights.
---------> The algorithm exists in many variants. 
-----------> Dijkstra's original algorithm found the shortest path between two given nodes, 
-----------> but a more common variant fixes a single node as the "source" node and finds shortest paths from the source to all other nodes in the graph, producing a shortest-path tree.
---------> For a given source node in the graph, the algorithm finds the shortest path between that node and every other.
-----------> It can also be used for finding the shortest paths from a single node to a single destination node by stopping the algorithm once the shortest path to the destination node has been determined. 
-----------> For example, if the nodes of the graph represent cities and edge path costs represent driving distances between pairs of cities connected by a direct road 
-----------> Dijkstra's algorithm can be used to find the shortest route between one city and all other cities. 
-----------> A widely used application of shortest path algorithms is network routing protocols, most notably IS-IS (Intermediate System to Intermediate System) and OSPF (Open Shortest Path First). 
-----------> It is also employed as a subroutine in other algorithms such as Johnson's.
---------> The Dijkstra algorithm uses labels that are positive integers or real numbers, which are totally ordered. 
-----------> It can be generalized to use any labels that are partially ordered, provided the subsequent labels (a subsequent label is produced when traversing an edge) are monotonically non-decreasing. 
-----------> This generalization is called the generic Dijkstra shortest-path algorithm.[8]
---------> Dijkstra's algorithm uses a data structure for storing and querying partial solutions sorted by distance from the start. 
-----------> While the original algorithm uses a min-priority queue and runs in time Θ((|V|+|E|)log |V|), it can also be implemented in Θ(|V|^{2}) using an array. 
-----------> The idea of this algorithm is also given in Leyzorek et al. 1957. Fredman & Tarjan 1984 propose using a Fibonacci heap min-priority queue to optimize the running time complexity to Θ(|E|+|V|log|V|). 
-----------> This is asymptotically the fastest known single-source shortest-path algorithm for arbitrary directed graphs with unbounded non-negative weights. 
-----------> However, specialized cases can indeed be improved further as detailed in Specialized variants. 
-----------> Additionally, if preprocessing is allowed algorithms such as contraction hierarchies can be up to seven orders of magnitude faster. 
---------> Algorithm
-----------> Let the node at which we are starting be called the initial node. 
-----------> Let the distance of node Y be the distance from the initial node to Y. 
-----------> Dijkstra's algorithm will initially start with infinite distances and will try to improve them step by step.
-------------> (1) Mark all nodes unvisited. 
---------------> Create a set of all the unvisited nodes called the unvisited set.
-------------> (2) Assign to every node a tentative distance value: set it to zero for our initial node and to infinity for all other nodes. 
---------------> During the run of the algorithm, the tentative distance of a node v is the length of the shortest path discovered so far between the node v and the starting node. 
---------------> Since initially no path is known to any other vertex than the source itself (which is a path of length zero), all other tentative distances are initially set to infinity. 
---------------> Set the initial node as current.[15]
-------------> (3) For the current node, consider all of its unvisited neighbors and calculate their tentative distances through the current node. 
---------------> Compare the newly calculated tentative distance to the one currently assigned to the neighbor and assign it the smaller one. 
---------------> For example, if the current node A is marked with a distance of 6, and the edge connecting it with a neighbor B has length 2, 
---------------> then the distance to B through A will be 6 + 2 = 8. 
---------------> If B was previously marked with a distance greater than 8 then change it to 8. 
---------------> Otherwise, the current value will be kept.
-------------> (4) When we are done considering all of the unvisited neighbors of the current node, mark the current node as visited and remove it from the unvisited set. 
---------------> A visited node will never be checked again (this is valid and optimal in connection with the behavior in step 6.
---------------> That the next nodes to visit will always be in the order of 'smallest distance from initial node first' so any visits after would have a greater distance).
-------------> (5) If the destination node has been marked visited (when planning a route between two specific nodes) 
---------------> or if the smallest tentative distance among the nodes in the unvisited set is infinity (when planning a complete traversal; 
---------------> occurs when there is no connection between the initial node and remaining unvisited nodes), then stop. 
---------------> The algorithm has finished.
-------------> (6) Otherwise, select the unvisited node that is marked with the smallest tentative distance, set it as the new current node, and go back to step 3.
-----------> When planning a route, it is actually not necessary to wait until the destination node is "visited" as above: 
-------------> the algorithm can stop once the destination node has the smallest tentative distance among all "unvisited" nodes (and thus could be selected as the next "current"). 
---------> Note: This was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.

-------> Floyd–Warshall algorithm: 
---------> This solves the all pairs shortest path problem in a weighted, directed graph.
---------> This an algorithm for finding shortest paths in a directed weighted graph with positive or negative edge weights (but with no negative cycles).
-----------> A single execution of the algorithm will find the lengths (summed weights) of shortest paths between all pairs of vertices. 
-----------> Although it does not return details of the paths themselves, it is possible to reconstruct the paths with simple modifications to the algorithm. 
-----------> Versions of the algorithm can also be used for finding the transitive closure of a relation R, or (in connection with the Schulze voting system) widest paths between all pairs of vertices in a weighted graph.
---------> Algorithm
-----------> The Floyd–Warshall algorithm compares all possible paths through the graph between each pair of vertices. 
-------------> It is able to do this with Θ(|V|^3) comparisons in a graph, even though there may be up to Ω(|V|^{2}) edges in the graph, and every combination of edges is tested. 
-------------> It does so by incrementally improving an estimate on the shortest path between two vertices, until the estimate is optimal.
-----------> Consider a graph G with vertices V numbered 1 through N. 
-------------> Further consider a function shortestPath(i, j, k) that returns the shortest possible path from i to j using vertices only from the set {1 , 2, …, k }  as intermediate points along the way. 
-------------> Now, given this function, our goal is to find the shortest path from each i to each j using any vertex in {1, 2, …, N}.
---------> For each of these pairs of vertices, the shortestPath(i, j, k) could be either
-----------> (1) a path that does not go through k (only uses vertices in the set {1, …, k−1}.)
-----------> or
-----------> (2) a path that does go through k (from i to k and then from k to j, both only using intermediate vertices in  {1, …, k−1})
---------> We know that the best path from i to j that only uses vertices 1 through k-1 is defined by shortestPath(i, j, k-1), 
-----------> and it is clear that if there was a better path from i to k to j, 
-----------> then the length of this path would be the concatenation of the shortest path from i to k (only using intermediate vertices in {1, …, k−1}) 
-----------> and the shortest path from k to j (only using intermediate vertices in  {1, …, k−1}).
---------> If w(i,j) is the weight of the edge between vertices i and j, we can define shortestPath(i, j, k) in terms of the following recursive formula: the base case is
-----------> shortestPath(i, j, 0)=w(i,j)
-----------> and the recursive case is
-----------> shortestPath(i, j, 0) = min(shortestPath(i, j, k-1), shortestPath(i, k, k-1) + shortestPath(k, j, k-1))
---------> This formula is the heart of the Floyd–Warshall algorithm. 
-----------> The algorithm works by first computing shortestPath(i, j, k) for all (i, j) pairs for k=1, then k=2, and so on. 
-----------> This process continues until k=N, and we have found the shortest path for all (i, j) pairs using any intermediate vertices. 
-----------> Pseudocode for this basic version follows:
-------------> let dist be a |V| × |V| array of minimum distances initialized to ∞ (infinity)
-------------> for each edge (u, v) do
------------->     dist[u][v] ← w(u, v)  // The weight of the edge (u, v)
-------------> for each vertex v do
------------->     dist[v][v] ← 0
-------------> for k from 1 to |V|
------------->     for i from 1 to |V|
------------->         for j from 1 to |V|
------------->             if dist[i][j] > dist[i][k] + dist[k][j] 
------------->                 dist[i][j] ← dist[i][k] + dist[k][j]
------------->             end if
-----------> Note: This is also known as Floyd's algorithm, the Roy–Warshall algorithm, the Roy–Floyd algorithm, or the WFI algorithm.

-------> Johnson's algorithm: 
---------> This provides an all pairs shortest path algorithm in sparse weighted directed graph
-----------> Johnson's algorithm is a way to find the shortest paths between all pairs of vertices in an edge-weighted directed graph. 
-----------> It allows some of the edge weights to be negative numbers, but no negative-weight cycles may exist. 
-----------> It works by using the Bellman–Ford algorithm to compute a transformation of the input graph that removes all negative weights, allowing Dijkstra's algorithm to be used on the transformed graph.
---------> A similar reweighting technique is also used in Suurballe's algorithm for finding two disjoint paths of minimum total length
-----------> between the same two vertices in a graph with non-negative edge weights.
---------> Johnson's algorithm consists of the following steps:
-----------> (1) First, a new node q is added to the graph, connected by zero-weight edges to each of the other nodes.
-----------> (2) Second, the Bellman–Ford algorithm is used, starting from the new vertex q, to find for each vertex v the minimum weight h(v) of a path from q to v. 
-------------> If this step detects a negative cycle, the algorithm is terminated.
-----------> (3) Next the edges of the original graph are reweighted using the values computed by the Bellman–Ford algorithm: 
-------------> an edge from u to v, having length w(u,v), is given the new length w(u,v) + h(u) − h(v).
-----------> (4) Finally, q is removed, and Dijkstra's algorithm is used to find the shortest paths from each node s to every other vertex in the reweighted graph. 
-------------> The distance in the original graph is then computed for each distance D(u , v), by adding h(v) − h(u) to the distance returned by Dijkstra's algorithm.
---------> Note: It is named after Donald B. Johnson, who first published the technique in 1977.



-----> Transitive closure problem
-------> This finds the transitive closure of a given binary relation
-------> In mathematics, the transitive closure of a binary relation R on a set X is the smallest relation on X that contains R and is transitive. 
---------> For finite sets, "smallest" can be taken in its usual sense, of having the fewest related pairs; for infinite sets it is the unique minimal transitive superset of R.
-------> For example, if X is a set of airports and x R y means "there is a direct flight from airport x to airport y" (for x and y in X), 
---------> then the transitive closure of R on X is the relation R+ such that x R+ y means "it is possible to fly from x to y in one or more flights". 
---------> Informally, the transitive closure gives you the set of all places you can get to from any starting place. 
-------> More formally, the transitive closure of a binary relation R on a set X is the transitive relation R+ on set X such that R+ contains R and R+ is minimal; see Lidl & Pilz (1998, p. 337).
---------> If the binary relation itself is transitive, then the transitive closure is that same binary relation; otherwise, the transitive closure is a different relation.
-------> Conversely, transitive reduction adduces a minimal relation S from a given relation R such that they have the same closure, that is, S+ = R+; however, many different S with this property may exist.
-------> Both transitive closure and transitive reduction are also used in the closely related area of graph theory. 



-----> Traveling salesman problem
-------> The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: 
---------> "Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?" 
---------> It is an NP-hard problem in combinatorial optimization, important in theoretical computer science and operations research.
-------> The travelling purchaser problem and the vehicle routing problem are both generalizations of TSP.
-------> In the theory of computational complexity, the decision version of the TSP (where given a length L, 
---------> the task is to decide whether the graph has a tour of at most L) belongs to the class of NP-complete problems. 
---------> Thus, it is possible that the worst-case running time for any algorithm for the TSP increases superpolynomially (but no more than exponentially) with the number of cities.
-------> The problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. 
---------> It is used as a benchmark for many optimization methods. 
---------> Even though the problem is computationally difficult, many heuristics and exact algorithms are known, 
---------> so that some instances with tens of thousands of cities can be solved completely and even problems with millions of cities can be approximated within a small fraction of 1%.
-------> The TSP has several applications even in its purest formulation, such as planning, logistics, and the manufacture of microchips. 
---------> Slightly modified, it appears as a sub-problem in many areas, such as DNA sequencing. 
---------> In these applications, the concept city represents, for example, customers, soldering points, or DNA fragments, 
-----------> and the concept distance represents travelling times or cost, or a similarity measure between DNA fragments. 
---------> The TSP also appears in astronomy, as astronomers observing many sources will want to minimize the time spent moving the telescope between the sources; 
-----------> in such problems, the TSP can be embedded inside an optimal control problem. 
---------> In many applications, additional constraints such as limited resources or time windows may be imposed.  

-------> Christofides algorithm
---------> The Christofides algorithm or Christofides–Serdyukov algorithm is an algorithm for finding approximate solutions to the travelling salesman problem, 
-----------> on instances where the distances form a metric space (they are symmetric and obey the triangle inequality). 
-----------> It is an approximation algorithm that guarantees that its solutions will be within a factor of 3/2 of the optimal solution length.
---------> This algorithm still stands as the best polynomial time approximation algorithm that has been thoroughly peer-reviewed 
-----------> by the relevant scientific community for the traveling salesman problem on general metric spaces. 
---------> Algorithm
-----------> Let G = (V,w) be an instance of the travelling salesman problem. 
-----------> That is, G is a complete graph on the set V of vertices, and the function w assigns a nonnegative real weight to every edge of G. 
-----------> According to the triangle inequality, for every three vertices u, v, and x, it should be the case that w(uv) + w(vx) ≥ w(ux).
-----------> Then the algorithm can be described in pseudocode as follows.
-------------> (1) Create a minimum spanning tree T of G.
-------------> (2) Let O be the set of vertices with odd degree in T. 
---------------> By the handshaking lemma, O has an even number of vertices.
-------------> (3) Find a minimum-weight perfect matching M in the induced subgraph given by the vertices from O.
---------------> A perfect matching in a graph is a matching that covers every vertex of the graph.
-------------> (4) Combine the edges of M and T to form a connected multigraph H in which each vertex has even degree.
-------------> (5) Form an Eulerian circuit in H.
-------------> (6) Make the circuit found in previous step into a Hamiltonian circuit by skipping repeated vertices (shortcutting).
---------> The steps 5 and 6 do not necessarily yield only one result. 
---------> As such the heuristic can give several different paths. 
---------> Note: This named after Nicos Christofides and Anatoliy I. Serdyukov, who discovered it independently in 1976.
---------> Note: In July 2020, Karlin, Klein, and Gharan released a preprint in which they introduced a novel approximation algorithm and claimed that its approximation ratio is 1.5 − 10−36. 
-----------> Their method follows similar principles to Christofides' algorithm, but uses a randomly chosen tree from a carefully chosen random distribution in place of the minimum spanning tree. 
-----------> The paper was published at STOC'21[7] where it received a best paper award.

-------> Nearest neighbour algorithm
---------> The nearest neighbour algorithm was one of the first algorithms used to solve the travelling salesman problem approximately. 
-----------> In that problem, the salesman starts at a random city and repeatedly visits the nearest city until all have been visited.
-----------> The algorithm quickly yields a short tour, but usually not the optimal one.
---------> Algorithm
-----------> These are the steps of the algorithm:
-------------> (1) Initialize all vertices as unvisited.
-------------> (2) Select an arbitrary vertex, set it as the current vertex u. Mark u as visited.
-------------> (3) Find out the shortest edge connecting the current vertex u and an unvisited vertex v.
-------------> (4) Set v as the current vertex u. Mark v as visited.
-------------> (5) If all the vertices in the domain are visited, then terminate. Else, go to step 3.
-----------> The sequence of the visited vertices is the output of the algorithm.
---------> The nearest neighbour algorithm is easy to implement and executes quickly, 
-----------> but it can sometimes miss shorter routes which are easily noticed with human insight, due to its "greedy" nature. 
-----------> As a general guide, if the last few stages of the tour are comparable in length to the first stages, 
-----------> then the tour is reasonable; if they are much greater, then it is likely that much better tours exist. 
-----------> Another check is to use an algorithm such as the lower bound algorithm to estimate if this tour is good enough.
---------> In the worst case, the algorithm results in a tour that is much longer than the optimal tour. 
-----------> To be precise, for every constant r there is an instance of the traveling salesman problem 
-----------> such that the length of the tour computed by the nearest neighbour algorithm is greater than r times the length of the optimal tour. 
-----------> Moreover, for each number of cities there is an assignment of distances between the cities for which the nearest neighbor heuristic produces the unique worst possible tour. 
-----------> (If the algorithm is applied on every vertex as the starting vertex, the best path found will be better than at least N/2-1 other tours, where N is the number of vertices.)
---------> The nearest neighbour algorithm may not find a feasible tour at all, even when one exists.
 
-----> Warnsdorff's rule: 
-------> This is a heuristic method for solving the Knight's tour problem.
-------> A knight's tour is a sequence of moves of a knight on a chessboard such that the knight visits every square exactly once. 
---------> If the knight ends on a square that is one knight's move from the beginning square (so that it could tour the board again immediately, following the same path), 
---------> the tour is closed (or re-entrant); otherwise, it is open.
-------> Warnsdorff's rule is a heuristic for finding a single knight's tour. 
---------> The knight is moved so that it always proceeds to the square from which the knight will have the fewest onward moves. 
---------> When calculating the number of onward moves for each candidate square, we do not count moves that revisit any square already visited.
---------> It is possible to have two or more choices for which the number of onward moves is equal; there are various methods for breaking such ties, 
---------> including one devised by Pohl[18] and another by Squirrel and Cull.
-------> This rule may also more generally be applied to any graph. 
---------> In graph-theoretic terms, each move is made to the adjacent vertex with the least degree. 
---------> Although the Hamiltonian path problem is NP-hard in general, on many graphs that occur in practice this heuristic is able to successfully locate a solution in linear time.
---------> The knight's tour is such a special case.
-------> The heuristic was first described in "Des Rösselsprungs einfachste und allgemeinste Lösung" by H. C. von Warnsdorff in 1823.[21]
---------> A computer program that finds a knight's tour was written by Gordon Horsington and published in 1984 in the book Century/Acorn User Book of Computer Puzzles.



---> Graph search

-----> A*
-------> This special case of best-first search that uses heuristics to improve speed.
-------> A* (pronounced "A-star") is a graph traversal and path search algorithm, 
---------> which is often used in many fields of computer science due to its completeness, optimality, and optimal efficiency. 
---------> One major practical drawback is its O ( b d ) {\displaystyle O(b^{d})} O(b^d) space complexity, as it stores all generated nodes in memory. 
---------> Thus, in practical travel-routing systems, it is generally outperformed by algorithms which can pre-process the graph to attain better performance, as well as memory-bounded approaches; 
---------> however, A* is still the best solution in many cases.
-------> Compared to Dijkstra's algorithm, the A* algorithm only finds the shortest path from a specified source to a specified goal, 
---------> and not the shortest-path tree from a specified source to all possible goals. 
---------> This is a necessary trade-off for using a specific-goal-directed heuristic. 
---------> For Dijkstra's algorithm, since the entire shortest-path tree is generated, every node is a goal, and there can be no specific-goal-directed heuristic. 
-------> Algorithm:
---------> A* is an informed search algorithm, or a best-first search, meaning that it is formulated in terms of weighted graphs: 
-----------> starting from a specific starting node of a graph, it aims to find a path to the given goal node having the smallest cost (least distance travelled, shortest time, etc.). 
-----------> It does this by maintaining a tree of paths originating at the start node and extending those paths one edge at a time until its termination criterion is satisfied.
---------> At each iteration of its main loop, A* needs to determine which of its paths to extend. 
-----------> It does so based on the cost of the path and an estimate of the cost required to extend the path all the way to the goal. 
-----------> Specifically, A* selects the path that minimizes:
-------------> f(n)=g(n)+h(n)
-----------> where n is the next node on the path, g(n) is the cost of the path from the start node to n, 
-----------> and h(n) is a heuristic function that estimates the cost of the cheapest path from n to the goal. 
-----------> A* terminates when the path it chooses to extend is a path from start to goal or if there are no paths eligible to be extended. 
-----------> The heuristic function is problem-specific. 
-----------> If the heuristic function is admissible – meaning that it never overestimates the actual cost to get to the goal –, 
-----------> A* is guaranteed to return a least-cost path from start to goal.
---------> Typical implementations of A* use a priority queue to perform the repeated selection of minimum (estimated) cost nodes to expand. 
-----------> This priority queue is known as the open set or fringe. 
-----------> At each step of the algorithm, the node with the lowest f(x) value is removed from the queue, 
-----------> the f and g values of its neighbors are updated accordingly, and these neighbors are added to the queue. 
-----------> The algorithm continues until a removed node (thus the node with the lowest f value out of all fringe nodes) is a goal node. 
-----------> The f value of that goal is then also the cost of the shortest path, since h at the goal is zero in an admissible heuristic.
---------> The algorithm described so far gives us only the length of the shortest path. 
-----------> To find the actual sequence of steps, the algorithm can be easily revised so that each node on the path keeps track of its predecessor. 
-----------> After this algorithm is run, the ending node will point to its predecessor, and so on, until some node's predecessor is the start node.
---------> As an example, when searching for the shortest route on a map, h(x) might represent the straight-line distance to the goal, 
-----------> since that is physically the smallest possible distance between any two points. 
-----------> For a grid map from a video game, using the Manhattan distance or the octile distance becomes better depending on the set of movements available (4-way or 8-way).
---------> If the heuristic h satisfies the additional condition h(x) ≤ d(x, y) + h(y) 
-----------> for every edge (x, y) of the graph (where d denotes the length of that edge), then h is called monotone, or consistent. 
-----------> With a consistent heuristic, A* is guaranteed to find an optimal path without processing any node more than once 
-----------> and A* is equivalent to running Dijkstra's algorithm with the reduced cost d'(x, y) = d(x, y) + h(y) − h(x).
---------> Pseudocode
-----------> function reconstruct_path(cameFrom, current)
----------->     total_path := {current}
----------->     while current in cameFrom.Keys:
----------->         current := cameFrom[current]
----------->         total_path.prepend(current)
----------->     return total_path
-----------> // A* finds a path from start to goal.
-----------> // h is the heuristic function. h(n) estimates the cost to reach goal from node n.
-----------> function A_Star(start, goal, h)
----------->     // The set of discovered nodes that may need to be (re-)expanded.
----------->     // Initially, only the start node is known.
----------->     // This is usually implemented as a min-heap or priority queue rather than a hash-set.
----------->     openSet := {start}
----------->     // For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start
----------->     // to n currently known.
----------->     cameFrom := an empty map
----------->     // For node n, gScore[n] is the cost of the cheapest path from start to n currently known.
----------->     gScore := map with default value of Infinity
----------->     gScore[start] := 0
----------->     // For node n, fScore[n] := gScore[n] + h(n). fScore[n] represents our current best guess as to
----------->     // how cheap a path could be from start to finish if it goes through n.
----------->     fScore := map with default value of Infinity
----------->     fScore[start] := h(start)
----------->     while openSet is not empty
----------->         // This operation can occur in O(Log(N)) time if openSet is a min-heap or a priority queue
----------->         current := the node in openSet having the lowest fScore[] value
----------->         if current = goal
----------->             return reconstruct_path(cameFrom, current)
----------->         openSet.Remove(current)
----------->         for each neighbor of current
----------->             // d(current,neighbor) is the weight of the edge from current to neighbor
----------->             // tentative_gScore is the distance from start to the neighbor through current
----------->             tentative_gScore := gScore[current] + d(current, neighbor)
----------->             if tentative_gScore < gScore[neighbor]
----------->                 // This path to neighbor is better than any previous one. Record it!
----------->                 cameFrom[neighbor] := current
----------->                 gScore[neighbor] := tentative_gScore
----------->                 fScore[neighbor] := tentative_gScore + h(neighbor)
----------->                 if neighbor not in openSet
----------->                     openSet.add(neighbor)
----------->     // Open set is empty but goal was never reached
----------->     return failure
---------> Remark: In this pseudocode, if a node is reached by one path, removed from openSet, 
-----------> and subsequently reached by a cheaper path, it will be added to openSet again. 
-----------> This is essential to guarantee that the path returned is optimal if the heuristic function is admissible but not consistent. 
-----------> If the heuristic is consistent, when a node is removed from openSet the path to it is guaranteed to be optimal 
-----------> so the test ‘tentative_gScore < gScore[neighbor]’ will always fail if the node is reached again. 
-------> Note: Peter Hart, Nils Nilsson and Bertram Raphael of Stanford Research Institute (now SRI International) first published the algorithm in 1968.
---------> It can be seen as an extension of Dijkstra's algorithm. 
---------> A* achieves better performance by using heuristics to guide its search.

-----> B*: 
-------> This is a best-first graph search algorithm that finds the least-cost path from a given initial node to any goal node (out of one or more possible goals).
-------> The algorithm stores intervals for nodes of the tree as opposed to single point-valued estimates. 
---------> Then, leaf nodes of the tree can be searched until one of the top level nodes has an interval which is clearly "best." 
-------> Note: First published by Hans Berliner in 1979, it is related to the A* search algorithm. 

-----> Backtracking: 
-------> This abandons partial solutions when they are found not to satisfy a complete solution
-------> Backtracking is a general algorithm for finding solutions to some computational problems, notably constraint satisfaction problems, 
---------> that incrementally builds candidates to the solutions, and abandons a candidate ("backtracks") 
---------> as soon as it determines that the candidate cannot possibly be completed to a valid solution.
-------> The classic textbook example of the use of backtracking is the eight queens puzzle, 
---------> that asks for all arrangements of eight chess queens on a standard chessboard so that no queen attacks any other. 
---------> In the common backtracking approach, the partial candidates are arrangements of k queens in the first k rows of the board, all in different rows and columns. 
---------> Any partial solution that contains two mutually attacking queens can be abandoned.
-------> Backtracking can be applied only for problems which admit the concept of a "partial candidate solution" 
---------> and a relatively quick test of whether it can possibly be completed to a valid solution. 
---------> It is useless, for example, for locating a given value in an unordered table. 
---------> When it is applicable, however, backtracking is often much faster than brute-force enumeration of all complete candidates, since it can eliminate many candidates with a single test.
-------> Backtracking is an important tool for solving constraint satisfaction problems, such as crosswords, verbal arithmetic, Sudoku, and many other puzzles. 
---------> It is often the most convenient technique for parsing, for the knapsack problem and other combinatorial optimization problems. 
---------> It is also the basis of the so-called logic programming languages such as Icon, Planner and Prolog.
-------> Backtracking depends on user-given "black box procedures" that define the problem to be solved, 
---------> the nature of the partial candidates, and how they are extended into complete candidates. 
---------> It is therefore a metaheuristic rather than a specific algorithm – although, unlike many other meta-heuristics, 
---------> it is guaranteed to find all solutions to a finite problem in a bounded amount of time.
-------> Algorithm:
---------> The backtracking algorithm enumerates a set of partial candidates that, in principle, 
---------> could be completed in various ways to give all the possible solutions to the given problem. 
-----------> The completion is done incrementally, by a sequence of candidate extension steps.
---------> Conceptually, the partial candidates are represented as the nodes of a tree structure, the potential search tree. 
-----------> Each partial candidate is the parent of the candidates that differ from it by a single extension step; 
-----------> the leaves of the tree are the partial candidates that cannot be extended any further.
---------> The backtracking algorithm traverses this search tree recursively, from the root down, in depth-first order. 
-----------> At each node c, the algorithm checks whether c can be completed to a valid solution. 
-----------> If it cannot, the whole sub-tree rooted at c is skipped (pruned). 
-----------> Otherwise, the algorithm (1) checks whether c itself is a valid solution, and if so reports it to the user; 
-----------> and (2) recursively enumerates all sub-trees of c. 
-----------> The two tests and the children of each node are defined by user-given procedures.
---------> Therefore, the actual search tree that is traversed by the algorithm is only a part of the potential tree. 
-----------> The total cost of the algorithm is the number of nodes of the actual tree times the cost of obtaining and processing each node. 
-----------> This fact should be considered when choosing the potential search tree and implementing the pruning test.
-----------> Pseudocode:
-----------> In order to apply backtracking to a specific class of problems, one must provide the data P for the particular instance of the problem that is to be solved, 
-------------> and six procedural parameters, root, reject, accept, first, next, and output. 
-------------> These procedures should take the instance data P as a parameter and should do the following:
---------------> root(P): return the partial candidate at the root of the search tree.
---------------> reject(P,c): return true only if the partial candidate c is not worth completing.
---------------> accept(P,c): return true if c is a solution of P, and false otherwise.
---------------> first(P,c): generate the first extension of candidate c.
---------------> next(P,s): generate the next alternative extension of a candidate, after the extension s.
---------------> output(P,c): use the solution c of P, as appropriate to the application.
-----------> The backtracking algorithm reduces the problem to the call backtrack(root(P)), where backtrack is the following recursive procedure:
-------------> procedure backtrack(c) is
------------->     if reject(P, c) then return
------------->     if accept(P, c) then output(P, c)
------------->     s ← first(P, c)
------------->     while s ≠ NULL do
------------->         backtrack(s)
------------->         s ← next(P, s)
-----------> Usage considerations
-------------> The reject procedure should be a boolean-valued function that returns true only if it is certain that no possible extension of c is a valid solution for P. 
---------------> If the procedure cannot reach a definite conclusion, it should return false. 
---------------> An incorrect true result may cause the backtrack procedure to miss some valid solutions. 
---------------> The procedure may assume that reject(P,t) returned false for every ancestor t of c in the search tree.
-------------> On the other hand, the efficiency of the backtracking algorithm depends on reject returning true for candidates that are as close to the root as possible. 
---------------> If reject always returns false, the algorithm will still find all solutions, but it will be equivalent to a brute-force search.
-------------> The accept procedure should return true if c is a complete and valid solution for the problem instance P, and false otherwise. 
---------------> It may assume that the partial candidate c and all its ancestors in the tree have passed the reject test.
-------------> The general pseudo-code above does not assume that the valid solutions are always leaves of the potential search tree. 
---------------> In other words, it admits the possibility that a valid solution for P can be further extended to yield other valid solutions.
-------------> The first and next procedures are used by the backtracking algorithm to enumerate the children of a node c of the tree, 
---------------> that is, the candidates that differ from c by a single extension step. 
---------------> The call first(P,c) should yield the first child of c, in some order; and the call next(P,s) should return the next sibling of node s, in that order. 
---------------> Both functions should return a distinctive "NULL" candidate, if the requested child does not exist.
-------------> Together, the root, first, and next functions define the set of partial candidates and the potential search tree. 
---------------> They should be chosen so that every solution of P occurs somewhere in the tree, and no partial candidate occurs more than once. 
---------------> Moreover, they should admit an efficient and effective reject predicate.
-----------> Early stopping variants
-------------> The pseudo-code above will call output for all candidates that are a solution to the given instance P. 
---------------> The algorithm can be modified to stop after finding the first solution, or a specified number of solutions; 
---------------> or after testing a specified number of partial candidates, or after spending a given amount of CPU time. 
-------> Note: The term "backtrack" was coined by American mathematician D. H. Lehmer in the 1950s.[4] 
---------> The pioneer string-processing language SNOBOL (1962) may have been the first to provide a built-in general backtracking facility. 

-----> Beam search: 
-------> This is a heuristic search algorithm that is an optimization of best-first search that reduces its memory requirement
-------> The beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. 
---------> Beam search is an optimization of best-first search that reduces its memory requirements. 
---------> Best-first search is a graph search which orders all partial solutions (states) according to some heuristic.
---------> But in beam search, only a predetermined number of best partial solutions are kept as candidates.
---------> It is thus a greedy algorithm.
-------> Algorithm:
---------> Beam search uses breadth-first search to build its search tree.
-----------> At each level of the tree, it generates all successors of the states at the current level, sorting them in increasing order of heuristic cost.
-----------> However, it only stores a predetermined number, β, of best states at each level (called the beam width). 
-----------> Only those states are expanded next. 
-----------> greater the beam width, the fewer states are pruned. 
-----------> With an infinite beam width, no states are pruned and beam search is identical to breadth-first search. 
-----------> The beam width bounds the memory required to perform the search. 
-----------> Since a goal state could potentially be pruned, beam search sacrifices completeness (the guarantee that an algorithm will terminate with a solution, if one exists). 
-----------> Beam search is not optimal (that is, there is no guarantee that it will find the best solution).
-------> Applications:
---------> A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree.
-----------> For example, it has been used in many machine translation systems. (The state of the art now primarily uses neural machine translation based methods.) 
-----------> To select the best translation, each part is processed, and many different ways of translating the words appear. 
-----------> The top best translations according to their sentence structures are kept, and the rest are discarded. 
-----------> The translator then evaluates the translations according to a given criterion, choosing the translation which best keeps the goals. 
-------> Note: The term "beam search" was coined by Raj Reddy of Carnegie Mellon University in 1977.[2] 
-------> Note: The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976.[7] 

-----> Beam stack search: 
-------> This integrates backtracking with beam search
-------> Beam stack search is a search algorithm that combines chronological backtracking (that is, depth-first search) with beam search and is similar to depth-first beam search.
---------> Both search algorithms are anytime algorithms that find good but likely sub-optimal solutions quickly, 
---------> like beam search, then backtrack and continue to find improved solutions until convergence to an optimal solution. 
-------> Implementation
---------> Beam stack search uses the beam stack as a data structure to integrate chronological backtracking with beam search 
-----------> and can be combined with the divide and conquer algorithm technique, 
-----------> resulting in divide-and-conquer beam-stack search. 
-------> Alternatives
---------> Beam search using limited discrepancy backtracking (BULB) is a search algorithm that combines limited discrepancy search with beam search 
-----------> and thus performs non-chronological backtracking, which often outperforms the chronological backtracking done by beam stack search and depth-first beam search. 

-----> Best-first search: 
-------> This traverses a graph in the order of likely importance using a priority queue.
---------> Best-first search is a class of search algorithms, which explore a graph by expanding the most promising node chosen according to a specified rule.
-------> Some authors have used "best-first search" to refer specifically to a search with a heuristic that attempts to predict how close the end of a path is to a solution (or, goal),
---------> so that paths which are judged to be closer to a solution (or, goal) are extended first. 
---------> This specific type of search is called greedy best-first search or pure heuristic search.
-------> Efficient selection of the current best candidate for extension is typically implemented using a priority queue.
-------> The A* search algorithm is an example of a best-first search algorithm, as is B*. 
---------> Best-first algorithms are often used for path finding in combinatorial search. 
---------> Neither A* nor B* is a greedy best-first search, as they incorporate the distance from the start in addition to estimated distances to the goal. 
-------> Greedy BFS
---------> Using a greedy algorithm, expand the first successor of the parent.
---------> After a successor is generated:
-----------> If the successor's heuristic is better than its parent, 
-------------> the successor is set at the front of the queue (with the parent reinserted directly behind it), and the loop restarts.
-----------> Else, the successor is inserted into the queue (in a location determined by its heuristic value). 
-------------> The procedure will evaluate the remaining successors (if any) of the parent.
---------> Below is a pseudocode example of this algorithm, where queue represents a priority queue which orders nodes based on their heuristic distances from the goal. 
---------> This implementation keeps track of visited nodes, and can therefore be used for undirected graphs. It can be modified to retrieve the path.
-----------> procedure GBS(start, target) is:
----------->   mark start as visited
----------->   add start to queue
----------->   while queue is not empty do:
----------->     current_node ← vertex of queue with min distance to target
----------->     remove current_node from queue
----------->     foreach neighbor n of current_node do:
----------->       if n not in visited then:
----------->         if n is target:
----------->           return n
----------->         else:
----------->           mark n as visited
----------->           add n to queue
----------->   return failure 
-------> Note: Judea Pearl described the best-first search as estimating the promise of node n by a "heuristic evaluation function f(n) which, in general, 
---------> may depend on the description of n, the description of the goal, 
---------> the information gathered by the search up to that point, and most importantly, on any extra knowledge about the problem domain."


-----> Bidirectional search: 
-------> This find the shortest path from an initial vertex to a goal vertex in a directed graph.
---------> Bidirectional search is a graph search algorithm that finds a shortest path from an initial vertex to a goal vertex in a directed graph. 
---------> It runs two simultaneous searches: one forward from the initial state, and one backward from the goal, stopping when the two meet. 
---------> The reason for this approach is that in many cases it is faster: 
-----------> for instance, in a simplified model of search problem complexity in which both searches expand a tree with branching factor b,
-----------> and the distance from start to goal is d, each of the two searches has complexity O(bd/2) (in Big O notation), 
-----------> and the sum of these two search times is much less than the O(bd) complexity that would result from a single search from the beginning to the goal.
-------> As in A* search, bi-directional search can be guided by a heuristic estimate of the remaining distance to the goal (in the forward tree) or from the start (in the backward tree).
-------> Description
---------> A Bidirectional Heuristic Search is a state space search from some state s to another state t, searching from s to t and from t to s simultaneously. 
-----------> It returns a valid list of operators that if applied to s will give us t.
---------> While it may seem as though the operators have to be invertible for the reverse search, 
-----------> it is only necessary to be able to find, given any node n, 
-----------> the set of parent nodes of n such that there exists some valid operator from each of the parent nodes to n. 
-----------> This has often been likened to a one-way street in the route-finding domain: 
-----------> it is not necessary to be able to travel down both directions, but it is necessary when standing at the end of the street 
-----------> to determine the beginning of the street as a possible route.
---------> Similarly, for those edges that have inverse arcs (i.e. arcs going in both directions) it is not necessary that each direction be of equal cost. 
-----------> The reverse search will always use the inverse cost (i.e. the cost of the arc in the forward direction). 
-----------> More formally, if n is a node with parent p, then k1(p,n)=k2(n,p), defined as being the cost from p to n.
-------> Note: Andrew Goldberg and others explained the correct termination conditions for the bidirectional version of Dijkstra’s Algorithm.
---------> Ira Pohl (1971) was the first one to design and implement a bi-directional heuristic search algorithm.
---------> Search trees emanating from the start and goal nodes failed to meet in the middle of the solution space. 
---------> The BHFFA algorithm fixed this defect Champeaux (1977).
-------> Note: A solution found by the uni-directional A* algorithm using an admissible heuristic has a shortest path length; 
---------> the same property holds for the BHFFA2 bidirectional heuristic version described in de Champeaux (1983). 
---------> BHFFA2 has, among others, more careful termination conditions than BHFFA. 

-----> Breadth-first search: 
-------> This traverses a graph level by level.
-------> Breadth-first search (BFS) is an algorithm for searching a tree data structure for a node that satisfies a given property. 
---------> It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level. 
---------> Extra memory, usually a queue, is needed to keep track of the child nodes that were encountered but not yet explored.
-------> For example, in a chess endgame a chess engine may build the game tree from the current position by applying all possible moves, 
---------> and use breadth-first search to find a win position for white.
---------> Implicit trees (such as game trees or other problem-solving trees) may be of infinite size; 
---------> breadth-first search is guaranteed to find a solution node[1] if one exists.
-------> In contrast, (plain) depth-first search, which explores the node branch as far as possible before backtracking and expanding other nodes,
---------> may get lost in an infinite branch and never make it to the solution node. 
---------> Iterative deepening depth-first search avoids the latter drawback at the price of exploring the tree's top parts over and over again. 
---------> On the other hand, both depth-first algorithms get along without extra memory.
-------> Breadth-first search can be generalized to graphs, when the start node (sometimes referred to as a 'search key') is explicitly given, 
---------> and precautions are taken against following a vertex twice.
-------> Pseudocode
---------> Input: A graph G and a starting vertex root of G
---------> Output: Goal state. The parent links trace the shortest path back to root[8]
--------->  1  procedure BFS(G, root) is
--------->  2      let Q be a queue
--------->  3      label root as explored
--------->  4      Q.enqueue(root)
--------->  5      while Q is not empty do
--------->  6          v := Q.dequeue()
--------->  7          if v is the goal then
--------->  8              return v
--------->  9          for all edges from v to w in G.adjacentEdges(v) do
---------> 10              if w is not labeled as explored then
---------> 11                  label w as explored
---------> 12                  Q.enqueue(w)
-------> More details
---------> This non-recursive implementation is similar to the non-recursive implementation of depth-first search, but differs from it in two ways:
-----------> it uses a queue (First In First Out) instead of a stack and
-----------> it checks whether a vertex has been explored before enqueueing the vertex rather than delaying this check until the vertex is dequeued from the queue.
---------> If G is a tree, replacing the queue of this breadth-first search algorithm with a stack will yield a depth-first search algorithm. 
-----------> For general graphs, replacing the stack of the iterative depth-first search implementation 
-----------> with a queue would also produce a breadth-first search algorithm, although a somewhat nonstandard one.
---------> The Q queue contains the frontier along which the algorithm is currently searching.
-----------> Nodes can be labelled as explored by storing them in a set, or by an attribute on each node, depending on the implementation.
-----------> Note that the word node is usually interchangeable with the word vertex.
-----------> The parent attribute of each node is useful for accessing the nodes in a shortest path, 
-----------> for example by backtracking from the destination node up to the starting node, once the BFS has been run, 
-----------> and the predecessors nodes have been set.
---------> Breadth-first search produces a so-called breadth first tree. 
-------> BFS and its application in finding connected components of graphs were invented in 1945 by Konrad Zuse, 
---------> in his (rejected) Ph.D. thesis on the Plankalkül programming language, but this was not published until 1972. 
---------> It was reinvented in 1959 by Edward F. Moore, who used it to find the shortest path out of a maze,
---------> and later developed by C. Y. Lee into a wire routing algorithm (published 1961).



-----> Brute-force search: 
-------> This An exhaustive and reliable search method, but computationally inefficient in many applications.
-------> Brute-force search or exhaustive search, also known as generate and test, 
---------> is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution 
---------> and checking whether each candidate satisfies the problem's statement.
-------> A brute-force algorithm that finds the divisors of a natural number n would enumerate all integers from 1 to n, 
---------> and check whether each of them divides n without remainder.
---------> A brute-force approach for the eight queens puzzle would examine all possible arrangements of 8 pieces on the 64-square chessboard 
---------> and for each arrangement, check whether each (queen) piece can attack any other.
-------> While a brute-force search is simple to implement and will always find a solution if it exists, 
---------> implementation costs are proportional to the number of candidate solutions,
---------> which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion).
---------> Therefore, brute-force search is typically used when the problem size is limited, 
---------> or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size. 
---------> The method is also used when the simplicity of implementation is more important than speed.
-------> This is the case, for example, in critical applications where any errors in the algorithm would have very serious consequences or when using a computer to prove a mathematical theorem. 
---------> Brute-force search is also useful as a baseline method when benchmarking other algorithms or metaheuristics. 
---------> Indeed, brute-force search can be viewed as the simplest metaheuristic. 
---------> Brute force search should not be confused with backtracking, 
---------> where large sets of solutions can be discarded without being explicitly enumerated (as in the textbook computer solution to the eight queens problem above). 
---------> The brute-force method for finding an item in a table – namely, check all entries of the latter, sequentially – is called linear search. 
-------> Basic algorithm
---------> In order candidate for P after the current one c.
-----------> valid (P, c): check whether candidate c is a solution for P.
-----------> output (P, c): use the solution c of P as appropriate to the application.
---------> The next procedure must also tell when there are no more candidates for the instance P, after the current one c.
---------> A convenient way to do that is to return a "null candidate", some conventional data value Λ that is distinct from any real candidate. 
---------> Likewise the first procedure should return Λ if there are no candidates at all for the instance P. 
---------> The brute-force method is then expressed by the algorithm:
-----------> c ← first(P)
-----------> while c ≠ Λ do
----------->     if valid(P,c) then
----------->         output(P, c)
----------->     c ← next(P, c)
-----------> end while
---------> For example, when looking for the divisors of an integer n, the instance data P is the number n. 
-----------> The call first(n) should return the integer 1 if n ≥ 1, or Λ otherwise; the call next(n,c) should return c + 1 if c < n, and Λ otherwise; 
-----------> and valid(n,c) should return true if and only if c is a divisor of n. (In fact, if we choose Λ to be n + 1, the tests n ≥ 1 and c < n are unnecessary.)
-----------> The brute-force search algorithm above will call output for every candidate that is a solution to the given instance P. 
-----------> The algorithm is easily modified to stop after finding the first solution, or a specified number of solutions; 
-----------> or after testing a specified number of candidates, or after spending a given amount of CPU time. 

-----> D*: 
-------> This an incremental heuristic search algorithm.
-------> D* (pronounced "D star") is any one of the following three related incremental search algorithms:
---------> The original D*,[1] by Anthony Stentz, is an informed incremental search algorithm.
---------> Focused D*[2] is an informed incremental heuristic search algorithm by Anthony Stentz that combines ideas of A* and the original D*. 
-----------> Focused D* resulted from a further development of the original D*.
---------> D* Lite[4] is an incremental heuristic search algorithm by Sven Koenig and Maxim Likhachev that builds on LPA*,
-----------> an incremental heuristic search algorithm that combines ideas of A* and Dynamic SWSF-FP.[6]
-------> All three search algorithms solve the same assumption-based path planning problems, 
---------> including planning with the freespace assumption, 
---------> where a robot has to navigate to given goal coordinates in unknown terrain. 
-------> It makes assumptions about the unknown part of the terrain (for example: that it contains no obstacles) 
---------> and finds a shortest path from its current coordinates to the goal coordinates under these assumptions. 
---------> The robot then follows the path. 
---------> When it observes new map information (such as previously unknown obstacles), it adds the information to its map 
---------> and, if necessary, replans a new shortest path from its current coordinates to the given goal coordinates. 
---------> It repeats the process until it reaches the goal coordinates or determines that the goal coordinates cannot be reached. 
---------> When traversing unknown terrain, new obstacles may be discovered frequently, so this replanning needs to be fast. 
---------> Incremental (heuristic) search algorithms speed up searches for sequences of similar search problems by
---------> using experience with the previous problems to speed up the search for the current one. 
---------> Assuming the goal coordinates do not change, all three search algorithms are more efficient than repeated A* searches.
-------> D* and its variants have been widely used for mobile robot and autonomous vehicle navigation.
---------> Current systems are typically based on D* Lite rather than the original D* or Focused D*. 
---------> In fact, even Stentz's lab uses D* Lite rather than D* in some implementations. 
---------> Such navigation systems include a prototype system tested on the Mars rovers Opportunity 
---------> and Spirit and the navigation system of the winning entry in the DARPA Urban Challenge, both developed at Carnegie Mellon University.
-------> Operation
---------> The basic operation of D* is outlined below.
---------> Like Dijkstra's algorithm and A*, D* maintains a list of nodes to be evaluated, known as the "OPEN list". 
---------> Nodes are marked as having one of several states:
-----------> NEW, meaning it has never been placed on the OPEN list
-----------> OPEN, meaning it is currently on the OPEN list
-----------> CLOSED, meaning it is no longer on the OPEN list
-----------> RAISE, indicating its cost is higher than the last time it was on the OPEN list
-----------> LOWER, indicating its cost is lower than the last time it was on the OPEN list
-------> Note: The original D* was introduced by Anthony Stentz in 1994. 
---------> The name D* comes from the term "Dynamic A*", because the algorithm behaves like A* except that the arc costs can change as the algorithm runs. 

-----> Depth-first search: 
-------> This traverses a graph branch by branch.
-------> Depth-first search (DFS) is an algorithm for traversing or searching tree or graph data structures. 
---------> The algorithm starts at the root node (selecting some arbitrary node as the root node in the case of a graph) 
---------> and explores as far as possible along each branch before backtracking. 
---------> Extra memory, usually a stack, is needed to keep track of the nodes discovered so far along a specified branch which helps in backtracking of the graph.
-------> Properties
-------> The time and space analysis of DFS differs according to its application area. 
---------> DFS is typically used to traverse an entire graph, and takes time O(|V|+|E|),[4] where |V| is the number of vertices and |E| the number of edges. 
---------> This is linear in the size of the graph. 
---------> In these applications it also uses space O(|V|) in the worst case to store the stack of vertices 
---------> on the current search path as well as the set of already-visited vertices. 
---------> Thus, in this setting, the time and space bounds are the same as for breadth-first search
---------> and the choice of which of these two algorithms to use depends less on their complexity 
---------> and more on the different properties of the vertex orderings the two algorithms produce.
-------> For applications of DFS in relation to specific domains, such as searching for solutions in artificial intelligence or web-crawling, 
---------> the graph to be traversed is often either too large to visit in its entirety or infinite (DFS may suffer from non-termination). 
---------> In such cases, search is only performed to a limited depth; due to limited resources, such as memory or disk space, 
---------> one typically does not use data structures to keep track of the set of all previously visited vertices. 
---------> When search is performed to a limited depth, the time is still linear in terms of the number of expanded vertices and edges 
---------> (although this number is not the same as the size of the entire graph because some vertices may be searched more than once and others not at all) 
---------> but the space complexity of this variant of DFS is only proportional to the depth limit,
---------> and as a result, is much smaller than the space needed for searching to the same depth using breadth-first search. 
---------> For such applications, DFS also lends itself much better to heuristic methods for choosing a likely-looking branch. 
---------> When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits. 
---------> In the artificial intelligence mode of analysis, with a branching factor greater than one, 
---------> iterative deepening increases the running time by only a constant factor over the case in which the correct depth limit is known due to the geometric growth of the number of nodes per level.
-------> DFS may also be used to collect a sample of graph nodes. 
---------> However, incomplete DFS, similarly to incomplete BFS, is biased towards nodes of high degree. 
-------> Note: A version of depth-first search was investigated in the 19th century by French mathematician Charles Pierre Trémaux[1] as a strategy for solving mazes.

-----> Dijkstra's algorithm:
-------> This is special case of A* for which no heuristic function is used
-------> Dijkstra's algorithm is discussed above.

-----> General Problem Solver: 
-------> This a seminal theorem-proving algorithm intended to work as a universal problem solver machine.
-------> General Problem Solver (GPS) is a computer program  intended to work as a universal problem solver machine. 
---------> In contrast to the former Logic Theorist project, the GPS works with means–ends analysis.[
---------> Any problem that can be expressed as a set of well-formed formulas (WFFs) or Horn clauses, 
---------> and that constitute a directed graph with one or more sources (that is, axioms) and sinks (that is, desired conclusions), can be solved, in principle, by GPS. 
---------> Proofs in the predicate logic and Euclidean geometry problem spaces are prime examples of the domain the applicability of GPS. 
---------> It was based on Simon and Newell's theoretical work on logic machines.
---------> GPS was the first computer program which separated its knowledge of problems (rules represented as input data) from its strategy of how to solve problems (a generic solver engine). 
---------> GPS was implemented in the third-order programming language, IPL.
-------> While GPS solved simple problems such as the Towers of Hanoi that could be sufficiently formalized, 
---------> it could not solve any real-world problems because search was easily lost in the combinatorial explosion. 
---------> Put another way, the number of "walks" through the inferential digraph became computationally untenable. 
---------> (In practice, even a straightforward state space search such as the Towers of Hanoi can become computationally infeasible, 
---------> albeit judicious prunings of the state space can be achieved by such elementary AI techniques as A* and IDA*).
-------> The user defined objects and operations that could be done on the objects, and GPS generated heuristics by means-ends analysis in order to solve problems. 
---------> It focused on the available operations, finding what inputs were acceptable and what outputs were generated. It then created subgoals to get closer and closer to the goal.
-------> The GPS paradigm eventually evolved into the Soar architecture for artificial intelligence. 
-------> Note: This was created in 1959 by Herbert A. Simon, J. C. Shaw, and Allen Newell (RAND Corporation)

-----> Iterative deepening depth-first search (IDDFS): 
-------> This a state space search strategy.
-------> Iterative deepening search or more specifically iterative deepening depth-first search (IDS or IDDFS) 
---------> is a state space/graph search strategy in which a depth-limited version of depth-first search is run repeatedly with increasing depth limits until the goal is found. 
---------> IDDFS is optimal like breadth-first search, but uses much less memory; at each iteration, it visits the nodes in the search tree in the same order as depth-first search, 
---------> but the cumulative order in which nodes are first visited is effectively breadth-first.
-------> Algorithm for directed graphs
---------> The following pseudocode shows IDDFS implemented in terms of a recursive depth-limited DFS (called DLS) for directed graphs. 
---------> This implementation of IDDFS does not account for already-visited nodes and therefore does not work for undirected graphs.
-----------> function IDDFS(root) is
----------->     for depth from 0 to ∞ do
----------->         found, remaining ← DLS(root, depth)
----------->         if found ≠ null then
----------->             return found
----------->         else if not remaining then
----------->             return null
-----------> function DLS(node, depth) is
----------->     if depth = 0 then
----------->         if node is a goal then
----------->             return (node, true)
----------->         else
----------->             return (null, true)    (Not found, but may have children)
----------->     else if depth > 0 then
----------->         any_remaining ← false
----------->         foreach child of node do
----------->             found, remaining ← DLS(child, depth−1)
----------->             if found ≠ null then
----------->                 return (found, true)   
----------->             if remaining then
----------->                 any_remaining ← true    (At least one node found at depth, let IDDFS deepen)
----------->         return (null, any_remaining)
---------> If the goal node is found, then DLS unwinds the recursion returning with no further iterations. 
-----------> Otherwise, if at least one node exists at that level of depth, the remaining flag will let IDDFS continue.
---------> 2-tuples are useful as return value to signal IDDFS to continue deepening or stop, in case tree depth and goal membership are unknown a priori. 
-----------> Another solution could use sentinel values instead to represent not found or remaining level results. 

-----> Jump point search:
-------> This an optimization to A* which may reduce computation time by an order of magnitude using further heuristics. 
-------> Jump point search (JPS) is an optimization to the A* search algorithm for uniform-cost grids. 
---------> It reduces symmetries in the search procedure by means of graph pruning,
---------> eliminating certain nodes in the grid based on assumptions that can be made about the current node's neighbors, 
---------> as long as certain conditions relating to the grid are satisfied. 
---------> As a result, the algorithm can consider long "jumps" along straight (horizontal, vertical and diagonal) lines in the grid, 
---------> rather than the small steps from one grid position to the next that ordinary A* considers.
-------> Jump point search preserves A*'s optimality, while potentially reducing its running time by an order of magnitude.

-----> Lexicographic breadth-first search (also known as Lex-BFS): 
-------> This is a linear time algorithm for ordering the vertices of a graph.
-------> Lexicographic breadth-first search or Lex-BFS is a linear time algorithm for ordering the vertices of a graph. 
---------> The algorithm is different from a breadth-first search, but it produces an ordering that is consistent with breadth-first search.
-------> Background
---------> The breadth-first search algorithm is commonly defined by the following process:
-----------> Initialize a queue of graph vertices, with the starting vertex of the graph as the queue's only element.
-----------> While the queue is non-empty, remove (dequeue) a vertex v from the queue, and add to the queue (enqueue) 
---------> all the other vertices that can be reached by an edge from v that have not already been added in earlier steps.
---------> However, rather than defining the vertex to choose at each step in an imperative way as the one produced by the dequeue operation of a queue, 
---------> one can define the same sequence of vertices declaratively by the properties of these vertices. 
---------> That is, a standard breadth-first search is just the result of repeatedly applying this rule:
-----------> Repeatedly output a vertex v, choosing at each step a vertex v that has not already been chosen 
-----------> and that has a predecessor (a vertex that has an edge to v) as early in the output as possible.
---------> In some cases, this ordering of vertices by the output positions of their predecessors may have ties
-----------> two different vertices have the same earliest predecessor. 
---------> In this case, the order in which those two vertices are chosen may be arbitrary. 
---------> The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties. 
---------> In lexicographic breadth-first search, the output ordering is the order that would be produced by the rule:
-----------> Repeatedly output a vertex v, choosing at each step a vertex v that has not already been chosen 
---------> and whose entire set of already-output predecessors is as small as possible in lexicographic order.
---------> So, when two vertices v and w have the same earliest predecessor, earlier than any other unchosen vertices, 
-----------> the standard breadth-first search algorithm will order them arbitrarily. 
-----------> Instead, in this case, the LexBFS algorithm would choose between v and w by the output ordering of their second-earliest predecessors. 
-----------> If only one of them has a second-earliest predecessor that has already been output, that one is chosen. 
-----------> If both v and w have the same second-earliest predecessor, then the tie is broken by considering their third-earliest predecessors, and so on.
---------> Applying this rule directly by comparing vertices according to this rule would lead to an inefficient algorithm. 
-----------> Instead, the lexicographic breadth-first search uses a set partitioning data structure in order to produce the same ordering more efficiently, 
-----------> just as a standard breadth-first search uses a queue data structure to produce its ordering efficiently.
-------> Algorithm
---------> The lexicographic breadth-first search algorithm replaces 
---------> the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices. 
---------> The sets in the sequence form a partition of the remaining vertices. 
---------> At each step, a vertex v from the first set in the sequence is removed from that set, 
---------> and if that removal causes the set to become empty then the set is removed from the sequence. 
---------> Then, each set in the sequence is replaced by two subsets: the neighbors of v and the non-neighbors of v. 
---------> The subset of neighbors is placed earlier in the sequence than the subset of non-neighbors. 
---------> In pseudocode, the algorithm can be expressed as follows:
-----------> Initialize a sequence Σ of sets, to contain a single set containing all vertices.
-----------> Initialize the output sequence of vertices to be empty.
-----------> While Σ is non-empty:
----------->     Find and remove a vertex v from the first set in Σ
----------->     If the first set in Σ is now empty, remove it from Σ
----------->     Add v to the end of the output sequence.
----------->     For each edge v-w such that w still belongs to a set S in Σ:
----------->         If the set S containing w has not yet been replaced while processing v, 
----------->         create a new empty replacement set T and place it prior to S in the sequence; otherwise, let T be the set prior to S.
----------->         Move w from S to T, and if this causes S to become empty remove S from Σ.
-------> Each vertex is processed once, each edge is examined only when its two endpoints are processed, 
---------> and (with an appropriate representation for the sets in Σ that allows items to be moved from one set to another in constant time) 
---------> each iteration of the inner loop takes only constant time. 
---------> Therefore, like simpler graph search algorithms such as breadth-first search and depth first search, this algorithm takes linear time.
-------> The algorithm is called lexicographic breadth-first search because the order it produces is an ordering that could also have been produced by a breadth-first search, 
---------> and because if the ordering is used to index the rows and columns of an adjacency matrix of a graph then the algorithm sorts the rows and columns into lexicographical order. 
-------> Note: The lexicographic breadth-first search algorithm is based on the idea of partition refinement and was first developed by Donald J. Rose, Robert E. Tarjan, and George S. Lueker (1976).
---------> A more detailed survey of the topic is presented by Corneil (2004). 
---------> It has been used as a subroutine in other graph algorithms including the recognition of chordal graphs, and optimal coloring of distance-hereditary graphs. 

-----> Uniform-cost search: 
-------> This a tree search that finds the lowest-cost route where costs vary.
-------> In common presentations of Dijkstra's algorithm, initially all nodes are entered into the priority queue. 
---------> This is, however, not necessary: the algorithm can start with a priority queue that contains only one item, and insert new items as they are discovered 
---------> instead of doing a decrease-key, check whether the key is in the queue; if it is, decrease its key, otherwise insert it).
---------> This variant has the same worst-case bounds as the common variant, but maintains a smaller priority queue in practice, speeding up the queue operations.
-------> Moreover, not inserting all nodes in a graph makes it possible to extend the algorithm to find the shortest path from a single source 
---------> to the closest of a set of target nodes on infinite graphs or those too large to represent in memory. 
---------> The resulting algorithm is called uniform-cost search (UCS) in the artificial intelligence literature and can be expressed in pseudocode as
-----------> procedure uniform_cost_search(start) is
----------->     node ← start
----------->     frontier ← priority queue containing node only
----------->     expanded ← empty set
----------->     do
----------->         if frontier is empty then
----------->             return failure
----------->         node ← frontier.pop()
----------->         if node is a goal state then
----------->             return solution(node)
----------->         expanded.add(node)
----------->         for each of node's neighbors n do
----------->             if n is not in expanded and not in frontier then
----------->                 frontier.add(n)
----------->             else if n is in frontier with higher cost
----------->                 replace existing node with n
-------> The complexity of this algorithm can be expressed in an alternative way for very large graphs:
---------> when C* is the length of the shortest path from the start node to any node satisfying the "goal" predicate, each edge has cost at least ε, 
---------> and the number of neighbors per node is bounded by b, then the algorithm's worst-case time and space complexity are both in O(b1+⌊C* ⁄ ε⌋).
-------> Further optimizations of Dijkstra's algorithm for the single-target case include bidirectional variants, 
---------> goal-directed variants such as the A* algorithm (see § Related problems and algorithms), 
---------> graph pruning to determine which nodes are likely to form the middle segment of shortest paths (reach-based routing), 
---------> and hierarchical decompositions of the input graph that reduce s–t routing to connecting s and t to their respective "transit nodes" 
---------> followed by shortest-path computation between these transit nodes using a "highway".
---------> Combinations of such techniques may be needed for optimal practical performance on specific problems.

-----> SSS*: 
-------> This state space search traversing a game tree in a best-first fashion similar to that of the A* search algorithm.
-------> SSS* is a search algorithm that conducts a state space search traversing a game tree in a best-first fashion similar to that of the A* search algorithm. 
-------> SSS* is based on the notion of solution trees. 
-------> Informally, a solution tree can be formed from any arbitrary game tree by pruning the number of branches at each MAX node to one. 
---------> Such a tree represents a complete strategy for MAX, since it specifies exactly one MAX action for every possible sequence of moves made by the opponent. 
---------> Given a game tree, SSS* searches through the space of partial solution trees, gradually analyzing larger and larger subtrees, 
---------> eventually producing a single solution tree with the same root and Minimax value as the original game tree. 
---------> SSS* never examines a node that alpha-beta pruning would prune, and may prune some branches that alpha-beta would not. 
---------> Stockman speculated that SSS* may therefore be a better general algorithm than alpha-beta. 
---------> However, Igor Roizen and Judea Pearl have shown that the savings in the number of positions that SSS*
---------> evaluates relative to alpha/beta is limited and generally not enough to compensate for the increase in other resources 
---------> (e.g., the storing and sorting of a list of nodes made necessary by the best-first nature of the algorithm). 
---------> However, Aske Plaat, Jonathan Schaeffer, Wim Pijls and Arie de Bruin have shown that a sequence of null-window alpha-beta calls is equivalent to SSS* 
---------> (i.e., it expands the same nodes in the same order) when alpha-beta is used with a transposition table, as is the case in all game-playing programs for chess, checkers, etc. 
---------> Now the storing and sorting of the OPEN list were no longer necessary. 
---------> This allowed the implementation of (an algorithm equivalent to) SSS* in tournament quality game-playing programs. 
---------> Experiments showed that it did indeed perform better than Alpha-Beta in practice, but that it did not beat NegaScout.
-------> The reformulation of a best-first algorithm as a sequence of depth-first calls prompted 
---------> the formulation of a class of null-window alpha-beta algorithms, of which MTD(f) is the best known example. 
-------> Algorithm
---------> There is a priority queue OPEN that stores states (J, s, h) or the nodes, 
---------> where J - node identificator (Dot-decimal notation is used to identify nodes, ϵ is a root), 
---------> s is an element of {L,S} - state of the node J (L - the node is live, which means it's not solved yet and S - the node is solved), 
---------> h ∈ (− ∞ , ∞) - value of the solved node. 
---------> Items in OPEN queue are sorted descending by their h value. 
---------> If more than one node has the same value of h, a node left-most in the tree is chosen.
-----------> OPEN := { (e, L, inf) }
-----------> while true do   // repeat until stopped
----------->     pop an element p=(J, s, h) from the head of the OPEN queue
----------->     if J = e and s = S then
----------->         STOP the algorithm and return h as a result
----------->     else
----------->         apply Gamma operator for p
---------> Γ/Gamma operator for p=(J, s, h) is defined in the following way:
-----------> if s = L then
----------->     if J is a terminal node then
----------->         (1.) add (J, S, min(h, value(J))) to OPEN
----------->     else if J is a MIN node then
----------->         (2.) add (J.1, L, h) to OPEN
----------->     else
----------->         (3.) for j=1..number_of_children(J) add (J.j, L, h) to OPEN
-----------> else
----------->     if J is a MIN node then
----------->         (4.) add (parent(J), S, h) to OPEN
----------->              remove from OPEN all the states that are associated with the children of parent(J)
----------->     else if is_last_child(J) then   // if J is the last child of parent(J)
----------->         (5.) add (parent(J), S, h) to OPEN
----------->     else
----------->         (6.) add (parent(J).(k+1), L, h) to OPEN   // add state associated with the next child of parent(J) to OPEN
-------> Note: This was introduced by George Stockman in 1979



---> Subgraphs

-----> Cliques
-------> A clique (/ˈkliːk/ or /ˈklɪk/) is a subset of vertices of an undirected graph such that every TWO distinct vertices in the clique are adjacent. 
---------> Me: So basically every vertex is adjacent to any other vertex.
---------> That is, a clique of a graph G is an induced subgraph of G that is complete. 
---------> Cliques are one of the basic concepts of graph theory and are used in many other mathematical problems and constructions on graphs. 
---------> Task of finding whether there is a clique of a given size in a graph (the clique problem) is NP-complete, 
---------> but despite this hardness result, many algorithms for finding cliques have been studied.
-------> Although the study of complete subgraphs goes back at least to the graph-theoretic reformulation of Ramsey theory by Erdős & Szekeres (1935), 
---------> the term clique comes from Luce & Perry (1949), who used complete subgraphs in social networks to model cliques of people; t
---------> hat is, groups of people all of whom know each other. 
---------> Cliques have many other applications in the sciences and particularly in bioinformatics. 
-------> Definitions
---------> A clique, C, in an undirected graph G = (V, E) is a subset of the vertices, C is an element of V, such that every two distinct vertices are adjacent. 
-----------> This is equivalent to the condition that the induced subgraph of G induced by C is a complete graph. 
-----------> In some cases, the term clique may also refer to the subgraph directly.
---------> A maximal clique is a clique that cannot be extended by including one more adjacent vertex, 
-----------> that is, a clique which does not exist exclusively within the vertex set of a larger clique. 
-----------> Some authors define cliques in a way that requires them to be maximal, and use other terminology for complete subgraphs that are not maximal.
---------> A maximum clique of a graph, G, is a clique, such that there is no clique with more vertices. 
-----------> Moreover, the clique number ω(G) of a graph G is the number of vertices in a maximum clique in G.
---------> The intersection number of G is the smallest number of cliques that together cover all edges of G.
---------> The clique cover number of a graph G is the smallest number of cliques of G whose union covers the set of vertices V of the graph.
---------> A maximum clique transversal of a graph is a subset of vertices with the property that each maximum clique of the graph contains at least one vertex in the subset.
---------> The opposite of a clique is an independent set, in the sense that every clique corresponds to an independent set in the complement graph.
-----------> The clique cover problem concerns finding as few cliques as possible that include every vertex in the graph.
---------> A related concept is a biclique, a complete bipartite subgraph. 
-----------> The bipartite dimension of a graph is the minimum number of bicliques needed to cover all the edges of the graph. 

-------> Bron–Kerbosch algorithm: 
---------> This a technique for finding maximal cliques in an undirected graph.
---------> The Bron–Kerbosch algorithm is an enumeration algorithm for finding all maximal cliques in an undirected graph. 
-----------> That is, it lists all subsets of vertices with the two properties that each pair of vertices in one of the listed subsets is connected by an edge, 
-----------> and no listed subset can have any additional vertices added to it while preserving its complete connectivity. 
-----------> The Bron–Kerbosch algorithm was designed by Dutch scientists Coenraad Bron and Joep Kerbosch, who published its description in 1973.
---------> Although other algorithms for solving the clique problem have running times that are, 
-----------> in theory, better on inputs that have few maximal independent sets, the Bron–Kerbosch algorithm
-----------> and subsequent improvements to it are frequently reported as being more efficient in practice than the alternatives. 
-----------> It is well-known and widely used in application areas of graph algorithms such as computational chemistry.
---------> Without pivoting
-----------> The basic form of the Bron–Kerbosch algorithm is a recursive backtracking algorithm that searches for all maximal cliques in a given graph G. 
-------------> More generally, given three disjoint sets of vertices R, P, and X, 
-------------> it finds the maximal cliques that include all of the vertices in R, some of the vertices in P, and none of the vertices in X. 
-------------> In each call to the algorithm, P and X are disjoint sets whose union consists of those vertices that form cliques when added to R. 
-------------> In other words, P ∪ X is the set of vertices which are joined to every element of R. 
-------------> When P and X are both empty there are no further elements that can be added to R, so R is a maximal clique and the algorithm outputs R.
-----------> The recursion is initiated by setting R and X to be the empty set and P to be the vertex set of the graph. 
-------------> Within each recursive call, the algorithm considers the vertices in P in turn; if there are no such vertices, it either reports R as a maximal clique (if X is empty), or backtracks. 
-------------> For each vertex v chosen from P, it makes a recursive call in which v is added to R and in which P and X are restricted to the neighbor set N(v) of v, 
-------------> which finds and reports all clique extensions of R that contain v. 
-------------> Then, it moves v from P to X to exclude it from consideration in future cliques and continues with the next vertex in P.
-----------> That is, in pseudocode, the algorithm performs the following steps:
-------------> algorithm BronKerbosch1(R, P, X) is
------------->     if P and X are both empty then
------------->         report R as a maximal clique
------------->     for each vertex v in P do
------------->         BronKerbosch1(R union {v}, P intersection N(v), X intersection N(v))
------------->         P := P \ {v}
------------->         X := X union {v}
---------> With pivoting
-----------> The basic form of the algorithm, described above, is inefficient in the case of graphs with many non-maximal cliques: it makes a recursive call for every clique, maximal or not. 
-----------> To save time and allow the algorithm to backtrack more quickly in branches of the search that contain no maximal cliques, 
-----------> Bron and Kerbosch introduced a variant of the algorithm involving a "pivot vertex" u, chosen from P (or more generally, as later investigators realized,[4] from P union of X). 
-----------> Any maximal clique must include either u or one of its non-neighbors, for otherwise the clique could be augmented by adding u to it. 
-----------> Therefore, only u and its non-neighbors need to be tested as the choices for the vertex v that is added to R in each recursive call to the algorithm. 
-----------> In pseudocode:
-------------> algorithm BronKerbosch2(R, P, X) is
------------->     if P and X are both empty then
------------->         report R as a maximal clique
------------->     choose a pivot vertex u in P union X
------------->     for each vertex v in P \ N(u) do
------------->         BronKerbosch2(R union {v}, P intersection N(v), X intersection N(v))
------------->         P := P \ {v}
------------->         X := X union {v}
-----------> If the pivot is chosen to minimize the number of recursive calls made by the algorithm, 
-----------> the savings in running time compared to the non-pivoting version of the algorithm can be significant.
---------> With vertex ordering
-----------> An alternative method for improving the basic form of the Bron–Kerbosch algorithm involves forgoing pivoting at the outermost level of recursion, 
-------------> and instead choosing the ordering of the recursive calls carefully in order to minimize the sizes of the sets P of candidate vertices within each recursive call.
-----------> The degeneracy of a graph G is the smallest number d such that every subgraph of G has a vertex with degree d or less. 
-------------> Every graph has a degeneracy ordering, an ordering of the vertices such that each vertex has d or fewer neighbors that come later in the ordering; 
-------------> a degeneracy ordering may be found in linear time by repeatedly selecting the vertex of minimum degree among the remaining vertices. 
-------------> If the order of the vertices v that the Bron–Kerbosch algorithm loops through is a degeneracy ordering, 
-------------> then the set P of candidate vertices in each call (the neighbors of v that are later in the ordering) will be guaranteed to have size at most d. 
-------------> The set X of excluded vertices will consist of all earlier neighbors of v, and may be much larger than d. 
-------------> In recursive calls to the algorithm below the topmost level of the recursion, the pivoting version can still be used.
-----------> In pseudocode, the algorithm performs the following steps:
-------------> algorithm BronKerbosch3(G) is
------------->     P = V(G)
------------->     R = X = empty
------------->     for each vertex v in a degeneracy ordering of G do
------------->         BronKerbosch2({v}, P is an element of N(v), X is an element of N(v))
------------->         P := P \ {v}
------------->         X := X union {v}
-----------> This variant of the algorithm can be proven to be efficient for graphs of small degeneracy,
-------------> and experiments show that it also works well in practice for large sparse social networks and other real-world graphs.
---------> Note: A contemporaneous algorithm of Akkoyunlu (1973), although presented in different terms, 
-----------> can be viewed as being the same as the Bron–Kerbosch algorithm, as it generates the same search tree.

-------> MaxCliqueDyn maximum clique algorithm: 
---------> This finds a maximum clique in an undirected graph.
---------> The MaxCliqueDyn algorithm is an algorithm for finding a maximum clique in an undirected graph. 
-----------> It is based on a basic algorithm (MaxClique algorithm) which finds a maximum clique of bounded size. 
-----------> The bound is found using improved coloring algorithm. 
-----------> The MaxCliqueDyn extends MaxClique algorithm to include dynamically varying bounds. 
-----------> In comparison to earlier algorithms described in the published article the MaxCliqueDyn algorithm 
-------------> is improved by an improved approximate coloring algorithm (ColorSort algorithm) 
-----------> and by applying tighter, more computationally expensive upper bounds on a fraction of the search space. 
-----------> Both improvements reduce time to find maximum clique. 
-----------> In addition to reducing time improved coloring algorithm also reduces the number of steps needed to find a maximum clique.
---------> MaxClique algorithm
-----------> The MaxClique algorithm is the basic algorithm of MaxCliqueDyn algorithm. 
-----------> The pseudo code of the algorithm is:
-----------> procedure MaxClique(R, C) is
----------->     Q = Ø; Qmax = Ø;
----------->     while R ≠ Ø do
----------->         choose a vertex p with a maximum color C(p) from set R;
----------->         R := R\{p};
----------->         if |Q| + C(p)>|Qmax| then
----------->             Q := Q union {p};
----------->             if R intersection Γ(p) ≠ Ø then
----------->                 obtain a vertex-coloring C' of G(R intersection Γ(p));
----------->                 MaxClique(R ⋂ Γ(p), C');
----------->             else if |Q|>|Qmax| then Qmax:=Q;
----------->             Q := Q\{p};
----------->         else
----------->             return
----------->     end while
-----------> where Q is a set of vertices of the currently growing clique, 
-----------> Qmax is a set of vertices of the largest clique currently found, R is a set of candidate vertices and C its corresponding set of color classes. 
-----------> The MaxClique algorithm recursively searches for maximum clique by adding and removing vertices to and from Q. 
---------> Note: This algorithm was designed by Janez Konc and description was published in 2007. 

-------> Strongly connected components
---------> In the mathematical theory of directed graphs, a graph is said to be strongly connected if every vertex is reachable from every other vertex. 
-----------> The strongly connected components of an arbitrary directed graph form a partition into subgraphs that are themselves strongly connected. 
-----------> It is possible to test the strong connectivity of a graph, or to find its strongly connected components, in linear time (that is, Θ(V + E)).
---------> A directed graph is called strongly connected if there is a path in each direction between each pair of vertices of the graph. 
-----------> That is, a path exists from the first vertex in the pair to the second, and another path exists from the second vertex to the first. 
-----------> In a directed graph G that may not itself be strongly connected, a pair of vertices u and v are said to be strongly connected to each other if there is a path in each direction between them.
---------> The binary relation of being strongly connected is an equivalence relation, and the induced subgraphs of its equivalence classes are called strongly connected components. 
-----------> Equivalently, a strongly connected component of a directed graph G is a subgraph that is strongly connected, and is maximal with this property: 
-----------> no additional edges or vertices from G can be included in the subgraph without breaking its property of being strongly connected. 
-----------> The collection of strongly connected components forms a partition of the set of vertices of G. 
-----------> A strongly connected component C is called trivial when C consists of a single vertex which is not connected to itself with an edge and non-trivial otherwise.
---------> If each strongly connected component is contracted to a single vertex, the resulting graph is a directed acyclic graph, the condensation of G. 
-----------> A directed graph is acyclic if and only if it has no strongly connected subgraphs with more than one vertex, 
-----------> because a directed cycle is strongly connected and every non-trivial strongly connected component contains at least one directed cycle. 
---------> Algorithms
-----------> DFS-based linear-time algorithms
-------------> Several algorithms based on depth first search compute strongly connected components in linear time.
-------------> (1) Kosaraju's algorithm uses two passes of depth first search. 
---------------> The first, in the original graph, is used to choose the order in which the outer loop of the second depth first search
---------------> tests vertices for having been visited already and recursively explores them if not. 
---------------> The second depth first search is on the transpose graph of the original graph, and each recursive exploration finds a single new strongly connected component.[2][3] 
---------------> It is named after S. Rao Kosaraju, who described it (but did not publish his results) in 1978; Micha Sharir later published it in 1981.[4]
-------------> (2) Tarjan's strongly connected components algorithm, published by Robert Tarjan in 1972, performs a single pass of depth first search. 
---------------> It maintains a stack of vertices that have been explored by the search but not yet assigned to a component, 
---------------> and calculates "low numbers" of each vertex (an index number of the highest ancestor reachable in one step from a descendant of the vertex) 
-------------> which it uses to determine when a set of vertices should be popped off the stack into a new component.
-------------> (3) The path-based strong component algorithm uses a depth first search, like Tarjan's algorithm, but with two stacks. 
---------------> One of the stacks is used to keep track of the vertices not yet assigned to components, while the other keeps track of the current path in the depth first search tree. 
---------------> The first linear time version of this algorithm was published by Edsger W. Dijkstra in 1976.[6]
-------------> Although Kosaraju's algorithm is conceptually simple, Tarjan's and the path-based algorithm require only one depth-first search rather than two.
-----------> Reachability-based algorithms
-------------> Previous linear-time algorithms are based on depth-first search which is generally considered hard to parallelize. 
---------------> Fleischer et al.[7] in 2000 proposed a divide-and-conquer approach based on reachability queries, 
---------------> and such algorithms are usually called reachability-based SCC algorithms. 
---------------> The idea of this approach is to pick a random pivot vertex and apply forward and backward reachability queries from this vertex. 
---------------> The two queries partition the vertex set into 4 subsets: vertices reached by both, either one, or none of the searches. 
---------------> One can show that a strongly connected component has to be contained in one of the subsets. 
---------------> The vertex subset reached by both searches forms a strongly connected component, and the algorithm then recurses on the other 3 subsets.
-------------> The expected sequential running time of this algorithm is shown to be O(n log n), a factor of O(log n) more than the classic algorithms. 
---------------> The parallelism comes from: (1) the reachability queries can be parallelized more easily (e.g. by a breadth-first search (BFS), 
---------------> and it can be fast if the diameter of the graph is small); and (2) the independence between the subtasks in the divide-and-conquer process. 
---------------> This algorithm performs well on real-world graphs,[3] but does not have theoretical guarantee on the parallelism 
---------------> (consider if a graph has no edges, the algorithm requires O(n) levels of recursions).
-------------> Blelloch et al.[8] in 2016 shows that if the reachability queries are applied in a random order, the cost bound of O(n log n) still holds. 
---------------> Furthermore, the queries then can be batched in a prefix-doubling manner (i.e. 1, 2, 4, 8 queries) and run simultaneously in one round. 
---------------> The overall span of this algorithm is log2 n reachability queries, which is probably the optimal parallelism that can be achieved using the reachability-based approach
-----------> Generating random strongly connected graphs
-------------> Peter M. Maurer describes an algorithm for generating random strongly connected graphs, 
-------------> based on a modification of an algorithm for strong connectivity augmentation, 
-------------> the problem of adding as few edges as possible to make a graph strongly connected. 
-------------> When used in conjunction with the Gilbert or Erdős-Rényi models with node relabelling, 
-------------> the algorithm is capable of generating any strongly connected graph on n nodes, 
-------------> without restriction on the kinds of structures that can be generated. 

---------> Path-based strong component algorithm
-----------> In graph theory, the strongly connected components of a directed graph may be found using an algorithm that uses depth-first search in combination with two stacks, 
-------------> one to keep track of the vertices in the current component and the second to keep track of the current search path.
-------------> The algorithm performs a depth-first search of the given graph G, maintaining as it does two stacks S and P (in addition to the normal call stack for a recursive function). 
-------------> Stack S contains all the vertices that have not yet been assigned to a strongly connected component, in the order in which the depth-first search reaches the vertices. 
-------------> Stack P contains vertices that have not yet been determined to belong to different strongly connected components from each other. 
-------------> It also uses a counter C of the number of vertices reached so far, which it uses to compute the preorder numbers of the vertices.
-----------> When the depth-first search reaches a vertex v, the algorithm performs the following steps:
-------------> Set the preorder number of v to C, and increment C.
-------------> Push v onto S and also onto P.
-------------> For each edge from v to a neighboring vertex w:
------------->     If the preorder number of w has not yet been assigned (the edge is a tree edge), recursively search w;
------------->     Otherwise, if w has not yet been assigned to a strongly connected component (the edge is a forward/back/cross edge):
------------->         Repeatedly pop vertices from P until the top element of P has a preorder number less than or equal to the preorder number of w.
-------------> If v is the top element of P:
------------->     Pop vertices from S until v has been popped, and assign the popped vertices to a new component.
------------->     Pop v from P.
-----------> The overall algorithm consists of a loop through the vertices of the graph, 
-------------> calling this recursive search on each vertex that does not yet have a preorder number assigned to it. 

---------> Kosaraju's algorithm
-----------> Kosaraju-Sharir's algorithm  is a linear time algorithm to find the strongly connected components of a directed graph. 
-------------> Kosaraju suggested it in 1978 but did not publish it, while Sharir independently discovered it and published it in 1981. 
-------------> It makes use of the fact that the transpose graph (the same graph with the direction of every edge reversed) has exactly the same strongly connected components as the original graph. 
-----------> The primitive graph operations that the algorithm uses are to enumerate the vertices of the graph, 
-------------> to store data per vertex (if not in the graph data structure itself, then in some table that can use vertices as indices), 
-------------> to enumerate the out-neighbours of a vertex (traverse edges in the forward direction), 
-------------> and to enumerate the in-neighbours of a vertex (traverse edges in the backward direction); 
-------------> however the last can be done without,
-------------> at the price of constructing a representation of the transpose graph during the forward traversal phase. 
-------------> The only additional data structure needed by the algorithm is an ordered list L of graph vertices, that will grow to contain each vertex once.
-----------> If strong components are to be represented by appointing a separate root vertex for each component, 
-----------> and assigning to each vertex the root vertex of its component, then Kosaraju's algorithm can be stated as follows:
-------------> For each vertex u of the graph, mark u as unvisited. Let L be empty.
-------------> For each vertex u of the graph do Visit(u), where Visit(u) is the recursive subroutine:
------------->     If u is unvisited then:
------------->         Mark u as visited.
------------->         For each out-neighbour v of u, if v is unvisited, do Visit(v).
------------->         Prepend u to L.
------------->     Otherwise do nothing.
-------------> For each element u of L in order, do Assign(u,u) where Assign(u,root) is the recursive subroutine:
------------->     If u has not been assigned to a component then:
------------->         Assign u as belonging to the component whose root is root.
------------->         For each in-neighbour v of u, do Assign(v,root).
------------->     Otherwise do nothing.
-----------> Note: Versions of this algorithm have been proposed by Purdom (1970), Munro (1971), Dijkstra (1976), Cheriyan & Mehlhorn (1996), and Gabow (2000); of these, 
-------------> Dijkstra's version was the first to achieve linear time.
-----------> Note: This also known as Kosaraju's algorithm.
-----------> Note: Aho, Hopcroft and Ullman credit it to S. Rao Kosaraju and Micha Sharir. 

---------> Tarjan's strongly connected components algorithm
-----------> Tarjan's strongly connected components algorithm is an algorithm in graph theory for finding the strongly connected components (SCCs) of a directed graph. 
-------------> It runs in linear time, matching the time bound for alternative methods including Kosaraju's algorithm and the path-based strong component algorithm. 
-----------> The algorithm takes a directed graph as input, and produces a partition of the graph's vertices into the graph's strongly connected components. 
-------------> Each vertex of the graph appears in exactly one of the strongly connected components. 
-------------> Any vertex that is not on a directed cycle forms a strongly connected component all by itself: 
-------------> for example, a vertex whose in-degree or out-degree is 0, or any vertex of an acyclic graph.
-----------> The basic idea of the algorithm is this: 
-------------> A depth-first search (DFS) begins from an arbitrary start node (and subsequent depth-first searches are conducted on any nodes that have not yet been found). 
-------------> As usual with depth-first search, the search visits every node of the graph exactly once, declining to revisit any node that has already been visited. 
-------------> Thus, the collection of search trees is a spanning forest of the graph. 
-------------> The strongly connected components will be recovered as certain subtrees of this forest. 
-------------> The roots of these subtrees are called the "roots" of the strongly connected components. 
-------------> Any node of a strongly connected component might serve as a root, if it happens to be the first node of a component that is discovered by search. 
-----------> Note: The algorithm is named for its inventor, Robert Tarjan.

-------> Subgraph isomorphism problem
---------> The subgraph isomorphism problem is a computational task in which two graphs G and H are given as input, 
-----------> and one must determine whether G contains a subgraph that is isomorphic (me: this means the same) to H. 
-----------> Subgraph isomorphism is a generalization of both the maximum clique problem and the problem of testing whether a graph contains a Hamiltonian cycle, and is therefore NP-complete. 
-----------> However certain other cases of subgraph isomorphism may be solved in polynomial time.
---------> Sometimes the name subgraph matching is also used for the same problem. This name puts emphasis on finding such a subgraph as opposed to the bare decision problem. 
---------> Decision problem and computational complexity
-----------> To prove subgraph isomorphism is NP-complete, it must be formulated as a decision problem. 
-----------> The input to the decision problem is a pair of graphs G and H. The answer to the problem is positive if H is isomorphic to a subgraph of G, and negative otherwise.
-----------> Formal question:
-------------> Let G = (V, E), H = (V′, E′) be graphs. 
---------------> Is there a subgraph G0 = (V0, E0) ∣ V0 is a subset of V , E0 is a subset of E ∩ (V0 × V0) G0 congruent with H? 
---------------> I. e., does there exist a bijection f : V0 → V′ such that {v1, v2} an element of E0 ⟺ {f(v1), f(v2)} an element of E′ ?
-------------> The proof of subgraph isomorphism being NP-complete is simple and based on reduction of the clique problem, 
---------------> an NP-complete decision problem in which the input is a single graph G and a number k, and the question is whether G contains a complete subgraph with k vertices. 
---------------> To translate this to a subgraph isomorphism problem, simply let H be the complete graph Kk; 
---------------> then the answer to the subgraph isomorphism problem for G and H is equal to the answer to the clique problem for G and k. 
---------------> Since the clique problem is NP-complete, this polynomial-time many-one reduction shows that subgraph isomorphism is also NP-complete.
-------------> An alternative reduction from the Hamiltonian cycle problem translates a graph G which is to be tested for Hamiltonicity into the pair of graphs G and H, 
---------------> where H is a cycle having the same number of vertices as G. 
---------------> Because the Hamiltonian cycle problem is NP-complete even for planar graphs, this shows that subgraph isomorphism remains NP-complete even in the planar case.
-------------> Subgraph isomorphism is a generalization of the graph isomorphism problem, which asks whether G is isomorphic to H: 
---------------> the answer to the graph isomorphism problem is true if and only if G and H both have the same numbers of vertices and edges and the subgraph isomorphism problem for G and H is true. 
---------------> However the complexity-theoretic status of graph isomorphism remains an open question.
-------------> In the context of the Aanderaa–Karp–Rosenberg conjecture on the query complexity of monotone graph properties, 
---------------> Gröger (1992) showed that any subgraph isomorphism problem has query complexity Ω(n3/2); 
---------------> that is, solving the subgraph isomorphism requires an algorithm to check the presence or absence in the input of Ω(n3/2) different edges in the graph.
---------> Algorithms
-----------> Ullmann (1976) describes a recursive backtracking procedure for solving the subgraph isomorphism problem. 
-------------> Although its running time is, in general, exponential, it takes polynomial time for any fixed choice of H (with a polynomial that depends on the choice of H). 
-------------> When G is a planar graph (or more generally a graph of bounded expansion) and H is fixed, the running time of subgraph isomorphism can be reduced to linear time.[2]
-----------> Ullmann (2010) is a substantial update to the 1976 subgraph isomorphism algorithm paper.
-----------> Cordella (2004) proposed in 2004 another algorithm based on Ullmann's, VF2, which improves the refinement process using different heuristics and uses significantly less memory.
-----------> Bonnici (2013) proposed a better algorithm, which improves the initial order of the vertices using some heuristics.
-----------> The current state of the art solver for moderately-sized, hard instances is the Glasgow Subgraph Solver (McCreesh (2020)).
-------------> This solver adopts a constraint programming approach, using bit-parallel data structures and specialized propagation algorithms for performance. 
-------------> It supports most common variations of the problem and is capable of counting or enumerating solutions as well as deciding whether one exists.
-----------> For large graphs, state-of-the art algorithms include CFL-Match and Turboiso, and extensions thereupon such as DAF by Han (2019). 



---> Sequence algorithms

-----> Approximate sequence matching

-----> Bitap algorithm: 
-------> This is a fuzzy algorithm that determines if strings are approximately equal.
-------> The bitap algorithm (also known as the shift-or, shift-and or Baeza-Yates–Gonnet algorithm) is an approximate string matching algorithm. 
---------> The algorithm tells whether a given text contains a substring which is "approximately equal" to a given pattern, 
---------> where approximate equality is defined in terms of Levenshtein distance,
---------> if the substring and pattern are within a given distance k of each other, then the algorithm considers them equal. 
---------> The algorithm begins by precomputing a set of bitmasks containing one bit for each element of the pattern. 
---------> Then it is able to do most of the work with bitwise operations, which are extremely fast.
-------> The bitap algorithm is perhaps best known as one of the underlying algorithms of the Unix utility agrep, written by Udi Manber, Sun Wu, and Burra Gopal. 
---------> Manber and Wu's original paper gives extensions of the algorithm to deal with fuzzy matching of general regular expressions.
-------> Due to the data structures required by the algorithm, it performs best on patterns less than a constant length (typically the word length of the machine in question), 
---------> and also prefers inputs over a small alphabet. 
---------> Once it has been implemented for a given alphabet and word length m, however, its running time is completely predictable, 
---------> it runs in O(mn) operations, no matter the structure of the text or the pattern.
-------> The bitap algorithm for exact string searching was invented by Bálint Dömölki in 1964 and extended by R. K. Shyamasundar in 1977, 
---------> before being reinvented by Ricardo Baeza-Yates and Gaston Gonnet in 1989 (one chapter of first author's PhD thesis) 
---------> which also extended it to handle classes of characters, wildcards, and mismatches. 
---------> In 1991, it was extended by Manber and Wu [6][7] to handle also insertions and deletions (full fuzzy string searching). 
---------> This algorithm was later improved by Baeza-Yates and Navarro in 1996.
-------> Exact searching
---------> The bitap algorithm for exact string searching, in full generality, looks like this in pseudocode:
-----------> algorithm bitap_search is
----------->     input: text as a string.
----------->            pattern as a string.
----------->     output: string
----------->     m := length(pattern)
----------->     if m = 0 then
----------->         return text
----------->     /* Initialize the bit array R. */
----------->     R := new array[m+1] of bit, initially all 0
----------->     R[0] := 1
-----------> 
----------->     for i := 0; i < length(text); i += 1 do
----------->         /* Update the bit array. */
----------->         for k := m; k ≥ 1; k -= 1 do
----------->             R[k] := R[k - 1] & (text[i] = pattern[k - 1])
-----------> 
----------->         if R[m] then
----------->             return (text + i - m) + 1
-----------> 
----------->     return null
-------> Fuzzy searching
---------> To perform fuzzy string searching using the bitap algorithm, it is necessary to extend the bit array R into a second dimension. 
-----------> Instead of having a single array R that changes over the length of the text, we now have k distinct arrays R1..k. Array Ri 
-----------> holds a representation of the prefixes of pattern that match any suffix of the current string with i or fewer errors. 
-----------> In this context, an "error" may be an insertion, deletion, or substitution; see Levenshtein distance for more information on these operations.
---------> The implementation below performs fuzzy matching (returning the first match with up to k errors) using the fuzzy bitap algorithm. 
-----------> However, it only pays attention to substitutions, not to insertions or deletions – in other words, a Hamming distance of k. 
-----------> As before, the semantics of 0 and 1 are reversed from their conventional meanings.
-------------> #include <stdlib.h>
-------------> #include <string.h>
-------------> #include <limits.h>
-------------> const char *bitap_fuzzy_bitwise_search(const char *text, const char *pattern, int k)
-------------> {
------------->     const char *result = NULL;
------------->     int m = strlen(pattern);
------------->     unsigned long *R;
------------->     unsigned long pattern_mask[CHAR_MAX+1];
------------->     int i, d;
-------------> 
------------->     if (pattern[0] == '\0') return text;
------------->     if (m > 31) return "The pattern is too long!";
-------------> 
------------->     /* Initialize the bit array R */
------------->     R = malloc((k+1) * sizeof *R);
------------->     for (i=0; i <= k; ++i)
------------->         R[i] = ~1;
-------------> 
------------->     /* Initialize the pattern bitmasks */
------------->     for (i=0; i <= CHAR_MAX; ++i)
------------->         pattern_mask[i] = ~0;
------------->     for (i=0; i < m; ++i)
------------->         pattern_mask[pattern[i]] &= ~(1UL << i);
-------------> 
------------->     for (i=0; text[i] != '\0'; ++i) {
------------->         /* Update the bit arrays */
------------->         unsigned long old_Rd1 = R[0];
-------------> 
------------->         R[0] |= pattern_mask[text[i]];
------------->         R[0] <<= 1;
-------------> 
------------->         for (d=1; d <= k; ++d) {
------------->             unsigned long tmp = R[d];
------------->             /* Substitution is all we care about */
------------->             R[d] = (old_Rd1 & (R[d] | pattern_mask[text[i]])) << 1;
------------->             old_Rd1 = tmp;
------------->         }
-------------> 
------------->         if (0 == (R[k] & (1UL << m))) {
------------->             result = (text+i - m) + 1;
------------->             break;
------------->         }
------------->     }
-------------> 
------------->     free(R);
------------->     return result;
-------------> }



-------> Phonetic algorithms
---------> A phonetic algorithm is an algorithm for indexing of words by their pronunciation. 
---------> Most phonetic algorithms were developed for English and are not useful for indexing words in other languages. 
---------> Because English spelling varies significantly depending on multiple factors, such as the word's origin and usage over time and borrowings from other languages, 
---------> phonetic algorithms necessarily take into account numerous rules and exceptions.
---------> Algorithms
-----------> Among the best-known phonetic algorithms are:
-------------> (1) Soundex, which was developed to encode surnames for use in censuses. 
---------------> Soundex codes are four-character strings composed of a single letter followed by three numbers.
-------------> (2) Daitch–Mokotoff Soundex, which is a refinement of Soundex designed to better match surnames of Slavic and Germanic origin. 
---------------> Daitch–Mokotoff Soundex codes are strings composed of six numeric digits.
-------------> (3) Cologne phonetics: This is similar to Soundex, but more suitable for German words.
-------------> (4) Metaphone and Double Metaphone which are suitable for use with most English words, not just names. 
---------------> Metaphone algorithms are the basis for many popular spell checkers.
-------------> (5) New York State Identification and Intelligence System (NYSIIS), which maps similar phonemes to the same letter. 
---------------> The result is a string that can be pronounced by the reader without decoding.
-------------> (6) Match Rating Approach developed by Western Airlines in 1977 - this algorithm has an encoding and range comparison technique.
-------------> (7) Caverphone, created to assist in data matching between late 19th century and early 20th century electoral rolls, optimized for accents present in parts of New Zealand.
-----------> Common uses
-------------> (1) Spell checkers can often contain phonetic algorithms. 
---------------> The Metaphone algorithm, for example, can take an incorrectly spelled word and create a code. 
---------------> The code is then looked up in directory for words with the same or similar Metaphone. 
---------------> Words that have the same or similar Metaphone become possible alternative spellings.
-------------> (2) Search functionality will often use phonetic algorithms to find results that don't match exactly the term(s) used in the search. 
---------------> Searching for names can be difficult as there are often multiple alternative spellings for names. 
---------------> An example is the name Claire. 
---------------> It has two alternatives, Clare/Clair, which are both pronounced the same. 
---------------> Searching for one spelling wouldn't show results for the two others. 
---------------> Using Soundex all three variations produce the same Soundex code, C460. 
---------------> By searching names based on the Soundex code all three variations will be returned.

---------> Daitch–Mokotoff Soundex: 
-----------> This is a Soundex refinement which allows matching of Slavic and Germanic surnames.
-----------> Daitch–Mokotoff Soundex (D–M Soundex) is a phonetic algorithm invented in 1985 by Jewish genealogists Gary Mokotoff and Randy Daitch. 
-----------> It is a refinement of the Russell and American Soundex algorithms designed to allow greater accuracy in matching of Slavic and Yiddish surnames with similar pronunciation but differences in spelling.
-----------> Daitch–Mokotoff Soundex is sometimes referred to as "Jewish Soundex" and "Eastern European Soundex", 
-----------> although the authors discourage use of these nicknames for the algorithm because the algorithm itself is independent of the fact that the motivation 
-----------> for creating the new system was the poor result of predecessor systems when dealing with Slavic and Yiddish surnames. 
-----------> Improvements over the older Soundex algorithms include:
-------------> (1) Coded names are six digits long, resulting in greater search precision (traditional Soundex uses four characters)
-------------> (2) The initial character of the name is coded.
-------------> (3) Several rules in the algorithm encode multiple character n-grams as single digits (American and Russell Soundex do not handle multi-character n-grams)
-------------> (4) Multiple possible encodings can be returned for a single name (traditional Soundex returns only one encoding, even if the spelling of a name could potentially have multiple pronunciations)

---------> Double Metaphone: 
-----------> This is an improvement on Metaphone.
-----------> The Double Metaphone phonetic encoding algorithm is the second generation of this algorithm. 
-------------> Its implementation was described in the June 2000 issue of C/C++ Users Journal. 
-------------> It makes a number of fundamental design improvements over the original Metaphone algorithm.
-----------> It is called "Double" because it can return both a primary and a secondary code for a string; 
-------------> this accounts for some ambiguous cases as well as for multiple variants of surnames with common ancestry. 
-------------> For example, encoding the name "Smith" yields a primary code of SM0 and a secondary code of XMT, 
-------------> while the name "Schmidt" yields a primary code of XMT and a secondary code of SMT—both have XMT in common.
-----------> Double Metaphone tries to account for myriad irregularities in English of Slavic, Germanic, Celtic, Greek, French, Italian, Spanish, Chinese, and other origins. 
-------------> Thus it uses a much more complex ruleset for coding than its predecessor; for example, it tests for approximately 100 different contexts of the use of the letter C alone. 

---------> Match rating approach:
-----------> This is a phonetic algorithm developed by Western Airlines.
-------------> The match rating approach (MRA) is a phonetic algorithm for indexing of words by their pronunciation 
-------------> developed by Western Airlines in 1977 for the indexation and comparison of homophonous names.
-----------> The algorithm itself has a simple set of encoding rules but a more lengthy set of comparison rules. 
-------------> The main mechanism is the similarity comparison, which calculates the number of unmatched characters 
-------------> by comparing the strings from left to right and then from right to left, and removing identical characters. 
-------------> This value is subtracted from 6 and then compared to a minimum threshold. 
-------------> The minimum threshold is defined in table A and is dependent upon the length of the strings.
-----------> The encoded name is known (perhaps incorrectly) as a personal numeric identifier (PNI). 
-------------> The encoded name can never contain more than 6 alpha only characters.
-----------> The match rating approach performs well with names containing the letter "y", unlike the original flavor of the NYSIIS algorithm; 
-------------> for example, the surnames "Smith" and "Smyth" are successfully matched. 
-------------> However, MRA does not perform well with encoded names that differ in length by more than 2. 
-----------> Encoding rules
-------------> (1) Delete all vowels unless the vowel begins the word
-------------> (2) Remove the second consonant of any double consonants present
-------------> (3) Reduce codex to 6 letters by joining the first 3 and last 3 letters only
-----------> Comparison rules
-------------> In this section, the words "string(s)" and "name(s)" mean "encoded string(s)" and "encoded name(s)".
---------------> (1) If the length difference between the encoded strings is 3 or greater, then no similarity comparison is done.
---------------> (2) Obtain the minimum rating value by calculating the length sum of the encoded strings and using table A
---------------> (3) Process the encoded strings from left to right and remove any identical characters found from both strings respectively.
---------------> (4) Process the unmatched characters from right to left and remove any identical characters found from both names respectively.
---------------> (5) Subtract the number of unmatched characters from 6 in the longer string. This is the similarity rating.
---------------> (6) If the similarity rating equal to or greater than the minimum rating then the match is considered good.

---------> Metaphone: 
-----------> This is an algorithm for indexing words by their sound, when pronounced in English
-----------> Metaphone is a phonetic algorithm, published by Lawrence Philips in 1990, for indexing words by their English pronunciation. 
-------------> It fundamentally improves on the Soundex algorithm by using information about variations and inconsistencies in English spelling and pronunciation to produce a more accurate encoding, 
-------------> which does a better job of matching words and names which sound similar. As with Soundex, similar-sounding words should share the same keys. M
-------------> etaphone is available as a built-in operator in a number of systems.
-----------> Philips later produced a new version of the algorithm, which he named Double Metaphone. 
-------------> Contrary to the original algorithm whose application is limited to English only, this version takes into account spelling peculiarities of a number of other languages. 
-------------> In 2009 Philips released a third version, called Metaphone 3, which achieves an accuracy of approximately 99% for English words, non-English words familiar to Americans, 
-------------> and first names and family names commonly found in the United States, having been developed according to modern engineering standards against a test harness of prepared correct encodings. 
-----------> Procedure
-------------> Original Metaphone codes use the 16 consonant symbols 0BFHJKLMNPRSTWXY. 
---------------> The '0' represents "th" (as an ASCII approximation of Θ), 'X' represents "sh" or "ch", and the others represent their usual English pronunciations. 
---------------> The vowels AEIOU are also used, but only at the beginning of the code. 
---------------> This table summarizes most of the rules in the original implementation:
-----------------> Drop duplicate adjacent letters, except for C.
-----------------> If the word begins with 'KN', 'GN', 'PN', 'AE', 'WR', drop the first letter.
-----------------> Drop 'B' if after 'M' at the end of the word.
-----------------> 'C' transforms to 'X' if followed by 'IA' or 'H' (unless in latter case, it is part of '-SCH-', in which case it transforms to 'K').
-----------------> 'C' transforms to 'S' if followed by 'I', 'E', or 'Y'. Otherwise, 'C' transforms to 'K'.
-----------------> 'D' transforms to 'J' if followed by 'GE', 'GY', or 'GI'. Otherwise, 'D' transforms to 'T'.
-----------------> Drop 'G' if followed by 'H' and 'H' is not at the end or before a vowel. Drop 'G' if followed by 'N' or 'NED' and is at the end.
-----------------> 'G' transforms to 'J' if before 'I', 'E', or 'Y', and it is not in 'GG'. Otherwise, 'G' transforms to 'K'.
-----------------> Drop 'H' if after vowel and not before a vowel.
-----------------> 'CK' transforms to 'K'.
-----------------> 'PH' transforms to 'F'.
-----------------> 'Q' transforms to 'K'.
-----------------> 'S' transforms to 'X' if followed by 'H', 'IO', or 'IA'.
-----------------> 'T' transforms to 'X' if followed by 'IA' or 'IO'. 'TH' transforms to '0'. Drop 'T' if followed by 'CH'.
-----------------> 'V' transforms to 'F'.
-----------------> 'WH' transforms to 'W' if at the beginning. Drop 'W' if not followed by a vowel.
-----------------> 'X' transforms to 'S' if at the beginning. Otherwise, 'X' transforms to 'KS'.
-----------------> Drop 'Y' if not followed by a vowel.
-----------------> 'Z' transforms to 'S'.
---------------> Drop all vowels unless it is the beginning.
-------------> This table does not constitute a complete description of the original Metaphone algorithm, and the algorithm cannot be coded correctly from it. 
---------------> Original Metaphone contained many errors and was superseded by Double Metaphone, 
---------------> and in turn Double Metaphone and original Metaphone were superseded by Metaphone 3, 
---------------> which corrects thousands of miscodings that will be produced by the first two versions.
-------------> To implement Metaphone without purchasing a (source code) copy of Metaphone 3, the reference implementation of Double Metaphone can be used.
---------------> Alternatively, version 2.1.3 of Metaphone 3, an earlier 2009 version without a number of encoding corrections made in the current version, version 2.5.4, 
---------------> has been made available under the terms of the BSD License via the OpenRefine project.

---------> NYSIIS: 
-----------> This is a phonetic algorithm, improves on Soundex.
-----------> The New York State Identification and Intelligence System Phonetic Code, commonly known as NYSIIS, 
-------------> is a phonetic algorithm devised in 1970 as part of the New York State Identification and Intelligence System 
-------------> (now a part of the New York State Division of Criminal Justice Services). 
-------------> It features an accuracy increase of 2.7% over the traditional Soundex algorithm.
-----------> Procedure
-------------> The algorithm, as described in Name Search Techniques,[2] is:
---------------> If the first letters of the name are
--------------->     'MAC' then change these letters to 'MCC'
--------------->     'KN' then change these letters to 'NN'
--------------->     'K' then change this letter to 'C'
--------------->     'PH' then change these letters to 'FF'
--------------->     'PF' then change these letters to 'FF'
--------------->     'SCH' then change these letters to 'SSS'
---------------> If the last letters of the name are[3]
--------------->     'EE' then change these letters to 'Y␢'
--------------->     'IE' then change these letters to 'Y␢'
--------------->     'DT' or 'RT' or 'RD' or 'NT' or 'ND' then change these letters to 'D␢'
---------------> The first character of the NYSIIS code is the first character of the name.
---------------> In the following rules, a scan is performed on the characters of the name. 
---------------> This is described in terms of a program loop. 
---------------> A pointer is used to point to the current position under consideration in the name. 
---------------> Step 4 is to set this pointer to point to the second character of the name.
---------------> Considering the position of the pointer, only one of the following statements can be executed.
--------------->     If blank then go to rule 7.
--------------->     If the current position is a vowel (AEIOU) then if equal to 'EV' then change to 'AF' otherwise change current position to 'A'.
--------------->     If the current position is the letter
--------------->         'Q' then change the letter to 'G'
--------------->         'Z' then change the letter to 'S'
--------------->         'M' then change the letter to 'N'
--------------->     If the current position is the letter 'K' then if the next letter is 'N' then replace the current position by 'N' otherwise replace the current position by 'C'
--------------->     If the current position points to the letter string
--------------->         'SCH' then replace the string with 'SSS'
--------------->         'PH' then replace the string with 'FF'
--------------->     If the current position is the letter 'H' and either the preceding or following letter is not a vowel (AEIOU) then replace the current position with the preceding letter.
--------------->     If the current position is the letter 'W' and the preceding letter is a vowel then replace the current position with the preceding position.
--------------->     If none of these rules applies, then retain the current position letter value.
---------------> If the current position letter is equal to the last letter placed in the code then set the pointer to point to the next letter and go to step 5.
---------------> The next character of the NYSIIS code is the current position letter.
---------------> Increment the pointer to point at the next letter.
---------------> Go to step 5.
---------------> If the last character of the NYSIIS code is the letter 'S' then remove it.
---------------> If the last two characters of the NYSIIS code are the letters 'AY' then replace them with the single character 'Y'.
---------------> If the last character of the NYSIIS code is the letter 'A' then remove this letter.

---------> Soundex: 
-----------> This is a phonetic algorithm for indexing names by sound, as pronounced in English.
-------------> Soundex is a phonetic algorithm for indexing names by sound, as pronounced in English. 
-------------> The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. 
-------------> The algorithm mainly encodes consonants; a vowel will not be encoded unless it is the first letter. 
-------------> Soundex is the most widely known of all phonetic algorithms (in part because it is a standard feature of popular database software 
-------------> such as IBM Db2, PostgreSQL,[2] MySQL,[3] SQLite,[4] Ingres, MS SQL Server,[5] Oracle.[6] and SAP ASE.[7]) 
-------------> Improvements to Soundex are the basis for many modern phonetic algorithms.



-------> String metrics:
---------> This is computes a similarity or dissimilarity (distance) score between two pairs of text strings.
---------> A string metric (also known as a string similarity metric or string distance function)
-----------> is a metric that measures distance ("inverse similarity") between two text strings for approximate string matching or comparison and in fuzzy string searching. 
-----------> A requirement for a string metric (e.g. in contrast to string matching) is fulfillment of the triangle inequality. 
-----------> For example, the strings "Sam" and "Samuel" can be considered to be close. 
-----------> A string metric provides a number indicating an algorithm-specific indication of distance.
---------> The most widely known string metric is a rudimentary one called the Levenshtein distance (also known as edit distance). 
-----------> It operates between two input strings, returning a number equivalent to the number of substitutions and deletions needed in order to transform one input string into another. 
-----------> Simplistic string metrics such as Levenshtein distance have expanded to include phonetic, token, grammatical and character-based methods of statistical comparisons.
---------> String metrics are used heavily in information integration and are currently used in areas including fraud detection, 
-----------> fingerprint analysis, plagiarism detection, ontology merging, DNA analysis, RNA analysis, image analysis, evidence-based machine learning, 
-----------> database data deduplication, data mining, incremental search, data integration, Malware Detection, and semantic knowledge integration. 
---------> There are other popular measures of edit distance, which are calculated using a different set of allowable edit operations. For instance,
-----------> The Levenshtein distance allows deletion, insertion and substitution;
-----------> The Damerau–Levenshtein distance allows insertion, deletion, substitution, and the transposition of two adjacent characters;
-----------> The longest common subsequence (LCS) distance allows only insertion and deletion, not substitution;
-----------> The Hamming distance allows only substitution, hence, it only applies to strings of the same length.

---------> Damerau–Levenshtein distance: 
-----------> This is computes a distance measure between two strings, improves on Levenshtein distance.
-----------> The Damerau–Levenshtein distance is a string metric for measuring the edit distance between two sequences. 
-------------> Informally, the Damerau–Levenshtein distance between two words is the minimum number of operations 
-------------> (consisting of insertions, deletions or substitutions of a single character, or transposition of two adjacent characters) required to change one word into the other.
-----------> The Damerau–Levenshtein distance differs from the classical Levenshtein distance by including transpositions 
-------------> among its allowable operations in addition to the three classical single-character edit operations (insertions, deletions and substitutions).
-----------> In his seminal paper,[5] Damerau stated that in an investigation of spelling errors for an information-retrieval system, 
-------------> more than 80% were a result of a single error of one of the four types. 
-------------> Damerau's paper considered only misspellings that could be corrected with at most one edit operation. 
-------------> While the original motivation was to measure distance between human misspellings to improve applications such as spell checkers, 
-------------> Damerau–Levenshtein distance has also seen uses in biology to measure the variation between protein sequences.
-----------> Note: This named after Frederick J. Damerau and Vladimir I. Levenshtein
 
---------> Dice's coefficient (also known as the Dice coefficient): 
-----------> This is a similarity measure related to the Jaccard index.
-------------> The Jaccard index, also known as the Jaccard similarity coefficient, is a statistic used for gauging the similarity and diversity of sample sets.
-----------> The Sørensen–Dice coefficient (see below for other names) is a statistic used to gauge the similarity of two samples. 
-----------> Note: It was independently developed by the botanists Thorvald Sørensen[1] and Lee Raymond Dice,[2] who published in 1948 and 1945 respectively. 

---------> Hamming distance: 
-----------> Definition: The Hamming distance between two equal-length strings of symbols is the number of positions at which the corresponding symbols are different.
-----------> This is sum number of positions which are different.
-----------> The Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. 
-------------> In other words, it measures the minimum number of substitutions required to change one string into the other, 
-------------> or the minimum number of errors that could have transformed one string into the other. 
-------------> In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences. 
-------------> string metrics for measuring the edit distance between two sequences. It is named after the American mathematician Richard Hamming.
-----------> A major application is in coding theory, more specifically to block codes, in which the equal-length strings are vectors over a finite field. 
-----------> Examples
-------------> The symbols may be letters, bits, or decimal digits, among other possibilities. For example, the Hamming distance between:
------------->     "karolin" and "kathrin" is 3.
------------->     "karolin" and "kerstin" is 3.
------------->     "kathrin" and "kerstin" is 4.
------------->     0000 and 1111 is 4.
------------->     2173896 and 2233796 is 3.
-----------> Algorithm
-------------> The following function, written in Python 3, returns the Hamming distance between two strings:
---------------> def hamming_distance(string1, string2):
--------------->     dist_counter = 0
--------------->     for n in range(len(string1)):
--------------->         if string1[n] != string2[n]:
--------------->             dist_counter += 1
--------------->     return dist_counter
-------------> Or, in a shorter expression: 
---------------> sum(xi != yi for xi, yi in zip(x, y))
-----------> Note: This is named after the American mathematician Richard Hamming.

---------> Jaro–Winkler distance: 
-----------> This is a measure of similarity between two strings.
-----------> The Jaro–Winkler distance is a string metric measuring an edit distance between two sequences.
-----------> The Jaro–Winkler distance uses a prefix scale p which gives more favourable ratings to strings that match from the beginning for a set prefix length ℓ.
-----------> The lower the Jaro–Winkler distance for two strings is, the more similar the strings are. The score is normalized such that 1 means an exact match and 0 means there is no similarity. 
-------------> The original paper actually defined the metric in terms of similarity, so the distance is defined as the inversion of that value (distance = 1 − similarity).
-----------> Although often referred to as a distance metric, the Jaro–Winkler distance is not a metric in the mathematical sense of that term because it does not obey the triangle inequality. 
-----------> Note: This is a variant proposed in 1990 by William E. Winkler of the Jaro distance metric (1989, Matthew A. Jaro).

---------> Levenshtein edit distance: 
-----------> This computes a metric for the amount of difference between two sequences.
-------------> In information theory, linguistics, and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. 
-------------> Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. 
-------------> It is named after the Soviet mathematician Vladimir Levenshtein, who considered this distance in 1965.
-----------> Levenshtein distance may also be referred to as edit distance, although that term may also denote a larger family of distance metrics known collectively as edit distance.
-------------> It is closely related to pairwise string alignments. 
-----------> Algorithm: Check the APRG codes

-------> Trigram search: 
---------> This search for text when the exact syntax or spelling of the target object is not precisely known
---------> Trigram search is a method of searching for text when the exact syntax or spelling of the target object is not precisely known or when queries may be regular expressions. 
-----------> It finds objects which match the maximum number of three consecutive character strings (i.e. trigrams) in the entered search terms, which are generally near matches. 
-----------> Two strings with many shared trigrams can be expected to be very similar. 
-----------> Trigrams also allow for efficiently creating indexes for searches that are regular expressions or match the text inexactly. 
-----------> Indexes can significantly accelerate searches.
-----------> A threshold for number of trigram matches can be specified as a cutoff point, after which a result is no longer considered a match.
---------> Using trigrams for accelerating searches is a technique used in some systems for code searching, 
-----------> where queries that are regular expressions may be useful, search engines such as Elasticsearch, as well as in databases such as PostgreSQL.
-------> Examples
---------> Consider the string "alice". The trigrams of the string would be "ali", "lic", and "ice," not including spaces.
-----------> Searching for this string in a database with a trigram-based index would involve finding which objects contain as many of the three trigrams as possible.
---------> As a concrete example of using trigram search to search for a regular expression query, consider searching for the string ab[cd]e, 
-----------> where the brackets denote that the third character in the string being searched for could be c or d. 
-----------> In this situation, one could query the index for objects that have the two trigrams abc and bce or the two trigrams abd and bde. 
-----------> Thus, finding this query would involve no string matching, and could just query the index directly, which can be faster in practice.


-----> Selection algorithms

-------> Quickselect
---------> Quickselect is a selection algorithm to find the kth smallest element in an unordered list. 
-----------> It is related to the quicksort sorting algorithm. 
-----------> Like quicksort, it was developed by Tony Hoare, and thus is also known as Hoare's selection algorithm.
-----------> Like quicksort, it is efficient in practice and has good average-case performance, but has poor worst-case performance. 
-----------> Quickselect and its variants are the selection algorithms most often used in efficient real-world implementations.
---------> Quickselect uses the same overall approach as quicksort, choosing one element as a pivot and partitioning the data in two based on the pivot, accordingly as less than or greater than the pivot. 
-----------> However, instead of recursing into both sides, as in quicksort, quickselect only recurses into one side – the side with the element it is searching for. 
-----------> This reduces the average complexity from Θ(n log n) to Θ(n), with a worst case of O(n^2).
---------> As with quicksort, quickselect is generally implemented as an in-place algorithm, and beyond selecting the kth element, it also partially sorts the data. 
-----------> See selection algorithm for further discussion of the connection with sorting. 
---------> Algorithm
-----------> In quicksort, there is a subprocedure called partition that can, in linear time, 
-------------> group a list (ranging from indices left to right) into two parts: those less than a certain element, and those greater than or equal to the element. 
-------------> Here is pseudocode that performs a partition about the element list[pivotIndex]:
---------------> function partition(list, left, right, pivotIndex) is
--------------->     pivotValue := list[pivotIndex]
--------------->     swap list[pivotIndex] and list[right]  // Move pivot to end
--------------->     storeIndex := left
--------------->     for i from left to right − 1 do
--------------->         if list[i] < pivotValue then
--------------->             swap list[storeIndex] and list[i]
--------------->             increment storeIndex
--------------->     swap list[right] and list[storeIndex]  // Move pivot to its final place
--------------->     return storeIndex
-----------> This is known as the Lomuto partition scheme, which is simpler but less efficient than Hoare's original partition scheme.
-----------> In quicksort, we recursively sort both branches, leading to best-case Ω(n log ⁡ n) time. 
-------------> However, when doing selection, we already know which partition our desired element lies in, since the pivot is in its final sorted position,
-------------> with all those preceding it in an unsorted order and all those following it in an unsorted order. 
-------------> Therefore, a single recursive call locates the desired element in the correct partition, and we build upon this for quickselect:
---------------> // Returns the k-th smallest element of list within left..right inclusive
---------------> // (i.e. left <= k <= right).
---------------> function select(list, left, right, k) is
--------------->     if left = right then   // If the list contains only one element,
--------------->         return list[left]  // return that element
--------------->     pivotIndex  := ...     // select a pivotIndex between left and right,
--------------->                            // e.g., left + floor(rand() % (right − left + 1))
--------------->     pivotIndex  := partition(list, left, right, pivotIndex)
--------------->     // The pivot is in its final sorted position
--------------->     if k = pivotIndex then
--------------->         return list[k]
--------------->     else if k < pivotIndex then
--------------->         return select(list, left, pivotIndex − 1, k)
--------------->     else
--------------->         return select(list, pivotIndex + 1, right, k) 
-----------> Note the resemblance to quicksort: just as the minimum-based selection algorithm is a partial selection sort, 
-------------> this is a partial quicksort, generating and partitioning only O(log n) of its O(n) partitions. 
-------------> This simple procedure has expected linear performance, and, like quicksort, has quite good performance in practice. 
-------------> It is also an in-place algorithm, requiring only constant memory overhead if tail call optimization is available, or if eliminating the tail recursion with a loop:
---------------> function select(list, left, right, k) is
--------------->     loop
--------------->         if left = right then
--------------->             return list[left]
--------------->         pivotIndex := ...     // select pivotIndex between left and right
--------------->         pivotIndex := partition(list, left, right, pivotIndex)
--------------->         if k = pivotIndex then
--------------->             return list[k]
--------------->         else if k < pivotIndex then
--------------->             right := pivotIndex − 1
--------------->         else
--------------->             left := pivotIndex + 1

-------> Introselect
---------> Introselect (short for "introspective selection") is a selection algorithm that is a hybrid of quickselect 
-----------> and median of medians which has fast average performance and optimal worst-case performance. 
-----------> Introselect is related to the introsort sorting algorithm: these are analogous refinements of the basic quickselect and quicksort algorithms, 
-----------> in that they both start with the quick algorithm, which has good average performance and low overhead, 
-----------> but fall back to an optimal worst-case algorithm (with higher overhead) if the quick algorithm does not progress rapidly enough. 
-----------> Both algorithms were introduced by David Musser in (Musser 1997), with the purpose of providing generic algorithms 
-----------> for the C++ Standard Library that have both fast average performance and optimal worst-case performance, thus allowing the performance requirements to be tightened. 
-----------> However, in most C++ Standard Library implementations that use introselect, another "introselect" algorithm is used, 
-----------> which combines quickselect and heapselect, and has a worst-case running time of O(n log n).
---------> Algorithms
-----------> Introsort achieves practical performance comparable to quicksort while preserving O(n log n) worst-case behavior by creating a hybrid of quicksort and heapsort. 
-------------> Introsort starts with quicksort, so it achieves performance similar to quicksort if quicksort works, 
-------------> and falls back to heapsort (which has optimal worst-case performance) if quicksort does not progress quickly enough. 
-------------> Similarly, introselect combines quickselect with median of medians to achieve worst-case linear selection with performance similar to quickselect.
-----------> Introselect works by optimistically starting out with quickselect and only switching to a worst-case linear-time selection algorithm 
-------------> (the Blum-Floyd-Pratt-Rivest-Tarjan median of medians algorithm) if it recurses too many times without making sufficient progress. 
-------------> The switching strategy is the main technical content of the algorithm. 
-------------> Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large lists. 
-------------> Musser discusses a couple of simple approaches:
-------------> Keep track of the list of sizes of the subpartitions processed so far. 
---------------> If at any point k recursive calls have been made without halving the list size, for some small positive k, switch to the worst-case linear algorithm.
-------------> Sum the size of all partitions generated so far. If this exceeds the list size times some small positive constant k, switch to the worst-case linear algorithm. 
---------------> This sum is easy to track in a single scalar variable.
-----------> Both approaches limit the recursion depth to k(log n) = O(log n) and the total running time to O(n).
-----------> Note: The paper suggested that more research on introselect was forthcoming, but the author retired in 2007 without having published any such further research. 

-----> Sequence search

-------> Linear search:
---------> This locates an item in an unsorted sequence.
---------> A linear search or sequential search is a method for finding an element within a list. 
-----------> It sequentially checks each element of the list until a match is found or the whole list has been searched.
---------> A linear search runs in at worst linear time and makes at most n comparisons, where n is the length of the list. 
-----------> If each element is equally likely to be searched, then linear search has an average case of n+1/2 comparisons, 
-----------> but the average case can be affected if the search probabilities for each element vary. 
-----------> Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, 
-----------> allow significantly faster searching for all but short lists.
---------> Algorithm
-----------> A linear search sequentially checks each element of the list until it finds an element that matches the target value. 
-------------> If the algorithm reaches the end of the list, the search terminates unsuccessfully.
-----------> Basic algorithm
-------------> Given a list L of n elements with values or records L0 .... Ln−1, and target value T, 
-------------> the following subroutine uses linear search to find the index of the target T in L.
---------------> Set i to 0.
---------------> If Li = T, the search terminates successfully; return i.
---------------> Increase i by 1.
---------------> If i < n, go to step 2. Otherwise, the search terminates unsuccessfully.
-----------> With a sentinel
-------------> The basic algorithm above makes two comparisons per iteration: one to check if Li equals T,
---------------> and the other to check if i still points to a valid index of the list. 
---------------> By adding an extra record Ln to the list (a sentinel value) that equals the target, 
---------------> the second comparison can be eliminated until the end of the search, making the algorithm faster. 
---------------> The search will reach the sentinel if the target is not contained within the list.[4]
-----------------> Set i to 0.
-----------------> If Li = T, go to step 4.
-----------------> Increase i by 1 and go to step 2.
-----------------> If i < n, the search terminates successfully; return i. Else, the search terminates unsuccessfully.
-----------> In an ordered table
-------------> If the list is ordered such that L0 ≤ L1 ... ≤ Ln−1, the search can establish 
---------------> the absence of the target more quickly by concluding the search once Li exceeds the target. 
---------------> This variation requires a sentinel that is greater than the target.
-----------------> Set i to 0.
-----------------> If Li ≥ T, go to step 4.
-----------------> Increase i by 1 and go to step 2.
-----------------> If Li = T, the search terminates successfully; return i. Else, the search terminates unsuccessfully.

-------> Selection algorithm:
---------> This finds the kth largest item in a sequence.
---------> A selection algorithm is an algorithm for finding the kth smallest number in a list or array; such a number is called the kth order statistic. 
-----------> This includes the cases of finding the minimum, maximum, and median elements. 
-----------> There are O(n)-time (worst-case linear time) selection algorithms, 
-----------> and sublinear performance is possible for structured data; in the extreme, O(1) for an array of sorted data. 
-----------> Selection is a subproblem of more complex problems like the nearest neighbor and shortest path problems. 
-----------> Many selection algorithms are derived by generalizing a sorting algorithm, and conversely some sorting algorithms can be derived as repeated application of selection.
---------> The simplest case of a selection algorithm is finding the minimum (or maximum) element by iterating through the list, 
-----------> keeping track of the running minimum – the minimum so far – (or maximum) and can be seen as related to the selection sort. 
-----------> Conversely, the hardest case of a selection algorithm is finding the median. 
-----------> In fact, a specialized median-selection algorithm can be used to build a general selection algorithm, as in median of medians. 
-----------> The best-known selection algorithm is Quickselect, which is related to Quicksort; like Quicksort, 
-----------> it has (asymptotically) optimal average performance, but poor worst-case performance, though it can be modified to give optimal worst-case performance as well. 

-------> Ternary search: 
---------> This a technique for finding the minimum or maximum of a function that is either strictly increasing and then strictly decreasing or vice versa.
-----------> A ternary search algorithm is a technique in computer science for finding the minimum or maximum of a unimodal function. 
-----------> A ternary search determines either that the minimum or maximum cannot be in the first third of the domain 
-----------> or that it cannot be in the last third of the domain, then repeats on the remaining two thirds. 
-----------> A ternary search is an example of a divide and conquer algorithm (see search algorithm).
-----------> The function
-------------> Assume we are looking for a maximum of f(x) and that we know the maximum lies somewhere between A and B. 
-------------> For the algorithm to be applicable, there must be some value x {\displaystyle x} x such that
---------------> for all a,b with A ≤ a < b ≤ x, we have f(a)<f(b), and
---------------> for all a,b with x ≤ a < b ≤ B, we have f(a)>f(b).
-----------> Algorithm
-----------> Let f(x) be a unimodal function on some interval [l;r]. Take any two points m1 and m2 in this segment: l < m1 < m2 < r. 
-----------> Then there are three possibilities:
-------------> if f(m1) < f(m2), then the required maximum can not be located on the left side – [l;m1]. 
---------------> It means that the maximum further makes sense to look only in the interval [m1;r]
-------------> if f(m1) > f(m2), that the situation is similar to the previous, up to symmetry. 
---------------> Now, the required maximum can not be in the right side – [m2;r], so go to the segment [l;m2]
-------------> if f(m1) = f(m2), then the search should be conducted in [m1;m2], 
---------------> but this case can be attributed to any of the previous two (in order to simplify the code). 
---------------> Sooner or later the length of the segment will be a little less than a predetermined constant, and the process can be stopped.
-----------> choice points m1 and m2:
----------->     m1 = l + (r−l)/3
----------->     m2 = r − (r−l)/3
-----------> Run time order
----------->     T ( n ) = T ( 2 n / 3 ) + 1 = Θ ( log ⁡ n )
-----------> Recursive algorithm
-----------> 
-----------> def ternary_search(f, left, right, absolute_precision) -> float:
----------->     """Left and right are the current bounds;
----------->     the maximum is between them.
----------->     """
----------->     if abs(right - left) < absolute_precision:
----------->         return (left + right) / 2
-----------> 
----------->     left_third = (2*left + right) / 3
----------->     right_third = (left + 2*right) / 3
-----------> 
----------->     if f(left_third) < f(right_third):
----------->         return ternary_search(f, left_third, right, absolute_precision)
----------->     else:
----------->         return ternary_search(f, left, right_third, absolute_precision)
-----------> 
-----------> Iterative algorithm
-----------> 
-----------> def ternary_search(f, left, right, absolute_precision) -> float:
----------->     """Find maximum of unimodal function f() within [left, right].
----------->     To find the minimum, reverse the if/else statement or reverse the comparison.
----------->     """
----------->     while abs(right - left) >= absolute_precision:
----------->         left_third = left + (right - left) / 3
----------->         right_third = right - (right - left) / 3
-----------> 
----------->         if f(left_third) < f(right_third):
----------->             left = left_third
----------->         else:
----------->             right = right_third
-----------> 
----------->      # Left and right are the current bounds; the maximum is between them
----------->      return (left + right) / 2

-------> Sorted lists

---------> Binary search algorithm: 
-----------> This locates an item in a sorted sequence.
binary search, also known as half-interval search,[1] logarithmic search,[2] or binary chop,[3] is a search algorithm that finds the position of a target value within a sorted array.[4][5] Binary search compares the target value to the middle element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, again taking the middle element to compare to the target value, and repeating this until the target value is found. If the search ends with the remaining half being empty, the target is not in the array.

Binary search runs in logarithmic time in the worst case, making O ( log ⁡ n ) {\displaystyle O(\log n)} O(\log n) comparisons, where n {\displaystyle n} n is the number of elements in the array.[a][6] Binary search is faster than linear search except for small arrays. However, the array must be sorted first to be able to apply binary search. There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search. However, binary search can be used to solve a wider range of problems, such as finding the next-smallest or next-largest element in the array relative to the target even if it is absent from the array.

There are numerous variations of binary search. In particular, fractional cascading speeds up binary searches for the same value in multiple arrays. Fractional cascading efficiently solves a number of search problems in computational geometry and in numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and B-tree data structures are based on binary search. 

Algorithm

Binary search works on sorted arrays. Binary search begins by comparing an element in the middle of the array with the target value. If the target value matches the element, its position in the array is returned. If the target value is less than the element, the search continues in the lower half of the array. If the target value is greater than the element, the search continues in the upper half of the array. By doing this, the algorithm eliminates the half in which the target value cannot lie in each iteration.[7]
Procedure

Given an array A {\displaystyle A} A of n {\displaystyle n} n elements with values or records A 0 , A 1 , A 2 , … , A n − 1 {\displaystyle A_{0},A_{1},A_{2},\ldots ,A_{n-1}} {\displaystyle A_{0},A_{1},A_{2},\ldots ,A_{n-1}}sorted such that A 0 ≤ A 1 ≤ A 2 ≤ ⋯ ≤ A n − 1 {\displaystyle A_{0}\leq A_{1}\leq A_{2}\leq \cdots \leq A_{n-1}} {\displaystyle A_{0}\leq A_{1}\leq A_{2}\leq \cdots \leq A_{n-1}}, and target value T {\displaystyle T} T, the following subroutine uses binary search to find the index of T {\displaystyle T} T in A {\displaystyle A} A.[7]

    Set L {\displaystyle L} L to 0 {\displaystyle 0} 0 and R {\displaystyle R} R to n − 1 {\displaystyle n-1} n-1.
    If L > R {\displaystyle L>R} {\displaystyle L>R}, the search terminates as unsuccessful.
    Set m {\displaystyle m} m (the position of the middle element) to the floor of L + R 2 {\displaystyle {\frac {L+R}{2}}} {\displaystyle {\frac {L+R}{2}}}, which is the greatest integer less than or equal to L + R 2 {\displaystyle {\frac {L+R}{2}}} {\displaystyle {\frac {L+R}{2}}}.
    If A m < T {\displaystyle A_{m}<T} {\displaystyle A_{m}<T}, set L {\displaystyle L} L to m + 1 {\displaystyle m+1} m+1 and go to step 2.
    If A m > T {\displaystyle A_{m}>T} {\displaystyle A_{m}>T}, set R {\displaystyle R} R to m − 1 {\displaystyle m-1} m-1 and go to step 2.
    Now A m = T {\displaystyle A_{m}=T} {\displaystyle A_{m}=T}, the search is done; return m {\displaystyle m} m.

This iterative procedure keeps track of the search boundaries with the two variables L {\displaystyle L} L and R {\displaystyle R} R. The procedure may be expressed in pseudocode as follows, where the variable names and types remain the same as above, floor is the floor function, and unsuccessful refers to a specific value that conveys the failure of the search.[7]

function binary_search(A, n, T) is
    L := 0
    R := n − 1
    while L ≤ R do
        m := floor((L + R) / 2)
        if A[m] < T then
            L := m + 1
        else if A[m] > T then
            R := m − 1
        else:
            return m
    return unsuccessful

Alternatively, the algorithm may take the ceiling of L + R 2 {\displaystyle {\frac {L+R}{2}}} {\displaystyle {\frac {L+R}{2}}}. This may change the result if the target value appears more than once in the array. 

---------> Fibonacci search technique: 
-----------> This search a sorted sequence using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers.
the Fibonacci search technique is a method of searching a sorted array using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers.[1] Compared to binary search where the sorted array is divided into two equal-sized parts, one of which is examined further, Fibonacci search divides the array into two parts that have sizes that are consecutive Fibonacci numbers. On average, this leads to about 4% more comparisons to be executed,[2] but it has the advantage that one only needs addition and subtraction to calculate the indices of the accessed array elements, while classical binary search needs bit-shift (see Bitwise operation), division or multiplication,[1] operations that were less common at the time Fibonacci search was first published. Fibonacci search has an average- and worst-case complexity of O(log n) (see Big O notation).

The Fibonacci sequence has the property that a number is the sum of its two predecessors. Therefore the sequence can be computed by repeated addition. The ratio of two consecutive numbers approaches the Golden ratio, 1.618... Binary search works by dividing the seek area in equal parts (1:1). Fibonacci search can divide it into parts approaching 1:1.618 while using the simpler operations.

If the elements being searched have non-uniform access memory storage (i. e., the time needed to access a storage location varies depending on the location accessed), the Fibonacci search may have the advantage over binary search in slightly reducing the average time needed to access a storage location. If the machine executing the search has a direct mapped CPU cache, binary search may lead to more cache misses because the elements that are accessed often tend to gather in only a few cache lines; this is mitigated by splitting the array in parts that do not tend to be powers of two. If the data is stored on a magnetic tape where seek time depends on the current head position, a tradeoff between longer seek time and more comparisons may lead to a search algorithm that is skewed similarly to Fibonacci search.

Fibonacci search is derived from Golden section search, an algorithm by Jack Kiefer (1953) to search for the maximum or minimum of a unimodal function in an interval.[3]
Algorithm

Let k be defined as an element in F, the array of Fibonacci numbers. n = Fm is the array size. If n is not a Fibonacci number, let Fm be the smallest number in F that is greater than n.

The array of Fibonacci numbers is defined where Fk+2 = Fk+1 + Fk, when k ≥ 0, F1 = 1, and F0 = 1.

To test whether an item is in the list of ordered numbers, follow these steps:

    Set k = m.
    If k = 0, stop. There is no match; the item is not in the array.
    Compare the item against element in Fk−1.
    If the item matches, stop.
    If the item is less than entry Fk−1, discard the elements from positions Fk−1 + 1 to n. Set k = k − 1 and return to step 2.
    If the item is greater than entry Fk−1, discard the elements from positions 1 to Fk−1. Renumber the remaining elements from 1 to Fk−2, set k = k − 2, and return to step 2.

Alternative implementation (from "Sorting and Searching" by Knuth[4]):

Given a table of records R1, R2, ..., RN whose keys are in increasing order K1 < K2 < ... < KN, the algorithm searches for a given argument K. Assume N+1 = Fk+1

Step 1. [Initialize] i ← Fk, p ← Fk-1, q ← Fk-2 (throughout the algorithm, p and q will be consecutive Fibonacci numbers)

Step 2. [Compare] If K < Ki, go to Step 3; if K > Ki go to Step 4; and if K = Ki, the algorithm terminates successfully.

Step 3. [Decrease i] If q=0, the algorithm terminates unsuccessfully. Otherwise set (i, p, q) ← (i - q, q, p - q) (which moves p and q one position back in the Fibonacci sequence); then return to Step 2

Step 4. [Increase i] If p=1, the algorithm terminates unsuccessfully. Otherwise set (i,p,q) ← (i + q, p - q, 2q - p) (which moves p and q two positions back in the Fibonacci sequence); and return to Step 2

The two variants of the algorithm presented above always divide the current interval into a larger and a smaller subinterval. The original algorithm,[1] however, would divide the new interval into a smaller and a larger subinterval in Step 4. This has the advantage that the new i is closer to the old i and is more suitable for accelerating searching on magnetic tape. 

---------> Jump search (or block search): 
-----------> This linear search on a smaller subset of the sequence
a jump search or block search refers to a search algorithm for ordered lists. It works by first checking all items Lkm, where k ∈ N {\displaystyle k\in \mathbb {N} } k\in \mathbb {N} and m is the block size, until an item is found that is larger than the search key. To find the exact position of the search key in the list a linear search is performed on the sublist L[(k-1)m, km].

The optimal value of m is √n, where n is the length of the list L. Because both steps of the algorithm look at, at most, √n items the algorithm runs in O(√n) time. This is better than a linear search, but worse than a binary search. The advantage over the latter is that a jump search only needs to jump backwards once, while a binary can jump backwards up to log n times. This can be important if a jumping backwards takes significantly more time than jumping forward.

The algorithm can be modified by performing multiple levels of jump search on the sublists, before finally performing the linear search. For an k-level jump search the optimum block size ml for the l th level (counting from 1) is n(k-l)/k. The modified algorithm will perform k backward jumps and runs in O(kn1/(k+1)) time.
Implementation

algorithm JumpSearch is
    input: An ordered list L, its length n and a search key s.
    output: The position of s in L, or nothing if s is not in L.
    
    a ← 0
    b ← ⌊√n⌋
    
    while Lmin(b,n)-1 < s do
        a ← b
        b ← b + ⌊√n⌋
        if a ≥ n then
            return nothing
    
    while La < s do
        a ← a + 1
        if a = min(b, n)
            return nothing
    
    if La = s then
        return a
    else
        return nothing
		
---------> Predictive search: 
-----------> This binary-like search which factors in magnitude of search term versus the high and low values in the search.
Sometimes called dictionary search or interpolated search.
Interpolation search is an algorithm for searching for a key in an array that has been ordered by numerical values assigned to the keys (key values). It was first described by W. W. Peterson in 1957.[1] Interpolation search resembles the method by which people search a telephone directory for a name (the key value by which the book's entries are ordered): in each step the algorithm calculates where in the remaining search space the sought item might be, based on the key values at the bounds of the search space and the value of the sought key, usually via a linear interpolation. The key value actually found at this estimated position is then compared to the key value being sought. If it is not equal, then depending on the comparison, the remaining search space is reduced to the part before or after the estimated position. This method will only work if calculations on the size of differences between key values are sensible.
Interpolation searchInterpolation sort.gif
Visualization of the interpolation search algorithm in which 24 is the target value.
Class	Search algorithm
Data structure	Array
Worst-case performance	O(n)
Best-case performance	O(1)
Average performance	O(log(log(n)))[2]
Worst-case space complexity	O(1)

By comparison, binary search always chooses the middle of the remaining search space, discarding one half or the other, depending on the comparison between the key found at the estimated position and the key sought — it does not require numerical values for the keys, just a total order on them. The remaining search space is reduced to the part before or after the estimated position. The linear search uses equality only as it compares elements one-by-one from the start, ignoring any sorting.

On average the interpolation search makes about log(log(n)) comparisons (if the elements are uniformly distributed), where n is the number of elements to be searched. In the worst case (for instance where the numerical values of the keys increase exponentially) it can make up to O(n) comparisons.

In interpolation-sequential search, interpolation is used to find an item near the one being searched for, then linear search is used to find the exact item. 

---------> Uniform binary search: 
-----------> This an optimization of the classic binary search algorithm
Uniform binary search is an optimization of the classic binary search algorithm invented by Donald Knuth and given in Knuth's The Art of Computer Programming. It uses a lookup table to update a single array index, rather than taking the midpoint of an upper and a lower bound on each iteration; therefore, it is optimized for architectures (such as Knuth's MIX) on which

    a table lookup is generally faster than an addition and a shift, and
    many searches will be performed on the same array, or on several arrays of the same length

C implementation

The uniform binary search algorithm looks like this, when implemented in C.

#define LOG_N 4

static int delta[LOG_N];

void make_delta(int N)
{
    int power = 1;
    int i = 0;

    do {
        int half = power;
        power <<= 1;
        delta[i] = (N + half) / power;
    } while (delta[i++] != 0);
}

int unisearch(int *a, int key)
{
    int i = delta[0] - 1;  /* midpoint of array */
    int d = 0;

    while (1) {
        if (key == a[i]) {
            return i;
        } else if (delta[d] == 0) {
            return -1;
        } else {
            if (key < a[i]) {
                i -= delta[++d];
            } else {
                i += delta[++d];
            }
        }
    }
}

/* Example of use: */
#define N 10

int main(void)
{
    int a[N] = {1, 3, 5, 6, 7, 9, 14, 15, 17, 19};

    make_delta(N);

    for (int i = 0; i < 20; ++i)
        printf("%d is at index %d\n", i, unisearch(a, i));

    return 0;
}


Sequence merging

    Simple merge algorithm
    k-way merge algorithm
    Union (merge, with elements on the output not repeated)

Sequence permutations
Further information: Permutation

    Fisher–Yates shuffle (also known as the Knuth shuffle): randomly shuffle a finite set
    Schensted algorithm: constructs a pair of Young tableaux from a permutation
    Steinhaus–Johnson–Trotter algorithm (also known as the Johnson–Trotter algorithm): generates permutations by transposing elements
    Heap's permutation generation algorithm: interchange elements to generate next permutation

Sequence combinations
Further information: Combination
Sequence alignment

    Dynamic time warping: measure similarity between two sequences which may vary in time or speed
    Hirschberg's algorithm: finds the least cost sequence alignment between two sequences, as measured by their Levenshtein distance
    Needleman–Wunsch algorithm: find global alignment between two sequences
    Smith–Waterman algorithm: find local sequence alignment

Sequence sorting
Main article: Sorting algorithm
Accuracy dispute
 
This article appears to contradict the article Sorting_algorithm#Comparison_of_algorithms. Please see discussion on the linked talk page. (March 2011) (Learn how and when to remove this template message)

    Exchange sorts
        Bubble sort: for each pair of indices, swap the items if out of order
        Cocktail shaker sort or bidirectional bubble sort, a bubble sort traversing the list alternately from front to back and back to front
        Comb sort
        Gnome sort
        Odd–even sort
        Quicksort: divide list into two, with all items on the first list coming before all items on the second list.; then sort the two lists. Often the method of choice
    Humorous or ineffective
        Bogosort
        Stooge sort
    Hybrid
        Flashsort
        Introsort: begin with quicksort and switch to heapsort when the recursion depth exceeds a certain level
        Timsort: adaptative algorithm derived from merge sort and insertion sort. Used in Python 2.3 and up, and Java SE 7.
    Insertion sorts
        Insertion sort: determine where the current item belongs in the list of sorted ones, and insert it there
        Library sort
        Patience sorting
        Shell sort: an attempt to improve insertion sort
        Tree sort (binary tree sort): build binary tree, then traverse it to create sorted list
        Cycle sort: in-place with theoretically optimal number of writes
    Merge sorts
        Merge sort: sort the first and second half of the list separately, then merge the sorted lists
        Slowsort
        Strand sort
    Non-comparison sorts
        Bead sort
        Bucket sort
        Burstsort: build a compact, cache efficient burst trie and then traverse it to create sorted output
        Counting sort
        Pigeonhole sort
        Postman sort: variant of Bucket sort which takes advantage of hierarchical structure
        Radix sort: sorts strings letter by letter
    Selection sorts
        Heapsort: convert the list into a heap, keep removing the largest element from the heap and adding it to the end of the list
        Selection sort: pick the smallest of the remaining elements, add it to the end of the sorted list
        Smoothsort
    Other
        Bitonic sorter
        Pancake sorting
        Spaghetti sort
        Topological sort
    Unknown class
        Samplesort

Subsequences
Further information: Subsequence

    Kadane's algorithm: finds maximum sub-array of any size
    Longest common subsequence problem: Find the longest subsequence common to all sequences in a set of sequences
    Longest increasing subsequence problem: Find the longest increasing subsequence of a given sequence
    Ruzzo–Tompa algorithm: Find all non-overlapping, contiguous, maximal scoring subsequences in a sequence of real numbers
    Shortest common supersequence problem: Find the shortest supersequence that contains two or more sequences as subsequences

Substrings
Further information: Substring

    Longest common substring problem: find the longest string (or strings) that is a substring (or are substrings) of two or more strings
    Substring search
        Aho–Corasick string matching algorithm: trie based algorithm for finding all substring matches to any of a finite set of strings
        Boyer–Moore string-search algorithm: amortized linear (sublinear in most times) algorithm for substring search
        Boyer–Moore–Horspool algorithm: Simplification of Boyer–Moore
        Knuth–Morris–Pratt algorithm: substring search which bypasses reexamination of matched characters
        Rabin–Karp string search algorithm: searches multiple patterns efficiently
        Zhu–Takaoka string matching algorithm: a variant of Boyer–Moore
    Ukkonen's algorithm: a linear-time, online algorithm for constructing suffix trees
    Matching wildcards
        Rich Salz' wildmat: a widely used open-source recursive algorithm
        Krauss matching wildcards algorithm: an open-source non-recursive algorithm

Computational mathematics
Further information: Computational mathematics
See also: Combinatorial algorithms and Computational science
Abstract algebra
Further information: Abstract algebra

    Chien search: a recursive algorithm for determining roots of polynomials defined over a finite field
    Schreier–Sims algorithm: computing a base and strong generating set (BSGS) of a permutation group
    Todd–Coxeter algorithm: Procedure for generating cosets.

Computer algebra
Further information: Computer algebra

    Buchberger's algorithm: finds a Gröbner basis
    Cantor–Zassenhaus algorithm: factor polynomials over finite fields
    Faugère F4 algorithm: finds a Gröbner basis (also mentions the F5 algorithm)
    Gosper's algorithm: find sums of hypergeometric terms that are themselves hypergeometric terms
    Knuth–Bendix completion algorithm: for rewriting rule systems
    Multivariate division algorithm: for polynomials in several indeterminates
    Pollard's kangaroo algorithm (also known as Pollard's lambda algorithm ): an algorithm for solving the discrete logarithm problem
    Polynomial long division: an algorithm for dividing a polynomial by another polynomial of the same or lower degree
    Risch algorithm: an algorithm for the calculus operation of indefinite integration (i.e. finding antiderivatives)

Geometry
Main category: Geometric algorithms
Further information: Computational geometry

    Closest pair problem: find the pair of points (from a set of points) with the smallest distance between them
    Collision detection algorithms: check for the collision or intersection of two given solids
    Cone algorithm: identify surface points
    Convex hull algorithms: determining the convex hull of a set of points
        Graham scan
        Quickhull
        Gift wrapping algorithm or Jarvis march
        Chan's algorithm
        Kirkpatrick–Seidel algorithm
    Euclidean distance transform: computes the distance between every point in a grid and a discrete collection of points.
    Geometric hashing: a method for efficiently finding two-dimensional objects represented by discrete points that have undergone an affine transformation
    Gilbert–Johnson–Keerthi distance algorithm: determining the smallest distance between two convex shapes.
    Jump-and-Walk algorithm: an algorithm for point location in triangulations
    Laplacian smoothing: an algorithm to smooth a polygonal mesh
    Line segment intersection: finding whether lines intersect, usually with a sweep line algorithm
        Bentley–Ottmann algorithm
        Shamos–Hoey algorithm
    Minimum bounding box algorithms: find the oriented minimum bounding box enclosing a set of points
    Nearest neighbor search: find the nearest point or points to a query point
    Point in polygon algorithms: tests whether a given point lies within a given polygon
    Point set registration algorithms: finds the transformation between two point sets to optimally align them.
    Rotating calipers: determine all antipodal pairs of points and vertices on a convex polygon or convex hull.
    Shoelace algorithm: determine the area of a polygon whose vertices are described by ordered pairs in the plane
    Triangulation
        Delaunay triangulation
            Ruppert's algorithm (also known as Delaunay refinement): create quality Delaunay triangulations
            Chew's second algorithm: create quality constrained Delaunay triangulations
        Marching triangles: reconstruct two-dimensional surface geometry from an unstructured point cloud
        Polygon triangulation algorithms: decompose a polygon into a set of triangles
        Voronoi diagrams, geometric dual of Delaunay triangulation
            Bowyer–Watson algorithm: create voronoi diagram in any number of dimensions
            Fortune's Algorithm: create voronoi diagram
        Quasitriangulation

Number theoretic algorithms
Further information: Number theory

    Binary GCD algorithm: Efficient way of calculating GCD.
    Booth's multiplication algorithm
    Chakravala method: a cyclic algorithm to solve indeterminate quadratic equations, including Pell's equation
    Discrete logarithm:
        Baby-step giant-step
        Index calculus algorithm
        Pollard's rho algorithm for logarithms
        Pohlig–Hellman algorithm
    Euclidean algorithm: computes the greatest common divisor
    Extended Euclidean algorithm: Also solves the equation ax + by = c.
    Integer factorization: breaking an integer into its prime factors
        Congruence of squares
        Dixon's algorithm
        Fermat's factorization method
        General number field sieve
        Lenstra elliptic curve factorization
        Pollard's p − 1 algorithm
        Pollard's rho algorithm
        prime factorization algorithm
        Quadratic sieve
        Shor's algorithm
        Special number field sieve
        Trial division
    Multiplication algorithms: fast multiplication of two numbers
        Karatsuba algorithm
        Schönhage–Strassen algorithm
        Toom–Cook multiplication
    Modular square root: computing square roots modulo a prime number
        Tonelli–Shanks algorithm
        Cipolla's algorithm
        Berlekamp's root finding algorithm
    Odlyzko–Schönhage algorithm: calculates nontrivial zeroes of the Riemann zeta function
    Lenstra–Lenstra–Lovász algorithm (also known as LLL algorithm): find a short, nearly orthogonal lattice basis in polynomial time
    Primality tests: determining whether a given number is prime
        AKS primality test
        Baillie–PSW primality test
        Fermat primality test
        Lucas primality test
        Miller–Rabin primality test
        Sieve of Atkin
        Sieve of Eratosthenes
        Sieve of Sundaram

Numerical algorithms
Further information: Numerical analysis and List of numerical analysis topics
Differential equation solving
Further information: Differential equation

    Euler method
    Backward Euler method
    Trapezoidal rule (differential equations)
    Linear multistep methods
    Runge–Kutta methods
        Euler integration
    Multigrid methods (MG methods), a group of algorithms for solving differential equations using a hierarchy of discretizations
    Partial differential equation:
        Finite difference method
        Crank–Nicolson method for diffusion equations
        Lax–Wendroff for wave equations
    Verlet integration (French pronunciation: ​[vɛʁˈlɛ]): integrate Newton's equations of motion

Elementary and special functions
Further information: Special functions

    Computation of π:
        Borwein's algorithm: an algorithm to calculate the value of 1/π
        Gauss–Legendre algorithm: computes the digits of pi
        Chudnovsky algorithm: A fast method for calculating the digits of π
        Bailey–Borwein–Plouffe formula: (BBP formula) a spigot algorithm for the computation of the nth binary digit of π
    Division algorithms: for computing quotient and/or remainder of two numbers
        Long division
        Restoring division
        Non-restoring division
        SRT division
        Newton–Raphson division: uses Newton's method to find the reciprocal of D, and multiply that reciprocal by N to find the final quotient Q.
        Goldschmidt division
    Hyperbolic and Trigonometric Functions:
        BKM algorithm: computes elementary functions using a table of logarithms
        CORDIC: computes hyperbolic and trigonometric functions using a table of arctangents
    Exponentiation:
        Addition-chain exponentiation: exponentiation by positive integer powers that requires a minimal number of multiplications
        Exponentiating by squaring: an algorithm used for the fast computation of large integer powers of a number
    Montgomery reduction: an algorithm that allows modular arithmetic to be performed efficiently when the modulus is large
    Multiplication algorithms: fast multiplication of two numbers
        Booth's multiplication algorithm: a multiplication algorithm that multiplies two signed binary numbers in two's complement notation
        Fürer's algorithm: an integer multiplication algorithm for very large numbers possessing a very low asymptotic complexity
        Karatsuba algorithm: an efficient procedure for multiplying large numbers
        Schönhage–Strassen algorithm: an asymptotically fast multiplication algorithm for large integers
        Toom–Cook multiplication: (Toom3) a multiplication algorithm for large integers
    Multiplicative inverse Algorithms: for computing a number's multiplicative inverse (reciprocal).
        Newton's method
    Rounding functions: the classic ways to round numbers
    Spigot algorithm: A way to compute the value of a mathematical constant without knowing preceding digits
    Square and Nth root of a number:
        Alpha max plus beta min algorithm: an approximation of the square-root of the sum of two squares
        Methods of computing square roots
        nth root algorithm
        Shifting nth-root algorithm: digit by digit root extraction
    Summation:
        Binary splitting: a divide and conquer technique which speeds up the numerical evaluation of many types of series with rational terms
        Kahan summation algorithm: a more accurate method of summing floating-point numbers
    Unrestricted algorithm

Geometric

    Filtered back-projection: efficiently computes the inverse 2-dimensional Radon transform.
    Level set method (LSM): a numerical technique for tracking interfaces and shapes

Interpolation and extrapolation
Further information: Interpolation and Extrapolation

    Birkhoff interpolation: an extension of polynomial interpolation
    Cubic interpolation
    Hermite interpolation
    Lagrange interpolation: interpolation using Lagrange polynomials
    Linear interpolation: a method of curve fitting using linear polynomials
    Monotone cubic interpolation: a variant of cubic interpolation that preserves monotonicity of the data set being interpolated.
    Multivariate interpolation
        Bicubic interpolation, a generalization of cubic interpolation to two dimensions
        Bilinear interpolation: an extension of linear interpolation for interpolating functions of two variables on a regular grid
        Lanczos resampling ("Lanzosh"): a multivariate interpolation method used to compute new values for any digitally sampled data
        Nearest-neighbor interpolation
        Tricubic interpolation, a generalization of cubic interpolation to three dimensions
    Pareto interpolation: a method of estimating the median and other properties of a population that follows a Pareto distribution.
    Polynomial interpolation
        Neville's algorithm
    Spline interpolation: Reduces error with Runge's phenomenon.
        De Boor algorithm: B-splines
        De Casteljau's algorithm: Bézier curves
    Trigonometric interpolation

Linear algebra
Further information: Numerical linear algebra

    Eigenvalue algorithms
        Arnoldi iteration
        Inverse iteration
        Jacobi method
        Lanczos iteration
        Power iteration
        QR algorithm
        Rayleigh quotient iteration
    Gram–Schmidt process: orthogonalizes a set of vectors
    Matrix multiplication algorithms
        Cannon's algorithm: a distributed algorithm for matrix multiplication especially suitable for computers laid out in an N × N mesh
        Coppersmith–Winograd algorithm: square matrix multiplication
        Freivalds' algorithm: a randomized algorithm used to verify matrix multiplication
        Strassen algorithm: faster matrix multiplication

    Solving systems of linear equations
        Biconjugate gradient method: solves systems of linear equations
        Conjugate gradient: an algorithm for the numerical solution of particular systems of linear equations
        Gaussian elimination
        Gauss–Jordan elimination: solves systems of linear equations
        Gauss–Seidel method: solves systems of linear equations iteratively
        Levinson recursion: solves equation involving a Toeplitz matrix
        Stone's method: also known as the strongly implicit procedure or SIP, is an algorithm for solving a sparse linear system of equations
        Successive over-relaxation (SOR): method used to speed up convergence of the Gauss–Seidel method
        Tridiagonal matrix algorithm (Thomas algorithm): solves systems of tridiagonal equations
    Sparse matrix algorithms
        Cuthill–McKee algorithm: reduce the bandwidth of a symmetric sparse matrix
        Minimum degree algorithm: permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition
        Symbolic Cholesky decomposition: Efficient way of storing sparse matrix

Monte Carlo
Further information: Monte Carlo method

    Gibbs sampling: generates a sequence of samples from the joint probability distribution of two or more random variables
    Hybrid Monte Carlo: generates a sequence of samples using Hamiltonian weighted Markov chain Monte Carlo, from a probability distribution which is difficult to sample directly.
    Metropolis–Hastings algorithm: used to generate a sequence of samples from the probability distribution of one or more variables
    Wang and Landau algorithm: an extension of Metropolis–Hastings algorithm sampling

Numerical integration
Further information: Numerical integration

    MISER algorithm: Monte Carlo simulation, numerical integration

Root finding
Main article: Root-finding algorithm

    Bisection method
    False position method: approximates roots of a function
    ITP method: minmax optimal and superlinar convergence simultaneously
    Newton's method: finds zeros of functions with calculus
    Halley's method: uses first and second derivatives
    Secant method: 2-point, 1-sided
    False position method and Illinois method: 2-point, bracketing
    Ridder's method: 3-point, exponential scaling
    Muller's method: 3-point, quadratic interpolation

Optimization algorithms
Main article: Mathematical optimization

    Alpha–beta pruning: search to reduce number of nodes in minimax algorithm
    Branch and bound
    Bruss algorithm: see odds algorithm
    Chain matrix multiplication
    Combinatorial optimization: optimization problems where the set of feasible solutions is discrete
        Greedy randomized adaptive search procedure (GRASP): successive constructions of a greedy randomized solution and subsequent iterative improvements of it through a local search
        Hungarian method: a combinatorial optimization algorithm which solves the assignment problem in polynomial time
    Constraint satisfaction
        General algorithms for the constraint satisfaction
            AC-3 algorithm
            Difference map algorithm
            Min conflicts algorithm
        Chaff algorithm: an algorithm for solving instances of the boolean satisfiability problem
        Davis–Putnam algorithm: check the validity of a first-order logic formula
        Davis–Putnam–Logemann–Loveland algorithm (DPLL): an algorithm for deciding the satisfiability of propositional logic formula in conjunctive normal form, i.e. for solving the CNF-SAT problem
        Exact cover problem
            Algorithm X: a nondeterministic algorithm
            Dancing Links: an efficient implementation of Algorithm X
    Cross-entropy method: a general Monte Carlo approach to combinatorial and continuous multi-extremal optimization and importance sampling
    Differential evolution
    Dynamic Programming: problems exhibiting the properties of overlapping subproblems and optimal substructure
    Ellipsoid method: is an algorithm for solving convex optimization problems
    Evolutionary computation: optimization inspired by biological mechanisms of evolution
        Evolution strategy
        Gene expression programming
        Genetic algorithms
            Fitness proportionate selection – also known as roulette-wheel selection
            Stochastic universal sampling
            Truncation selection
            Tournament selection
        Memetic algorithm
        Swarm intelligence
            Ant colony optimization
            Bees algorithm: a search algorithm which mimics the food foraging behavior of swarms of honey bees
            Particle swarm
    Frank-Wolfe algorithm: an iterative first-order optimization algorithm for constrained convex optimization
    Golden-section search: an algorithm for finding the maximum of a real function
    Gradient descent
    Grid Search
    Harmony search (HS): a metaheuristic algorithm mimicking the improvisation process of musicians
    Interior point method
    Linear programming
        Benson's algorithm: an algorithm for solving linear vector optimization problems
        Dantzig–Wolfe decomposition: an algorithm for solving linear programming problems with special structure
        Delayed column generation
        Integer linear programming: solve linear programming problems where some or all the unknowns are restricted to integer values
            Branch and cut
            Cutting-plane method
        Karmarkar's algorithm: The first reasonably efficient algorithm that solves the linear programming problem in polynomial time.
        Simplex algorithm: An algorithm for solving linear programming problems
    Line search
    Local search: a metaheuristic for solving computationally hard optimization problems
        Random-restart hill climbing
        Tabu search
    Minimax used in game programming
    Nearest neighbor search (NNS): find closest points in a metric space
        Best Bin First: find an approximate solution to the nearest neighbor search problem in very-high-dimensional spaces
    Newton's method in optimization
    Nonlinear optimization
        BFGS method: A nonlinear optimization algorithm
        Gauss–Newton algorithm: An algorithm for solving nonlinear least squares problems.
        Levenberg–Marquardt algorithm: An algorithm for solving nonlinear least squares problems.
        Nelder–Mead method (downhill simplex method): A nonlinear optimization algorithm
    Odds algorithm (Bruss algorithm): Finds the optimal strategy to predict a last specific event in a random sequence event
    Random Search
    Simulated annealing
    Stochastic tunneling
    Subset sum algorithm

Computational science
Further information: Computational science
Astronomy

    Doomsday algorithm: day of the week
    Zeller's congruence is an algorithm to calculate the day of the week for any Julian or Gregorian calendar date
    various Easter algorithms are used to calculate the day of Easter

Bioinformatics
Further information: Bioinformatics
See also: Sequence alignment algorithms

    Basic Local Alignment Search Tool also known as BLAST: an algorithm for comparing primary biological sequence information
    Kabsch algorithm: calculate the optimal alignment of two sets of points in order to compute the root mean squared deviation between two protein structures.
    Velvet: a set of algorithms manipulating de Bruijn graphs for genomic sequence assembly
    Sorting by signed reversals: an algorithm for understanding genomic evolution.
    Maximum parsimony (phylogenetics): an algorithm for finding the simplest phylogenetic tree to explain a given character matrix.
    UPGMA: a distance-based phylogenetic tree construction algorithm.

Geoscience
Further information: Geoscience

    Vincenty's formulae: a fast algorithm to calculate the distance between two latitude/longitude points on an ellipsoid
    Geohash: a public domain algorithm that encodes a decimal latitude/longitude pair as a hash string

Linguistics
Further information: Computational linguistics and Natural language processing

    Lesk algorithm: word sense disambiguation
    Stemming algorithm: a method of reducing words to their stem, base, or root form
    Sukhotin's algorithm: a statistical classification algorithm for classifying characters in a text as vowels or consonants

Medicine
Further information: Medical algorithms

    ESC algorithm for the diagnosis of heart failure
    Manning Criteria for irritable bowel syndrome
    Pulmonary embolism diagnostic algorithms
    Texas Medication Algorithm Project

Physics
Further information: Computational physics

    Constraint algorithm: a class of algorithms for satisfying constraints for bodies that obey Newton's equations of motion
    Demon algorithm: a Monte Carlo method for efficiently sampling members of a microcanonical ensemble with a given energy
    Featherstone's algorithm: computes the effects of forces applied to a structure of joints and links
    Ground state approximation
        Variational method
            Ritz method
    n-body problems
        Barnes–Hut simulation: Solves the n-body problem in an approximate way that has the order O(n log n) instead of O(n2) as in a direct-sum simulation.
        Fast multipole method (FMM): speeds up the calculation of long-ranged forces
    Rainflow-counting algorithm: Reduces a complex stress history to a count of elementary stress-reversals for use in fatigue analysis
    Sweep and prune: a broad phase algorithm used during collision detection to limit the number of pairs of solids that need to be checked for collision
    VEGAS algorithm: a method for reducing error in Monte Carlo simulations
    Glauber dynamics: a method for simulating the Ising Model on a computer

Statistics
Further information: Computational statistics

    Algorithms for calculating variance: avoiding instability and numerical overflow
    Approximate counting algorithm: Allows counting large number of events in a small register
    Bayesian statistics
        Nested sampling algorithm: a computational approach to the problem of comparing models in Bayesian statistics
    Clustering Algorithms
        Average-linkage clustering: a simple agglomerative clustering algorithm
        Canopy clustering algorithm: an unsupervised pre-clustering algorithm related to the K-means algorithm
        Complete-linkage clustering: a simple agglomerative clustering algorithm
        DBSCAN: a density based clustering algorithm
        Expectation-maximization algorithm
        Fuzzy clustering: a class of clustering algorithms where each point has a degree of belonging to clusters
            Fuzzy c-means
            FLAME clustering (Fuzzy clustering by Local Approximation of MEmberships): define clusters in the dense parts of a dataset and perform cluster assignment solely based on the neighborhood relationships among objects
        KHOPCA clustering algorithm: a local clustering algorithm, which produces hierarchical multi-hop clusters in static and mobile environments.
        k-means clustering: cluster objects based on attributes into partitions
        k-means++: a variation of this, using modified random seeds
        k-medoids: similar to k-means, but chooses datapoints or medoids as centers
        Linde–Buzo–Gray algorithm: a vector quantization algorithm to derive a good codebook
        Lloyd's algorithm (Voronoi iteration or relaxation): group data points into a given number of categories, a popular algorithm for k-means clustering
        OPTICS: a density based clustering algorithm with a visual evaluation method
        Single-linkage clustering: a simple agglomerative clustering algorithm
        SUBCLU: a subspace clustering algorithm
        Ward's method: an agglomerative clustering algorithm, extended to more general Lance–Williams algorithms
        WACA clustering algorithm: a local clustering algorithm with potentially multi-hop structures; for dynamic networks
    Estimation Theory
        Expectation-maximization algorithm A class of related algorithms for finding maximum likelihood estimates of parameters in probabilistic models
            Ordered subset expectation maximization (OSEM): used in medical imaging for positron emission tomography, single-photon emission computed tomography and X-ray computed tomography.
        Odds algorithm (Bruss algorithm) Optimal online search for distinguished value in sequential random input
        Kalman filter: estimate the state of a linear dynamic system from a series of noisy measurements
    False nearest neighbor algorithm (FNN) estimates fractal dimension
    Hidden Markov model
        Baum–Welch algorithm: computes maximum likelihood estimates and posterior mode estimates for the parameters of a hidden Markov model
        Forward-backward algorithm: a dynamic programming algorithm for computing the probability of a particular observation sequence
        Viterbi algorithm: find the most likely sequence of hidden states in a hidden Markov model
    Partial least squares regression: finds a linear model describing some predicted variables in terms of other observable variables
    Queuing theory
        Buzen's algorithm: an algorithm for calculating the normalization constant G(K) in the Gordon–Newell theorem
    RANSAC (an abbreviation for "RANdom SAmple Consensus"): an iterative method to estimate parameters of a mathematical model from a set of observed data which contains outliers
    Scoring algorithm: is a form of Newton's method used to solve maximum likelihood equations numerically
    Yamartino method: calculate an approximation to the standard deviation σθ of wind direction θ during a single pass through the incoming data
    Ziggurat algorithm: generates random numbers from a non-uniform distribution

Computer science
Further information: Computer science
Computer architecture
Further information: Computer architecture

    Tomasulo algorithm: allows sequential instructions that would normally be stalled due to certain dependencies to execute non-sequentially

Computer graphics
Further information: Computer graphics

    Clipping
        Line clipping
            Cohen–Sutherland
            Cyrus–Beck
            Fast-clipping
            Liang–Barsky
            Nicholl–Lee–Nicholl
        Polygon clipping
            Sutherland–Hodgman
            Vatti
            Weiler–Atherton
    Contour lines and Isosurfaces
        Marching cubes: extract a polygonal mesh of an isosurface from a three-dimensional scalar field (sometimes called voxels)
        Marching squares: generates contour lines for a two-dimensional scalar field
        Marching tetrahedrons: an alternative to Marching cubes
    Discrete Green's Theorem: is an algorithm for computing double integral over a generalized rectangular domain in constant time. It is a natural extension to the summed area table algorithm
    Flood fill: fills a connected region of a multi-dimensional array with a specified symbol
    Global illumination algorithms: Considers direct illumination and reflection from other objects.
        Ambient occlusion
        Beam tracing
        Cone tracing
        Image-based lighting
        Metropolis light transport
        Path tracing
        Photon mapping
        Radiosity
        Ray tracing
    Hidden-surface removal or Visual surface determination
        Newell's algorithm: eliminate polygon cycles in the depth sorting required in hidden-surface removal
        Painter's algorithm: detects visible parts of a 3-dimensional scenery
        Scanline rendering: constructs an image by moving an imaginary line over the image
        Warnock algorithm
    Line Drawing: graphical algorithm for approximating a line segment on discrete graphical media.
        Bresenham's line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses decision variables)
        DDA line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses floating-point math)
        Xiaolin Wu's line algorithm: algorithm for line antialiasing.
    Midpoint circle algorithm: an algorithm used to determine the points needed for drawing a circle
    Ramer–Douglas–Peucker algorithm: Given a 'curve' composed of line segments to find a curve not too dissimilar but that has fewer points
    Shading
        Gouraud shading: an algorithm to simulate the differing effects of light and colour across the surface of an object in 3D computer graphics
        Phong shading: an algorithm to interpolate surface normal-vectors for surface shading in 3D computer graphics
    Slerp (spherical linear interpolation): quaternion interpolation for the purpose of animating 3D rotation
    Summed area table (also known as an integral image): an algorithm for computing the sum of values in a rectangular subset of a grid in constant time

Cryptography
Further information: Cryptography and Topics in cryptography

    Asymmetric (public key) encryption:
        ElGamal
        Elliptic curve cryptography
        MAE1
        NTRUEncrypt
        RSA
    Digital signatures (asymmetric authentication):
        DSA, and its variants:
            ECDSA and Deterministic ECDSA
            EdDSA (Ed25519)
        RSA
    Cryptographic hash functions (see also the section on message authentication codes):
        BLAKE
        MD5 – Note that there is now a method of generating collisions for MD5
        RIPEMD-160
        SHA-1 – Note that there is now a method of generating collisions for SHA-1
        SHA-2 (SHA-224, SHA-256, SHA-384, SHA-512)
        SHA-3 (SHA3-224, SHA3-256, SHA3-384, SHA3-512, SHAKE128, SHAKE256)
        Tiger (TTH), usually used in Tiger tree hashes
        WHIRLPOOL
    Cryptographically secure pseudo-random number generators
        Blum Blum Shub – based on the hardness of factorization
        Fortuna, intended as an improvement on Yarrow algorithm
        Linear-feedback shift register (note: many LFSR-based algorithms are weak or have been broken)
        Yarrow algorithm
    Key exchange
        Diffie–Hellman key exchange
        Elliptic-curve Diffie–Hellman (ECDH)
    Key derivation functions, often used for password hashing and key stretching
        bcrypt
        PBKDF2
        scrypt
        Argon2
    Message authentication codes (symmetric authentication algorithms, which take a key as a parameter):
        HMAC: keyed-hash message authentication
        Poly1305
        SipHash
    Secret sharing, Secret Splitting, Key Splitting, M of N algorithms
        Blakey's Scheme
        Shamir's Scheme
    Symmetric (secret key) encryption:
        Advanced Encryption Standard (AES), winner of NIST competition, also known as Rijndael
        Blowfish
        Twofish
        Threefish
        Data Encryption Standard (DES), sometimes DE Algorithm, winner of NBS selection competition, replaced by AES for most purposes
        IDEA
        RC4 (cipher)
        Tiny Encryption Algorithm (TEA)
        Salsa20, and its updated variant ChaCha20
    Post-quantum cryptography
    Proof-of-work algorithms

Digital logic

    Boolean minimization
        Quine–McCluskey algorithm: Also called as Q-M algorithm, programmable method for simplifying the boolean equations.
        Petrick's method: Another algorithm for boolean simplification.
        Espresso heuristic logic minimizer: Fast algorithm for boolean function minimization.

Machine learning and statistical classification
Main article: List of machine learning algorithms
Further information: Machine learning and Statistical classification

    ALOPEX: a correlation-based machine-learning algorithm
    Association rule learning: discover interesting relations between variables, used in data mining
        Apriori algorithm
        Eclat algorithm
        FP-growth algorithm
        One-attribute rule
        Zero-attribute rule
    Boosting (meta-algorithm): Use many weak learners to boost effectiveness
        AdaBoost: adaptive boosting
        BrownBoost: a boosting algorithm that may be robust to noisy datasets
        LogitBoost: logistic regression boosting
        LPBoost: linear programming boosting
    Bootstrap aggregating (bagging): technique to improve stability and classification accuracy
    Computer Vision
        Grabcut based on Graph cuts
    Decision Trees
        C4.5 algorithm: an extension to ID3
        ID3 algorithm (Iterative Dichotomiser 3): use heuristic to generate small decision trees
    Clustering: a class of unsupervised learning algorithms for grouping and bucketing related input vector.
        k-nearest neighbors (k-NN): a method for classifying objects based on closest training examples in the feature space
    Linde–Buzo–Gray algorithm: a vector quantization algorithm used to derive a good codebook
    Locality-sensitive hashing (LSH): a method of performing probabilistic dimension reduction of high-dimensional data
    Neural Network
        Backpropagation: A supervised learning method which requires a teacher that knows, or can calculate, the desired output for any given input
        Hopfield net: a Recurrent neural network in which all connections are symmetric
        Perceptron: the simplest kind of feedforward neural network: a linear classifier.
        Pulse-coupled neural networks (PCNN): Neural models proposed by modeling a cat's visual cortex and developed for high-performance biomimetic image processing.
        Radial basis function network: an artificial neural network that uses radial basis functions as activation functions
        Self-organizing map: an unsupervised network that produces a low-dimensional representation of the input space of the training samples
    Random forest: classify using many decision trees
    Reinforcement learning:
        Q-learning: learns an action-value function that gives the expected utility of taking a given action in a given state and following a fixed policy thereafter
        State–Action–Reward–State–Action (SARSA): learn a Markov decision process policy
        Temporal difference learning
    Relevance-Vector Machine (RVM): similar to SVM, but provides probabilistic classification
    Supervised learning: Learning by examples (labelled data-set split into training-set and test-set)
    Support-Vector Machine (SVM): a set of methods which divide multidimensional data by finding a dividing hyperplane with the maximum margin between the two sets
        Structured SVM: allows training of a classifier for general structured output labels.
    Winnow algorithm: related to the perceptron, but uses a multiplicative weight-update scheme

Programming language theory
Further information: Programming language theory

    C3 linearization: an algorithm used primarily to obtain a consistent linearization of a multiple inheritance hierarchy in object-oriented programming
    Chaitin's algorithm: a bottom-up, graph coloring register allocation algorithm that uses cost/degree as its spill metric
    Hindley–Milner type inference algorithm
    Rete algorithm: an efficient pattern matching algorithm for implementing production rule systems
    Sethi-Ullman algorithm: generates optimal code for arithmetic expressions

Parsing
Further information: Parsing

    CYK algorithm: An O(n3) algorithm for parsing context-free grammars in Chomsky normal form
    Earley parser: Another O(n3) algorithm for parsing any context-free grammar
    GLR parser:An algorithm for parsing any context-free grammar by Masaru Tomita. It is tuned for deterministic grammars, on which it performs almost linear time and O(n3) in worst case.
    Inside-outside algorithm: An O(n3) algorithm for re-estimating production probabilities in probabilistic context-free grammars
    LL parser: A relatively simple linear time parsing algorithm for a limited class of context-free grammars
    LR parser: A more complex linear time parsing algorithm for a larger class of context-free grammars. Variants:
        Canonical LR parser
        LALR (look-ahead LR) parser
        Operator-precedence parser
        SLR (Simple LR) parser
        Simple precedence parser
    Packrat parser: A linear time parsing algorithm supporting some context-free grammars and parsing expression grammars
    Recursive descent parser: A top-down parser suitable for LL(k) grammars
    Shunting-yard algorithm: convert an infix-notation math expression to postfix
    Pratt parser
    Lexical analysis

Quantum algorithms
Further information: Quantum algorithm

    Deutsch–Jozsa algorithm: criterion of balance for Boolean function
    Grover's algorithm: provides quadratic speedup for many search problems
    Shor's algorithm: provides exponential speedup (relative to currently known non-quantum algorithms) for factoring a number
    Simon's algorithm: provides a provably exponential speedup (relative to any non-quantum algorithm) for a black-box problem

Theory of computation and automata
Further information: Theory of computation

    Hopcroft's algorithm, Moore's algorithm, and Brzozowski's algorithm: algorithms for minimizing the number of states in a deterministic finite automaton
    Powerset construction: Algorithm to convert nondeterministic automaton to deterministic automaton.
    Tarski–Kuratowski algorithm: a non-deterministic algorithm which provides an upper bound for the complexity of formulas in the arithmetical hierarchy and analytical hierarchy

Information theory and signal processing
Main articles: Information theory and Signal processing
Coding theory
Further information: Coding theory
Error detection and correction
Further information: Error detection and correction

    BCH Codes
        Berlekamp–Massey algorithm
        Peterson–Gorenstein–Zierler algorithm
        Reed–Solomon error correction
    BCJR algorithm: decoding of error correcting codes defined on trellises (principally convolutional codes)
    Forward error correction
    Gray code
    Hamming codes
        Hamming(7,4): a Hamming code that encodes 4 bits of data into 7 bits by adding 3 parity bits
        Hamming distance: sum number of positions which are different
        Hamming weight (population count): find the number of 1 bits in a binary word
    Redundancy checks
        Adler-32
        Cyclic redundancy check
        Damm algorithm
        Fletcher's checksum
        Longitudinal redundancy check (LRC)
        Luhn algorithm: a method of validating identification numbers
        Luhn mod N algorithm: extension of Luhn to non-numeric characters
        Parity: simple/fast error detection technique
        Verhoeff algorithm

Lossless compression algorithms
Main page: Lossless compression algorithms

    Burrows–Wheeler transform: preprocessing useful for improving lossless compression
    Context tree weighting
    Delta encoding: aid to compression of data in which sequential data occurs frequently
    Dynamic Markov compression: Compression using predictive arithmetic coding
    Dictionary coders
        Byte pair encoding (BPE)
        Deflate
        Lempel–Ziv
            LZ77 and LZ78
            Lempel–Ziv Jeff Bonwick (LZJB)
            Lempel–Ziv–Markov chain algorithm (LZMA)
            Lempel–Ziv–Oberhumer (LZO): speed oriented
            Lempel–Ziv–Stac (LZS)
            Lempel–Ziv–Storer–Szymanski (LZSS)
            Lempel–Ziv–Welch (LZW)
            LZWL: syllable-based variant
            LZX
            Lempel–Ziv Ross Williams (LZRW)
    Entropy encoding: coding scheme that assigns codes to symbols so as to match code lengths with the probabilities of the symbols
        Arithmetic coding: advanced entropy coding
            Range encoding: same as arithmetic coding, but looked at in a slightly different way
        Huffman coding: simple lossless compression taking advantage of relative character frequencies
            Adaptive Huffman coding: adaptive coding technique based on Huffman coding
            Package-merge algorithm: Optimizes Huffman coding subject to a length restriction on code strings
        Shannon–Fano coding
        Shannon–Fano–Elias coding: precursor to arithmetic encoding[1]
    Entropy coding with known entropy characteristics
        Golomb coding: form of entropy coding that is optimal for alphabets following geometric distributions
        Rice coding: form of entropy coding that is optimal for alphabets following geometric distributions
        Truncated binary encoding
        Unary coding: code that represents a number n with n ones followed by a zero
        Universal codes: encodes positive integers into binary code words
            Elias delta, gamma, and omega coding
            Exponential-Golomb coding
            Fibonacci coding
            Levenshtein coding
    Fast Efficient & Lossless Image Compression System (FELICS): a lossless image compression algorithm
    Incremental encoding: delta encoding applied to sequences of strings
    Prediction by partial matching (PPM): an adaptive statistical data compression technique based on context modeling and prediction
    Run-length encoding: lossless data compression taking advantage of strings of repeated characters
    SEQUITUR algorithm: lossless compression by incremental grammar inference on a string

Lossy compression algorithms
Main page: Lossy compression algorithms

    3Dc: a lossy data compression algorithm for normal maps
    Audio and Speech compression
        A-law algorithm: standard companding algorithm
        Code-excited linear prediction (CELP): low bit-rate speech compression
        Linear predictive coding (LPC): lossy compression by representing the spectral envelope of a digital signal of speech in compressed form
        Mu-law algorithm: standard analog signal compression or companding algorithm
        Warped Linear Predictive Coding (WLPC)
    Image compression
        Block Truncation Coding (BTC): a type of lossy image compression technique for greyscale images
        Embedded Zerotree Wavelet (EZW)
        Fast Cosine Transform algorithms (FCT algorithms): computes Discrete Cosine Transform (DCT) efficiently
        Fractal compression: method used to compress images using fractals
        Set Partitioning in Hierarchical Trees (SPIHT)
        Wavelet compression: form of data compression well suited for image compression (sometimes also video compression and audio compression)
    Transform coding: type of data compression for "natural" data like audio signals or photographic images
    Video compression
    Vector quantization: technique often used in lossy data compression

Digital signal processing
Further information: Digital signal processing

    Adaptive-additive algorithm (AA algorithm): find the spatial frequency phase of an observed wave source
    Discrete Fourier transform: determines the frequencies contained in a (segment of a) signal
        Bluestein's FFT algorithm
        Bruun's FFT algorithm
        Cooley–Tukey FFT algorithm
        Fast Fourier transform
        Prime-factor FFT algorithm
        Rader's FFT algorithm
    Fast folding algorithm: an efficient algorithm for the detection of approximately periodic events within time series data
    Gerchberg–Saxton algorithm: Phase retrieval algorithm for optical planes
    Goertzel algorithm: identify a particular frequency component in a signal. Can be used for DTMF digit decoding.
    Karplus-Strong string synthesis: physical modelling synthesis to simulate the sound of a hammered or plucked string or some types of percussion

Image processing
Further information: Digital image processing

    Contrast Enhancement
        Histogram equalization: use histogram to improve image contrast
        Adaptive histogram equalization: histogram equalization which adapts to local changes in contrast
    Connected-component labeling: find and label disjoint regions
    Dithering and half-toning
        Error diffusion
        Floyd–Steinberg dithering
        Ordered dithering
        Riemersma dithering
    Elser difference-map algorithm: a search algorithm for general constraint satisfaction problems. Originally used for X-Ray diffraction microscopy
    Feature detection
        Canny edge detector: detect a wide range of edges in images
        Generalised Hough transform
        Hough transform
        Marr–Hildreth algorithm: an early edge detection algorithm
        SIFT (Scale-invariant feature transform): is an algorithm to detect and describe local features in images.
        SURF (Speeded Up Robust Features): is a robust local feature detector, first presented by Herbert Bay et al. in 2006, that can be used in computer vision tasks like object recognition or 3D reconstruction. It is partly inspired by the SIFT descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.[2][3]
    Richardson–Lucy deconvolution: image de-blurring algorithm
    Blind deconvolution: image de-blurring algorithm when point spread function is unknown.
    Median filtering
    Seam carving: content-aware image resizing algorithm
    Segmentation: partition a digital image into two or more regions
        GrowCut algorithm: an interactive segmentation algorithm
        Random walker algorithm
        Region growing
        Watershed transformation: a class of algorithms based on the watershed analogy

Software engineering
Further information: Software engineering

    Cache algorithms
    CHS conversion: converting between disk addressing systems
    Double dabble: Convert binary numbers to BCD
    Hash Function: convert a large, possibly variable-sized amount of data into a small datum, usually a single integer that may serve as an index into an array
        Fowler–Noll–Vo hash function: fast with low collision rate
        Pearson hashing: computes 8 bit value only, optimized for 8 bit computers
        Zobrist hashing: used in the implementation of transposition tables
    Unicode Collation Algorithm
    Xor swap algorithm: swaps the values of two variables without using a buffer

Database algorithms
Further information: Database

    Algorithms for Recovery and Isolation Exploiting Semantics (ARIES): transaction recovery
    Join algorithms
        Block nested loop
        Hash join
        Nested loop join
        Sort-Merge Join

Distributed systems algorithms
Further information: Distributed algorithm and Distributed systems

    Clock synchronization
        Berkeley algorithm
        Cristian's algorithm
        Intersection algorithm
        Marzullo's algorithm
    Consensus (computer science): agreeing on a single value or history among unreliable processors
        Chandra–Toueg consensus algorithm
        Paxos algorithm
        Raft (computer science)
    Detection of Process Termination
        Dijkstra-Scholten algorithm
        Huang's algorithm
    Lamport ordering: a partial ordering of events based on the happened-before relation
    Leader election: a method for dynamically selecting a coordinator
        Bully algorithm
    Mutual exclusion
        Lamport's Distributed Mutual Exclusion Algorithm
        Naimi-Trehel's log(n) Algorithm
        Maekawa's Algorithm
        Raymond's Algorithm
        Ricart–Agrawala Algorithm
    Snapshot algorithm: record a consistent global state for an asynchronous system
        Chandy–Lamport algorithm
    Vector clocks: generate a partial ordering of events in a distributed system and detect causality violations

Memory allocation and deallocation algorithms

    Buddy memory allocation: Algorithm to allocate memory such that fragmentation is less.
    Garbage collectors
        Cheney's algorithm: An improvement on the Semi-space collector
        Generational garbage collector: Fast garbage collectors that segregate memory by age
        Mark-compact algorithm: a combination of the mark-sweep algorithm and Cheney's copying algorithm
        Mark and sweep
        Semi-space collector: An early copying collector
    Reference counting

Networking
Further information: Network scheduler

    Karn's algorithm: addresses the problem of getting accurate estimates of the round-trip time for messages when using TCP
    Luleå algorithm: a technique for storing and searching internet routing tables efficiently
    Network congestion
        Exponential backoff
        Nagle's algorithm: improve the efficiency of TCP/IP networks by coalescing packets
        Truncated binary exponential backoff

Operating systems algorithms
Further information: Operating systems

    Banker's algorithm: Algorithm used for deadlock avoidance.
    Page replacement algorithms: Selecting the victim page under low memory conditions.
        Adaptive replacement cache: better performance than LRU
        Clock with Adaptive Replacement (CAR): is a page replacement algorithm that has performance comparable to Adaptive replacement cache

Process synchronization
Further information: Process synchronization
Further information: Process scheduler

    Dekker's algorithm
    Lamport's Bakery algorithm
    Peterson's algorithm

Scheduling
Further information: Scheduling (computing)

    Earliest deadline first scheduling
    Fair-share scheduling
    Least slack time scheduling
    List scheduling
    Multi level feedback queue
    Rate-monotonic scheduling
    Round-robin scheduling
    Shortest job next
    Shortest remaining time
    Top-nodes algorithm: resource calendar management

I/O scheduling
Further information: I/O scheduling
[icon] 
This section needs expansion. You can help by adding to it. (July 2017)
Disk scheduling

    Elevator algorithm: Disk scheduling algorithm that works like an elevator.
    Shortest seek first: Disk scheduling algorithm to reduce seek time.